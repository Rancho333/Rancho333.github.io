<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>2021年天弘跑团数据</title>
    <url>/2021/01/04/2021%E5%B9%B4%E5%A4%A9%E5%BC%98%E8%B7%91%E5%9B%A2%E6%95%B0%E6%8D%AE/</url>
    <content><![CDATA[<p>2021年天弘跑团数据统计</p>
<p>1月1号至1月3号</p>
<span id="more"></span>
<table>
<thead>
<tr>
<th align="left">姓名</th>
<th align="left">日期</th>
<th align="left">方式</th>
<th align="left">距离/km</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Leon</td>
<td align="left">1.1</td>
<td align="left">线上</td>
<td align="left">20.21</td>
</tr>
<tr>
<td align="left">Rancho</td>
<td align="left">1.1+1.2</td>
<td align="left">线上+线下</td>
<td align="left">20.21+10</td>
</tr>
<tr>
<td align="left">Gary</td>
<td align="left">1.1</td>
<td align="left">线上</td>
<td align="left">4.3</td>
</tr>
<tr>
<td align="left">Jason</td>
<td align="left">1.2</td>
<td align="left">线下</td>
<td align="left">20</td>
</tr>
<tr>
<td align="left">Ceecee+小朋友</td>
<td align="left">1.2</td>
<td align="left">线下</td>
<td align="left">5+5</td>
</tr>
<tr>
<td align="left">杨坤</td>
<td align="left">1.2</td>
<td align="left">线下</td>
<td align="left">15</td>
</tr>
<tr>
<td align="left">Lisa</td>
<td align="left">1.2</td>
<td align="left">线下</td>
<td align="left">5</td>
</tr>
<tr>
<td align="left">Lewis+小朋友</td>
<td align="left">1.2</td>
<td align="left">线下</td>
<td align="left">10+5</td>
</tr>
<tr>
<td align="left">吴徐祥</td>
<td align="left">1.2</td>
<td align="left">线下</td>
<td align="left">10</td>
</tr>
<tr>
<td align="left">energy</td>
<td align="left">1.2</td>
<td align="left">线上</td>
<td align="left">4.73</td>
</tr>
<tr>
<td align="left">xiang</td>
<td align="left">1.2</td>
<td align="left">线上</td>
<td align="left">8.25</td>
</tr>
</tbody></table>
<p>2月10号至18号春节跑步打卡数据统计</p>
<table>
<thead>
<tr>
<th align="left">姓名</th>
<th align="left">数据</th>
<th align="left">累计/km</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Lewis+小朋友</td>
<td align="left">5.03(10) + 7.68(13)</td>
<td align="left">12.71</td>
</tr>
<tr>
<td align="left">Rancho</td>
<td align="left">10.02(10) + 7.55(13) + 10.02(14) + 10.39(15) + 10.05(16) + 6.07(17) + 14.24(18)</td>
<td align="left">68.34</td>
</tr>
<tr>
<td align="left">Ceecee+小朋友</td>
<td align="left">7.55(13)</td>
<td align="left">7.55</td>
</tr>
<tr>
<td align="left">Xiang</td>
<td align="left">22.26(11) + 22.27(16)</td>
<td align="left">44.53</td>
</tr>
<tr>
<td align="left">Even</td>
<td align="left">8.88(12) + 13.14(14)</td>
<td align="left">22.02</td>
</tr>
<tr>
<td align="left">Leon</td>
<td align="left">8.88(12) + 12.21(13) + 13.14(14) + 15.21(15) + 14.91(17)</td>
<td align="left">64.35</td>
</tr>
<tr>
<td align="left">Jason</td>
<td align="left">9.01(10) + 4.87+7.68+5.16(13) + 9.85(15) + 9.02(17) + 6.06(18)</td>
<td align="left">51.65</td>
</tr>
<tr>
<td align="left">Linda</td>
<td align="left">7.05(13)</td>
<td align="left">7.05</td>
</tr>
<tr>
<td align="left">Jack XU</td>
<td align="left">3.03(14) + 3.03(16)</td>
<td align="left">6.06</td>
</tr>
<tr>
<td align="left">Vivian</td>
<td align="left">5.18(10) + 5.51(13) + 5.22(14) + 5.64(17) + 5.23(18)</td>
<td align="left">26.78</td>
</tr>
<tr>
<td align="left">ian.Yuan</td>
<td align="left">9.61(16) + 6.93(18)</td>
<td align="left">16.54</td>
</tr>
</tbody></table>
<p>2022年1月1号至3号元旦跑步数据：<br>| 姓名 | 数据 | 累计/km |<br>| :— | :— | :— |<br>| 杨鹏飞 | 5.2+5.4 | 10.6 |<br>| Xiang | 15 | 15 |<br>| Rancho | 20.22 | 20.22 |<br>| 李飞 | 5.03+5.03 | 10.06 |<br>| 卢海龙 | 8.18+7.22 | 15.4|<br>| 秦景 | 5.31 | 5.31 |<br>| Lewis | 5.02 | 5.02 |<br>| Jack Xu | 3.57+5.18+6.51 | 15.26|<br>| Leon | 20.22 | 20.22 |<br>| Andy | 22.22 | 22.22 |<br>| 军生 | 10.86+20.22 | 31.08|<br>| 万俊霞 | 3.7 | 3.7 |<br>| Keven | 5.2 | 5.2 |<br>| 洋桔梗 | 5.48 | 5.48 |<br>| Silesfleur | 6.27 | 6.27 |<br>| Gary | 5.22+5.55 | 10.77 |<br>| 5km |  6人 |<br>| 10km | 3人 |<br>| 15km | 7人 | </p>
<ol>
<li>Rancho + 男 + XL</li>
<li>Ceecee Nie +女+ M</li>
<li>Lewis+男+XL</li>
<li>卢海龙 + 男 + XL</li>
<li>Wind Wang+男+XL</li>
<li>Milly Li +女+M</li>
<li>Ferris+男+XL</li>
<li>陈毓敏Even +女+L</li>
<li>xiang+男+2XL</li>
<li>Leon + 男 + 3XL</li>
<li>杨坤 + 男 + XL</li>
<li>周军 + 男 +  XL</li>
<li>🏃Jason Zhang +男+L</li>
<li>zl  + 女 + xl</li>
<li>许天辉-TianhuiXu  + 男+ L</li>
<li>天天 +女+M</li>
<li>李超超 + 女 +  L</li>
<li>万俊霞+女+M</li>
<li>Sandy Zhang+男 + XL</li>
<li>Jack XU +男+XL</li>
<li>Lisa Q +女+XL</li>
<li>Vivian Xue+女+XL</li>
<li>Chad Xu +男+3XL</li>
<li>Jenny Yang+女XL</li>
<li>Keven kai+男 3XL</li>
<li>Jeff Zhang+男+XL</li>
<li>Don Liu +男+3XL</li>
<li>Lindsay Zou +女+XL</li>
<li>薛晶+女+L</li>
<li>謝 +男+2XL</li>
<li>Maggie Yu + 女+2XL</li>
<li>秋_秋_ ＋女＋XL</li>
<li>donmi + 男 + 2XL</li>
<li>Michael + 男+L</li>
<li>Tom Mo + 男 + 3XL</li>
<li>矿士Orge +男+L</li>
<li>Ely Sun + 男 + L</li>
<li>Mark Wu+男+3XL</li>
</ol>
]]></content>
  </entry>
  <entry>
    <title>C语言弱符号weak</title>
    <url>/2020/03/03/C%E8%AF%AD%E8%A8%80%E5%BC%B1%E7%AC%A6%E5%8F%B7weak/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>上一篇文章《ENOS上段错调试记录》中有提到弱符号<code>weak</code>引发的段错，这篇文章来学习一下weak的用法。说来惭愧，工作了快4年，第一次见到这个语法。</p>
<span id="more"></span>
<h1 id="weak弱符号定义"><a href="#weak弱符号定义" class="headerlink" title="weak弱符号定义"></a>weak弱符号定义</h1><p>网上找了下weak符号的定义：#pragma weak to define a weakglobal symbol. This pragma is used mainly in source files for building libraries. The linker does not produce an error if it is unable to resolve a weak symbol.<br>对于全局的函数和变量，能不能重命名是有一定的规矩的，强、弱符号就是针对这些全局函数和变量来说的。</p>
<table>
<thead>
<tr>
<th align="left">符号类型</th>
<th align="left">对象</th>
</tr>
</thead>
<tbody><tr>
<td align="left">强</td>
<td align="left">函数名，赋初值的全局变量</td>
</tr>
<tr>
<td align="left">弱</td>
<td align="left">未初始化的全局变量</td>
</tr>
</tbody></table>
<p>当代码中存在多个强或弱的全局变量时，规则如下：</p>
<ol>
<li>强符号只能定义一次，否则编译error(未使用weak修饰的都是强符号)</li>
<li>强弱符号同时存在，以强符号为准</li>
<li>没有强符号，从多个弱符号中选一个，<code>-fno-common</code>这种情况下可以打出<code>warning</code><br>这玩意的用途有点类似于<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#ifndef name</span><br><span class="line">    #define name</span><br><span class="line">#endif</span><br></pre></td></tr></table></figure></li>
</ol>
<h1 id="代码演示"><a href="#代码演示" class="headerlink" title="代码演示"></a>代码演示</h1><h2 id="弱符号声明"><a href="#弱符号声明" class="headerlink" title="弱符号声明"></a>弱符号声明</h2><p>两种方式，第一种 </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">extern void weak0();</span><br><span class="line">#pragma weak weak0</span><br></pre></td></tr></table></figure>
<p>第二种方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void __attribute__((weak)) weak0();</span><br></pre></td></tr></table></figure>

<h2 id="规则演示"><a href="#规则演示" class="headerlink" title="规则演示"></a>规则演示</h2><p>下面通过三段代码来演示上诉的3条规则。</p>
<h3 id="main-c"><a href="#main-c" class="headerlink" title="main.c"></a>main.c</h3><p><code>main.c</code>里面调用了2个声明为弱符号的函数，分别是<code>weak0</code>和<code>weak1</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;                                                                                                                                                                                              </span><br><span class="line">&#x2F;&#x2F;void __attribute__((weak)) weak0(void);</span><br><span class="line">&#x2F;&#x2F;void __attribute__((weak)) weak1(void);</span><br><span class="line">extern void weak0();</span><br><span class="line">extern void weak1();</span><br><span class="line">#pragma weak weak0</span><br><span class="line">#pragma weak weak1</span><br><span class="line"> </span><br><span class="line">int main(int argc, char **argv)&#123;</span><br><span class="line">    &#x2F;&#x2F;尝试调用弱符号函数weak0</span><br><span class="line">    if (weak0)&#123;</span><br><span class="line">        weak0();</span><br><span class="line">    &#125;   </span><br><span class="line">    else&#123;</span><br><span class="line">        printf(&quot;weak0&#x3D;%p\n&quot;, weak0);</span><br><span class="line">    &#125;   </span><br><span class="line">    &#x2F;&#x2F;尝试调用弱符号函数weak1</span><br><span class="line">    if (weak1)&#123;</span><br><span class="line">        weak1();</span><br><span class="line">    &#125;   </span><br><span class="line">    else&#123;</span><br><span class="line">        printf(&quot;weak1&#x3D;%p\n&quot;, weak1);</span><br><span class="line">    &#125;   </span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="weak-c"><a href="#weak-c" class="headerlink" title="weak.c"></a>weak.c</h3><p><code>weak.c</code>中定义了两个函数（weak0和weak1），并将之声明为弱符号</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;标记weak0为弱符号</span><br><span class="line">#pragma weak weak0</span><br><span class="line">&#x2F;&#x2F;标记weak1为弱符号</span><br><span class="line">void __attribute__((weak)) weak1(void);</span><br><span class="line"></span><br><span class="line">static char *label &#x3D; &quot;weak&quot;;</span><br><span class="line"></span><br><span class="line">void weak0(void)&#123;</span><br><span class="line">    printf(&quot;[%s]%s is called\n&quot;, label, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void weak1(void)&#123;</span><br><span class="line">    printf(&quot;[%s]%s is called\n&quot;, label, __FUNCTION__);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h3 id="strong-c"><a href="#strong-c" class="headerlink" title="strong.c"></a>strong.c</h3><p><code>strong.c</code>中重复定义了这两个函数，不做声明。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;两个函数都[不]声明为弱符号</span><br><span class="line">&#x2F;&#x2F;#pragma weak weak0</span><br><span class="line">&#x2F;&#x2F;void __attribute__((weak)) weak1(void);</span><br><span class="line"></span><br><span class="line">static char *label &#x3D; &quot;strong&quot;;</span><br><span class="line"></span><br><span class="line">void weak0(void)&#123;</span><br><span class="line">    printf(&quot;[%s]%s is called\n&quot;, label, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void weak1(void)&#123;</span><br><span class="line">    printf(&quot;[%s]%s is called\n&quot;, label, __FUNCTION__);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="不同编译组合及其输出情况"><a href="#不同编译组合及其输出情况" class="headerlink" title="不同编译组合及其输出情况"></a>不同编译组合及其输出情况</h2><h3 id="单独编译main-c"><a href="#单独编译main-c" class="headerlink" title="单独编译main.c"></a>单独编译main.c</h3><p>此处弱符号函数链接不成功，但是不会报编译错误，函数名所代表的地址为<code>nil</code><br><img src="https://rancho333.gitee.io/pictures/main.png"><br>如果这里依然调用它，那么便会如前面文章中提到的一样产生段错。<br><img src="https://rancho333.gitee.io/pictures/segmentation_fault.png"></p>
<h3 id="编译main-c-weak-c"><a href="#编译main-c-weak-c" class="headerlink" title="编译main.c+weak.c"></a>编译main.c+weak.c</h3><p>弱符号链接成功，可以正常调用。<br><img src="https://rancho333.gitee.io/pictures/weak.png"></p>
<h3 id="编译main-c-weak-c-strong-c"><a href="#编译main-c-weak-c-strong-c" class="headerlink" title="编译main.c+weak.c+strong.c"></a>编译main.c+weak.c+strong.c</h3><p>当出现强符号定义时，弱符号定义不起作用<br><img src="https://rancho333.gitee.io/pictures/strong.png"></p>
]]></content>
      <tags>
        <tag>弱符号</tag>
      </tags>
  </entry>
  <entry>
    <title>ENOS上段错调试记录</title>
    <url>/2020/03/02/ENOS%E4%B8%8A%E6%AE%B5%E9%94%99%E8%B0%83%E8%AF%95%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>移植ENOS过程中发现某些系统编译生成的命令运行过程中报<code>segmentation fault</code>,报错信息如下。这里记录一下调试过程中遇到的问题，涉及到<code>weak</code>属性，<code>-pthread</code>，<code>strace</code>等。</p>
<span id="more"></span>
<p><img src="https://rancho333.gitee.io/pictures/fault.png"></p>
<h2 id="段错调试手段记录"><a href="#段错调试手段记录" class="headerlink" title="段错调试手段记录"></a>段错调试手段记录</h2><p>产生段错首先想到的自然是通过<code>gdb</code>进行错误分析，由于toolchain中并没有提供，所以自行下载了一个gdb源码，通过经典<code>configure, make, make install</code>三部曲后移到板子上，gdb调试信息如下：<br><img src="https://rancho333.gitee.io/pictures/gdb.png"></p>
<p>gdb中并不能看出什么有效的信息，但看起来函数栈的调用还没有到ccs的main函数中（没有与ccs相关的打印），上一篇文章《关于动态库以及constructor属性的使用》中有提到。<br>通过<code>dmesg</code>查看内核报错信息：<br><img src="https://rancho333.gitee.io/pictures/dmesg.png"><br>可以看到<code>pc</code>寄存器取址的地址为全0 ，这一般是因为空指针导致，我们知道cpu指令的执行顺序为取址，分析，执行三个步骤，没取到指令后续自然是啥都没有了。</p>
<p>通过<code>strace ccs</code>命令来查看ccs的详细调用过程关于动态库的调用过程就不表了，这里直接看报错的位置：<br><img src="https://rancho333.gitee.io/pictures/strace.png"><br>发现执行完write指令之后就挂了，经过一番曲折之后定位到代码中：<br><img src="https://rancho333.gitee.io/pictures/iv_signal.png"><br><code>iv_fd_set_cloexec</code>中有两次<code>fnctl</code>的调用，与strace中的4次fnctl调用刚好对上，而函数<code>iv_signal_init</code>被<code>constructor</code>属性修饰，而该函数所在模块（libtask）是被编译成so供其它模块调用的，即所有调用该动态库的模块在执行main函数之前都会执行一遍<code>iv_signal_init</code>，进一步追查Makefile发现报错的命令全部都依赖与该动态库，一切都说通了，没有玄学。</p>
<p>在进一步排查，init中最可疑的就是<code>pthr_atfork</code>这个函数了，查看该函数定义，发现一个从没见过的用法<code>#pragma weak pthread_atfork</code>：<br><img src="https://rancho333.gitee.io/pictures/atfork.png"><br>后面会再写一篇关于这个属性的用法，简单说就是被<code>weak</code>修饰的符号即使不存在编译也不会报错。</p>
<h2 id="weak之后的调试"><a href="#weak之后的调试" class="headerlink" title="weak之后的调试"></a>weak之后的调试</h2><p>这里发现libtask中既没有自己实现<code>pthread_atfork</code>,也没有在Makefile中链接<code>-pthread</code>，而是使用<code>ifdef HAVE_PRAGMA_WEAK</code>(后来我改成ifndef了)来进行屏蔽，在运行过程中自然会报错，在调用之前打印该函数的地址，不出意料的是<code>NULL</code>，维护人员最初的用意已经不可考证了，直接去掉<code>HAVE_PRAGMA_WEAK</code>,编译中加上<code>-pthread</code>。<br><img src="https://rancho333.gitee.io/pictures/zhw_test.png"></p>
<p>这里有必要顺嘴提一下<code>-lpthread</code>和<code>-pthread</code>，如果使用<code>-lpthread</code>的时候会报一些<code>undefined reference to</code>的错误，错误原因可以自行百度，换成<code>-pthread</code>即可。</p>
]]></content>
      <tags>
        <tag>段错误</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo使用优化</title>
    <url>/2019/07/14/Hexo%E4%BD%BF%E7%94%A8%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">站点配置文件：位于站点根目录下，主要包含Hexo本身的配置</span><br><span class="line">主题配置文件：位于主题目录下，主要用于配置主题相关的选项</span><br></pre></td></tr></table></figure>

<p>版本说明, 当前配置基于以下版本进行修改，hexo代码环境打包在<a href="https://hub.docker.com/repository/docker/rancho123/ubuntu">docker</a>中，避免生产环境改变带来的问题。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo: 5.4.0</span><br><span class="line">hexo-cli: 4.2.0</span><br><span class="line">next: 7.8.0</span><br></pre></td></tr></table></figure>

<h2 id="hexo的一些规则"><a href="#hexo的一些规则" class="headerlink" title="hexo的一些规则"></a>hexo的一些规则</h2><ol>
<li>放在<code>source</code>下所有不以下划线开头的文件，在<code>hexo g</code>的时候会拷贝到<code>public</code>下面</li>
<li>hexo默认渲染所有的html和markdown文件 </li>
</ol>
<h2 id="使用next主题"><a href="#使用next主题" class="headerlink" title="使用next主题"></a>使用next主题</h2><p>网上一搜大部分都是Hexo+next的使用，本着站在前人的肩膀上原则，使用next主题。<br>主题下载：<code>git clone https://gitee.com/Rancho333/hexo-theme-next.git themes/next</code><br>启用主题，打开站点配置文件，找到<code>theme</code>字段，修改为如下：  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">theme: next</span><br></pre></td></tr></table></figure>

<h3 id="选择scheme"><a href="#选择scheme" class="headerlink" title="选择scheme"></a>选择scheme</h3><p>next提供4种不同外观，找到<code>scheme</code>字段，启用其中一种scheme，这里我选择Gemini.  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Schemes                                  </span></span><br><span class="line"><span class="comment">#scheme: Muse</span></span><br><span class="line"><span class="comment">#scheme: Mist</span></span><br><span class="line"><span class="comment">#scheme: Pisces</span></span><br><span class="line">scheme: Gemini</span><br></pre></td></tr></table></figure>

<h3 id="设置语言"><a href="#设置语言" class="headerlink" title="设置语言"></a>设置语言</h3><p>在站点配置文件中找到<code>language</code>字段，修改为(中文，英文为：en)：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">language: zh-CN</span><br></pre></td></tr></table></figure>
<p>注意需要在<code>themes/next/languages/</code>下面有对应的语言文件，否则不生效（使用默认）</p>
<h3 id="设置侧栏"><a href="#设置侧栏" class="headerlink" title="设置侧栏"></a>设置侧栏</h3><p>找到<code>sidebar</code>字段，修改如下：  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">sidebar:</span><br><span class="line">  <span class="comment">#靠左放置</span></span><br><span class="line">  position: left</span><br><span class="line">  <span class="comment">#显示时机</span></span><br><span class="line">  display: always</span><br></pre></td></tr></table></figure>

<h3 id="设置头像"><a href="#设置头像" class="headerlink" title="设置头像"></a>设置头像</h3><p>在主题配置文件中，找到<code>avatar</code>字段，值设置成头像的链接地址</p>
<h3 id="设置作者昵称"><a href="#设置作者昵称" class="headerlink" title="设置作者昵称"></a>设置作者昵称</h3><p>在站点配置文件中，找到<code>author</code>字段，进行设置  </p>
<h2 id="修改网址图标"><a href="#修改网址图标" class="headerlink" title="修改网址图标"></a>修改网址图标</h2><p>可以在<code>https://www.iconfont.cn/</code>上找合适的图标，下载两个尺寸(16x16和32x32)的png格式图片，放到主题下的images文件夹中。在主题配置文件中找到：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">favicon:                         </span><br><span class="line">  small: /images/R-16x16.png  </span><br><span class="line">  medium: /images/R-32x32.png </span><br></pre></td></tr></table></figure>
<p>替换small和medium两项，分别对应两种尺寸的图标。</p>
<h2 id="给文章添加”categories”属性"><a href="#给文章添加”categories”属性" class="headerlink" title="给文章添加”categories”属性"></a>给文章添加”categories”属性</h2><p>创建<code>categories</code>页面  </p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page categories</span><br></pre></td></tr></table></figure>
<p>找到<code>source/categories/index.md</code>文件，里面的初始内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---                                       </span><br><span class="line">title: categories</span><br><span class="line">date: 2019-07-12 12:14:44</span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>添加<code>type: &quot;categories&quot;</code>到内容中，添加后内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---                                               </span><br><span class="line">title: categories</span><br><span class="line">date: 2019-07-12 12:14:44</span><br><span class="line"><span class="built_in">type</span>: <span class="string">&quot;categories&quot;</span></span><br><span class="line">---</span><br></pre></td></tr></table></figure>

<p>给文章添加<code>categories</code>属性，打开任意一篇md文件，为其添加概述信，添加后内容如下：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">---                                              </span><br><span class="line">title: Linux查找so文件所在pkg </span><br><span class="line">date: 2019-07-14 20:17:03</span><br><span class="line">categories: </span><br><span class="line">- Linux相关</span><br><span class="line">tags:</span><br><span class="line">- Linux</span><br><span class="line">- so文件</span><br><span class="line">---</span><br></pre></td></tr></table></figure>
<p>hexo一篇文章只能属于一个分类，如添加多个分类，则按照分类嵌套进行处理。</p>
<h2 id="给文章添加”tags”属性"><a href="#给文章添加”tags”属性" class="headerlink" title="给文章添加”tags”属性"></a>给文章添加”tags”属性</h2><p>创建<code>tags</code>页面</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">hexo new page tags</span><br></pre></td></tr></table></figure>

<p>后面的操作与添加<code>categories</code>属性类似，一篇文章可以添加多个<code>tags</code>  </p>
<h1 id="关于图片"><a href="#关于图片" class="headerlink" title="关于图片"></a>关于图片</h1><p>有时候会分享md文件给别人，这时候要求图片的标识是因特网可达的，而不能使用资源文件夹这种方式。可以将图片放在<code>public/pictures</code>文件夹中，<code>hexo clean</code>命令会删除该文件夹。图片调用：<code>![](https://rancho333.gitee.io/pictures/arp_protocol.png) </code></p>
<ol>
<li>将图片源文件放到<code>source/pictures</code>路径下（源码可以备份，<code>hexo clean</code>命令会删除public文件夹）</li>
<li><code>hexo g</code>会将<code>source</code>下面非下划线开头的文件或文件夹拷贝到<code>public</code>下面</li>
<li><code>public</code>里面的内容会上传到master分支，所以我们可以使用上面的链接进行访问</li>
</ol>
<h1 id="文章搜索功能"><a href="#文章搜索功能" class="headerlink" title="文章搜索功能"></a>文章搜索功能</h1><p>安装搜索功能插件：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">npm install hexo-generator-searchdb --save</span><br></pre></td></tr></table></figure>
<p>在站点配置文件中添加：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">search:                                                                                                                                                                                          </span><br><span class="line">  path: search.xml    搜索文件path，所有的可搜索内容都静态写到了该文件中</span><br><span class="line">  field: post         搜索范围</span><br><span class="line">  format: html</span><br><span class="line">  <span class="built_in">limit</span>: 100         限制搜索的条目</span><br></pre></td></tr></table></figure>
<p>在主题配置文件中：</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">local_search:                                                                                       </span><br><span class="line">  <span class="built_in">enable</span>: <span class="literal">true</span> </span><br></pre></td></tr></table></figure>

<h1 id="查看插件以及脚本"><a href="#查看插件以及脚本" class="headerlink" title="查看插件以及脚本"></a>查看插件以及脚本</h1><p><code>hexo --debug</code>可以查看插件以及使用的脚本</p>
<h1 id="添加看板娘"><a href="#添加看板娘" class="headerlink" title="添加看板娘"></a>添加看板娘</h1><p>安装插件<code>hexo-helper-live2d</code><br>安装看板模型<code>live2d-widget-model-shizuku</code><br>在站点配置文件中增加如下配置</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># Live2D</span><br><span class="line"># https:&#x2F;&#x2F;github.com&#x2F;EYHN&#x2F;hexo-helper-live2d</span><br><span class="line">live2d:</span><br><span class="line">  enable: true</span><br><span class="line">  pluginRootPath: live2dw&#x2F;</span><br><span class="line">  pluginJsPath: lib&#x2F;</span><br><span class="line">  pluginModelPath: assets&#x2F; Relative)</span><br><span class="line"> </span><br><span class="line">  # 脚本加载源</span><br><span class="line">  scriptFrom: local # 默认从本地加载脚本</span><br><span class="line">  # scriptFrom: jsdelivr # 从 jsdelivr CDN 加载脚本</span><br><span class="line">  # scriptFrom: unpkg # 从 unpkg CDN 加载脚本</span><br><span class="line">  # scriptFrom: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;live2d-widget@3.x&#x2F;lib&#x2F;L2Dwidget.min.js # 从自定义地址加载脚本</span><br><span class="line">  tagMode: false # 只在有 &#123;&#123; live2d() &#125;&#125; 标签的页面上加载 &#x2F; 在所有页面上加载</span><br><span class="line">  log: false # 是否在控制台打印日志</span><br><span class="line"> </span><br><span class="line">  # 选择看板娘模型</span><br><span class="line">  model:</span><br><span class="line">    use: live2d-widget-model-shizuku  # npm package的名字</span><br><span class="line">    # use: wanko # &#x2F;live2d_models&#x2F; 目录下的模型文件夹名称</span><br><span class="line">    # use: .&#x2F;wives&#x2F;wanko # 站点根目录下的模型文件夹名称</span><br><span class="line">    # use: https:&#x2F;&#x2F;cdn.jsdelivr.net&#x2F;npm&#x2F;live2d-widget-model-wanko@1.0.5&#x2F;assets&#x2F;wanko.model.json # 自定义网络数据源</span><br><span class="line">  display:</span><br><span class="line">    position: left # 显示在左边还是右边</span><br><span class="line">    width: 100 # 宽度</span><br><span class="line">    height: 180 # 高度</span><br><span class="line">  mobile:</span><br><span class="line">    show: false</span><br><span class="line">  react:</span><br><span class="line">    opacityDefault: 0.7 # 默认透明度</span><br></pre></td></tr></table></figure>

<h2 id="添加字数统计"><a href="#添加字数统计" class="headerlink" title="添加字数统计"></a>添加字数统计</h2><p>安装插件<code>npm install hexo-wordcount --save</code><br>在<code>themes/next/layout/_macro/post.swig</code>文件的<code>busuazi</code>所在的模块的<code>endif</code>前面加上：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;span class&#x3D;&quot;post-meta-divider&quot;&gt;|&lt;&#x2F;span&gt;</span><br><span class="line">&lt;span title&#x3D;&quot;&#123;&#123; __(&#39;post.wordcount&#39;) &#125;&#125;&quot;&gt;&lt;span class&#x3D;&quot;post-meta-item-icon&quot;&gt;&lt;i class&#x3D;&quot;fa fa-file-word-o&quot;&gt;&lt;&#x2F;i&gt;&lt;&#x2F;span&gt;字数： &#123;&#123; wordcount(post.content) &#125;&#125;&lt;&#x2F;span&gt;</span><br></pre></td></tr></table></figure>
<p>在<code>themes/next/layout/_partials/footer.swig</code>文件的最后一行之前加上：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;div class&#x3D;&quot;theme-info&quot;&gt;</span><br><span class="line">  &lt;div class&#x3D;&quot;powered-by&quot;&gt;&lt;&#x2F;div&gt;</span><br><span class="line">&lt;span class&#x3D;&quot;post-count&quot;&gt;全站共 &#123;&#123; totalcount(site) &#125;&#125; 字&lt;&#x2F;span&gt;</span><br><span class="line">&lt;&#x2F;div&gt;</span><br></pre></td></tr></table></figure>

<h2 id="圆角设置"><a href="#圆角设置" class="headerlink" title="圆角设置"></a>圆角设置</h2><p>在 hexo/source/_data 目录下新建 variables.styl 文件，填写下面内容。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 圆角设置</span><br><span class="line">$border-radius-inner     &#x3D; 20px 20px 20px 20px;</span><br><span class="line">$border-radius           &#x3D; 20px;</span><br></pre></td></tr></table></figure>
<p>主题配置文件 next.yml 去除 variables.styl 的注释。</p>
<h2 id="设置网站背景"><a href="#设置网站背景" class="headerlink" title="设置网站背景"></a>设置网站背景</h2><p>除了设置背景图片，还需要设置博客文章博客文章透明度才能看到背景图片。<br>主题配置文件 next.yml 去除 style.styl 的注释。<br>在 hexo/source/_data/style.styl 文件中写入下面代码。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F; 设置背景图片</span><br><span class="line">body &#123;</span><br><span class="line">    background:url(&#x2F;images&#x2F;background.png);</span><br><span class="line">    background-repeat: no-repeat;</span><br><span class="line">    background-attachment:fixed; &#x2F;&#x2F;不重复</span><br><span class="line">    background-size: cover;      &#x2F;&#x2F;填充</span><br><span class="line">    background-position:50% 50%;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>next 主题的博客文章都是不透明的，这样即使设置了背景图片也无法看到，在 hexo/source/_data/styles.styl 中写入下面内容，使博客文章透明化。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;博客内容透明化</span><br><span class="line">&#x2F;&#x2F;文章内容的透明度设置</span><br><span class="line">.content-wrap &#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;侧边框的透明度设置</span><br><span class="line">.sidebar &#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;菜单栏的透明度设置</span><br><span class="line">.header-inner &#123;</span><br><span class="line">  background: rgba(255,255,255,0.9);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;搜索框（local-search）的透明度设置</span><br><span class="line">.popup &#123;</span><br><span class="line">  opacity: 0.9;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>参考资料：</strong><br><a href="http://theme-next.iissnan.com/">NexT官方</a>  </p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux下程序调试方法简述</title>
    <url>/2020/08/05/Linux%E4%B8%8B%E7%A8%8B%E5%BA%8F%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本文旨在综合性的描述Linux下程序调试的方法和思路，不会过于细节的描述某种工具的使用，如gdb，这些方法通过man以及google都能找到答案。包含知识点：strip, addr2line, strace, gdb, readelf。</p>
<span id="more"></span>
<h2 id="strip相关"><a href="#strip相关" class="headerlink" title="strip相关"></a>strip相关</h2><p>嵌入式系统要求小巧精简，最大限度去除冗余数据。Linux下编译出来elf文件是带有符号表的，通过<code>nm</code>命令可以查看，如：<br><img src="https://rancho333.gitee.io/pictures/nm.png"><br>这些符号表是进行程序调试的关键，例如通过<code>addr2line</code>进行地址和文件名或行数的转换，例如在<code>gdb</code>中通过<code>bt</code>显示函数调用栈信息，没有符号表这些工具都无法提供有价值信息。<br><code>strip</code>命令可以去掉这些符号信息，进而减小文件大小，同时不会影响elf的正常执行。<br><img src="https://rancho333.gitee.io/pictures/compare.png"><br>可以看到，<code>strip app</code>之后，app中没有符号表相关信息了。<br>在进行rootfs制作时，对于发行版本，我们进行<code>strip</code>操作，对于开发人员调试版本，我们保留符号表信息。<br><img src="https://rancho333.gitee.io/pictures/strip.png"></p>
<h2 id="gdb简述"><a href="#gdb简述" class="headerlink" title="gdb简述"></a>gdb简述</h2><p>遇到<code>core dump</code>最常使用的就是<code>gdb</code>了，<code>gdb</code>的一般使用方法<code>gdb app core</code>。常见子命令如下：</p>
<table>
<thead>
<tr>
<th align="left">cmd</th>
<th align="left">function</th>
</tr>
</thead>
<tbody><tr>
<td align="left">bt</td>
<td align="left">回溯显示app堆栈</td>
</tr>
<tr>
<td align="left">bt full</td>
<td align="left">不仅仅显示栈帧，还显示局部变量</td>
</tr>
<tr>
<td align="left">info reg</td>
<td align="left">显示寄存器内容</td>
</tr>
<tr>
<td align="left">run</td>
<td align="left">执行app</td>
</tr>
<tr>
<td align="left">print val</td>
<td align="left">打印变量val的值</td>
</tr>
<tr>
<td align="left">break</td>
<td align="left">设置断点</td>
</tr>
</tbody></table>
<p>gdb一般使用<em>断点</em>和<em>堆栈</em>进行程序调试，注意调试的程序一定要是<code>not stripped</code>的。<br>简单示例如下：<br><img src="https://rancho333.gitee.io/pictures/gdb.png"></p>
<h2 id="strace介绍"><a href="#strace介绍" class="headerlink" title="strace介绍"></a>strace介绍</h2><p>strace可以跟踪app的<code>system call</code>和<code>signals</code>，一般使用方法<code>strace app</code>，常见参数如下：</p>
<table>
<thead>
<tr>
<th align="left">cmd</th>
<th align="left">function</th>
</tr>
</thead>
<tbody><tr>
<td align="left">-tt</td>
<td align="left">在每行输出的前面，显示毫秒级别的时间</td>
</tr>
<tr>
<td align="left">-T</td>
<td align="left">显示每次系统调用所花费的时间</td>
</tr>
<tr>
<td align="left">-v</td>
<td align="left">对于某些相关调用，把完整的环境变量，文件stat结构等打出来</td>
</tr>
<tr>
<td align="left">-f</td>
<td align="left">跟踪目标进程，以及目标进程创建的所有子进程</td>
</tr>
<tr>
<td align="left">-e</td>
<td align="left">控制要跟踪的事件和跟踪行为,比如指定要跟踪的系统调用名称</td>
</tr>
<tr>
<td align="left">-o</td>
<td align="left">把strace的输出单独写到指定的文件</td>
</tr>
<tr>
<td align="left">-s</td>
<td align="left">当系统调用的某个参数是字符串时，最多输出指定长度的内容，默认是32个字节</td>
</tr>
<tr>
<td align="left">-p</td>
<td align="left">指定要跟踪的进程pid, 要同时跟踪多个pid, 重复多次-p选项即可</td>
</tr>
<tr>
<td align="left">-i</td>
<td align="left">在打印系统调用同时打印指令指针</td>
</tr>
</tbody></table>
<p>举个之前在ENOS飞腾移植过程中的一个例子，先使用gdb做一个基本的错误定位<br><img src="https://rancho333.gitee.io/pictures/strace1.png"><br>看起来像是没有进入main函数就已经挂了。<br>使用strace查看命令执行过程中的系统调用和信号：<br><img src="https://rancho333.gitee.io/pictures/strace2.png"><br>找到源码中的对应位置：<br><img src="https://rancho333.gitee.io/pictures/strace3.png"><br>iv_signal_init在main函数之前会执行并挂掉，将之注释掉测试通过。</p>
<h2 id="so库相关"><a href="#so库相关" class="headerlink" title="so库相关"></a>so库相关</h2><p>使用<code>ldd</code>命令可以查看app的依赖库，<code>readelf</code>命令可以获取到更多的内容<br><img src="https://rancho333.gitee.io/pictures/so.png"></p>
<p>如果app的依赖库找不到，报错格式一般如下：<br><img src="https://rancho333.gitee.io/pictures/so.png"></p>
<p>这里面缺少一些动态库，二进制可执行文件，分3种情况：</p>
<ol>
<li>文件不存在</li>
<li>文件存在但路径不对, /etc/ld.so.conf 此文件记录了编译时使用的动态库的路径</li>
<li>有些文件不必须，可以注释掉，参考<br>根据不同的情况处理之。</li>
</ol>
]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux双网卡设置-内外网</title>
    <url>/2021/01/26/Linux%E5%8F%8C%E7%BD%91%E5%8D%A1%E8%AE%BE%E7%BD%AE-%E5%86%85%E5%A4%96%E7%BD%91/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>搞了一台树莓派4B来玩，想通过ssh来进行管理。由于公司网络管控，考虑通过内网（eth0）来进行ssh管理，通过外网(wlan0)进行上网。</p>
<span id="more"></span>

<h1 id="网络配置"><a href="#网络配置" class="headerlink" title="网络配置"></a>网络配置</h1><p>有线网和无线网都连接好后，通过DHCP获取ip，<code>ip route</code>状态如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">default via 10.204.123.1 dev eth0 proto dhcp src 10.204.123.145 metric 202 </span><br><span class="line">default via 192.168.3.254 dev wlan0 proto dhcp src 192.168.3.38 metric 303 </span><br><span class="line">10.204.123.0&#x2F;24 dev eth0 proto dhcp scope link src 10.204.123.145 metric 202 </span><br><span class="line">192.168.0.0&#x2F;22 dev wlan0 proto dhcp scope link src 192.168.3.38 metric 303</span><br></pre></td></tr></table></figure>
<p>其中10.204.0.0/16网段是内网，设备没有通过认证，不能通过内网上外网。考虑通过该网段与自己的主机相连，其余网络连接走192.168网段。<br>先将默认路由删除，这里需要连接显示器。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">route del default</span><br></pre></td></tr></table></figure>
<p>因为有两条默认理由，该命令执行两次。</p>
<p>之后添加默认路由和默认网关，可以写到<code>/etc/rc.local</code>中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#foreign net</span><br><span class="line">route add -net 0.0.0.0&#x2F;0 wlan0</span><br><span class="line">route add -net 0.0.0.0&#x2F;0 gw 192.168.3.254</span><br><span class="line"></span><br><span class="line">#local net</span><br><span class="line">route add -net 10.204.123.0&#x2F;16 eth0</span><br><span class="line">route add -net 10.204.123.0&#x2F;16 gw 10.204.123.1</span><br></pre></td></tr></table></figure>
<p>使能之后，<code>ip route</code>状态如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">default via 10.204.123.1 dev eth0 proto dhcp src 10.204.123.145 metric 202 </span><br><span class="line">default via 192.168.3.254 dev wlan0 proto dhcp src 192.168.3.38 metric 303 </span><br><span class="line">10.204.0.0&#x2F;16 via 10.204.123.1 dev eth0 </span><br><span class="line">10.204.0.0&#x2F;16 dev eth0 scope link </span><br><span class="line">10.204.123.0&#x2F;24 dev eth0 proto dhcp scope link src 10.204.123.145 metric 202 </span><br><span class="line">192.168.0.0&#x2F;22 dev wlan0 proto dhcp scope link src 192.168.3.38 metric 303 </span><br></pre></td></tr></table></figure>
<p><code>route -n</code>状态如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">0.0.0.0         192.168.3.254   0.0.0.0         UG    303    0        0 wlan0</span><br><span class="line">10.204.0.0      10.204.123.1    255.255.0.0     UG    0      0        0 eth0</span><br><span class="line">10.204.0.0      0.0.0.0         255.255.0.0     U     0      0        0 eth0</span><br><span class="line">10.204.123.0    0.0.0.0         255.255.255.0   U     202    0        0 eth0</span><br><span class="line">192.168.0.0     0.0.0.0         255.255.252.0   U     303    0        0 wlan0</span><br></pre></td></tr></table></figure>
<p>可以看到10.204网段走的是10.204.123.1网关，其余的网段走的都是外网192.168.3.254网关。</p>
<p>如果设备上使能了dhcpcd功能，则需要在获取到ip、路由之后手动配置路由。可以通过wlan0网络（外网）配置eth0（内网）的路由。</p>
]]></content>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux密码修改</title>
    <url>/2020/03/09/Linux%E5%AF%86%E7%A0%81%E4%BF%AE%E6%94%B9/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>在做交换机Linux系统移植的过程中，发现进入shell的密码还是上一家的默认密码，还是改改吧。简单交代一下，ENOS上kernel加载完成之后应用的启动顺序如下如：</p>
<span id="more"></span>
<p><img src="https://rancho333.gitee.io/pictures/inittab.png"></p>
<p>这里是不进入shell的，而是直接进入klish作为交换机的命令行交互界面，类似于quagga的vtysh。之后在<code>configure</code>视图下面执行<code>start shell</code>进入linux shell的。<br><img src="https://rancho333.gitee.io/pictures/shell.png"><br>在fnconvert里面会获取用户<code>root</code>的密码，其实就是使用<code>getspnam</code>获取<code>passwd或者shadow</code>的口令。既然这玩意使用的是Linux的账户和密码，那就是修改<code>/etc/passwd</code>文件了。<br><img src="https://rancho333.gitee.io/pictures/spnam.png"></p>
<h1 id="passwd文件简介"><a href="#passwd文件简介" class="headerlink" title="passwd文件简介"></a>passwd文件简介</h1><p>Linux中每个用户在/etc/passwd文件中都有一个对应的记录行，每一行被冒号<code>:</code>分隔为7个字段，具体含义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">用户名：口令：用户标识号：组标识号：注释性描述：主目录：登陆shell</span><br></pre></td></tr></table></figure>
<p>发行版中口令字段一般是<code>*或x</code>，<code>*</code>表示账号锁定, <code>x</code>表示密码存放在<code>/etc/shadown</code>文件中（访问需要sudo权限，而passwd文件不需要），当然我们的嵌入式系统密文是直接放在passwd中，如下：<br><img src="https://rancho333.gitee.io/pictures/passwd.png"></p>
<p>其它字段除了<code>登陆shell</code>就没啥好玩的了，有些账号出于安全限制，并不会允许登陆进shell，而采用<code>nologin</code>的方式可以让这些用户使用部分系统功能。<br><img src="https://rancho333.gitee.io/pictures/nologin.png"></p>
<h2 id="修改用户密码"><a href="#修改用户密码" class="headerlink" title="修改用户密码"></a>修改用户密码</h2><p>常规的在linux命令行下面修改密码没啥好说的，直接敲<code>passwd</code>然后输入新密码就行了，之后你会发现<code>passwd或者shadow</code>中的口令发生变化了。这里介绍一下口令了列的组成，不同的特殊字符表示不同的特殊意义：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 该列留空，即&quot;::&quot;，表示该用户没有密码。</span><br><span class="line">2. 该列为&quot;!&quot;，即&quot;:!:&quot;，表示该用户被锁，被锁将无法登陆，但是可能其他的登录方式是不受限制的，如ssh公钥认证的方式，su的方式。</span><br><span class="line">3. 该列为&quot;*&quot;，即&quot;:*:&quot;，也表示该用户被锁，和&quot;!&quot;效果是一样的。</span><br><span class="line">4. 该列以&quot;!&quot;或&quot;!!&quot;开头，则也表示该用户被锁。</span><br><span class="line">5. 该列为&quot;!!&quot;，即&quot;:!!:&quot;，表示该用户从来没设置过密码。</span><br><span class="line">6. 如果格式为&quot;$id$salt$hashed&quot;，则表示该用户密码正常。其中$id$的id表示密码的加密算法，$1$表示使用MD5算法，$2a$表示使用Blowfish算法，&quot;$2y$&quot;是另一算法长度的Blowfish,&quot;$5$&quot;表示SHA-256算法，而&quot;$6$&quot;表示SHA-512算法。加密算法会根据salt进行特定的加密，hashed是生成的密文</span><br></pre></td></tr></table></figure>
<p>我看自己的linux服务器上面都是使用SHA-512加密的，而嵌入式系统上面用的是MD5，使用命令<br><img src="https://rancho333.gitee.io/pictures/openssl.png"><br>就可以生成密码了，将原来的口令字段替换掉即可完成密码的修改。</p>
<p>有个小问题，实验过程中，发现在嵌入式系统上直接在命令行中修改密码不是按照<code>$id$salt$hashed</code>模式生成的口令，而是：<br><img src="https://rancho333.gitee.io/pictures/abnormal.png"><br>但是在发行版Linux上面是符合预期的，有可能是嵌入式系统的某些差异吧，这里留个记录！</p>
]]></content>
      <tags>
        <tag>passwd</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux查找so文件所在pkg</title>
    <url>/2019/07/14/Linux%E6%9F%A5%E6%89%BEso%E6%96%87%E4%BB%B6%E6%89%80%E5%9C%A8pkg/</url>
    <content><![CDATA[<h2 id="问题描述"><a href="#问题描述" class="headerlink" title="问题描述"></a>问题描述</h2><p>在Ubuntu16.04 server上安装typora时报错：<code>Typora: error while loading shared libraries: libnss3.so</code>  </p>
<span id="more"></span>
<p><img src="https://rancho333.gitee.io/pictures/error.png"><br>使用find在机器上的确没有找到该so文件，一般情况下对于name.so，安装一个name包就行了(so文件与pkg文件名相同)，但有的时候是不相同的，这时需要利用apt-file查找so文件所属的pkg.<br><img src="https://rancho333.gitee.io/pictures/diff.png"></p>
<h2 id="安装apt-file"><a href="#安装apt-file" class="headerlink" title="安装apt-file"></a>安装apt-file</h2><p>安装命令：<code>sudo apt-get install apt-file</code><br>update：<code>apt-file update</code>,当/etc/apt/source.list文件发生变化时，需要重新update<br><img src="https://rancho333.gitee.io/pictures/update.png"></p>
<h2 id="查找软件所依赖的so文件并安装依赖包"><a href="#查找软件所依赖的so文件并安装依赖包" class="headerlink" title="查找软件所依赖的so文件并安装依赖包"></a>查找软件所依赖的so文件并安装依赖包</h2><p>查看软件位置：<code>whereis typora</code><br><img src="https://rancho333.gitee.io/pictures/where.png"></p>
<p>查找软件依赖so：<code>ldd /usr/bin/typora</code><br><img src="https://rancho333.gitee.io/pictures/not_found.png"></p>
<p>对每一个标有<code>not found</code>的so文件执行如下：<br><img src="https://rancho333.gitee.io/pictures/search.png"></p>
<p>找到pkg名称后，使用<code>sudo apt-get install pkg-name</code>安装即可。</p>
]]></content>
      <categories>
        <category>Linux相关</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>so文件</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux科学上网记录</title>
    <url>/2019/09/06/Linux%E7%A7%91%E5%AD%A6%E4%B8%8A%E7%BD%91%E8%AE%B0%E5%BD%95/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>之前在AWS部署了自己的shadowsocks的服务端，这个比较简单，参见ss的<a href="https://github.com/shadowsocks/shadowsocks/tree/master">github</a>上面介绍就可以很容易的部署起来了，之后在windows上Android安装了对应的客户端，可以顺利科学上网，此处对这一部分就不多做说明了。最近做SONiC（哈，又是SONiC），编译过程中需要在google上下载一些资源，那么就需要在Linux服务器上翻墙，并且在docker中可以访问google。</p>
<span id="more"></span>

<h2 id="在linux上安装ss"><a href="#在linux上安装ss" class="headerlink" title="在linux上安装ss"></a>在linux上安装ss</h2><p>Linux环境是ubuntu 16.04 server，没有图形界面，纯命令行。<br>使用pip安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get update</span><br><span class="line">sudo apt-get install python-pip</span><br><span class="line">sudo apt-get install python-setuptools m2crypto</span><br><span class="line">pip install shadowsocks</span><br></pre></td></tr></table></figure>
<p>或者直接用apt安装</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install shadowsocks</span><br></pre></td></tr></table></figure>
<p>中间可能会提示需要安装一些依赖，按提示安装即可。</p>
<h2 id="启动ss"><a href="#启动ss" class="headerlink" title="启动ss"></a>启动ss</h2><p>ss的服务端和客户端的程序其实是同一个（找ss的客户端找了半天），只是启动的命令不一样。客户端是sslocal命令，服务端是ssserver命令。有兴趣的同学可以<code>sslocal --help</code>看一下，这是一个很好的习惯。</p>
<p>这里我们直接使用配置文件的方式启动客户端，配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;                                                                                                     </span><br><span class="line">    &quot;server&quot;:&quot;x.x.x.x&quot;,</span><br><span class="line">    &quot;server_port&quot;:443,</span><br><span class="line">    &quot;local_address&quot;:&quot;127.0.0.1&quot;,</span><br><span class="line">    &quot;local_port&quot;:1080,</span><br><span class="line">    &quot;password&quot;:&quot;xxxx123456&quot;,</span><br><span class="line">    &quot;timeout&quot;:300,</span><br><span class="line">    &quot;method&quot;:&quot;aes-256-cfb&quot;,</span><br><span class="line">    &quot;fast_open&quot;:false</span><br><span class="line">&#125;</span><br><span class="line">server  服务端vps的公网IP地址</span><br><span class="line">server_port     服务端的端口</span><br><span class="line">local_address   本地ip，一般localhost</span><br><span class="line">local_port      本地端口</span><br><span class="line">password        服务端密码</span><br><span class="line">timeout         超时时间，应和服务端一致</span><br><span class="line">method          加密方式，和服务端一致</span><br></pre></td></tr></table></figure>
<p>这里一定注意配置文件的信息，请参照服务端配置文件，之后可以启动客户端：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sslocal -c &#x2F;home&#x2F;mudao&#x2F;shadowsocks.json -d -start</span><br></pre></td></tr></table></figure>

<h2 id="配置privoxy代理"><a href="#配置privoxy代理" class="headerlink" title="配置privoxy代理"></a>配置privoxy代理</h2><p>ss是sock5代理，需要在local配置privoxy将http、https转换成sock5流量才能走到vps。</p>
<ul>
<li><p>安装privoxy</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt-get install privoxy</span><br></pre></td></tr></table></figure></li>
<li><p>配置privoxy</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vi &#x2F;etc&#x2F;privoxy&#x2F;config</span><br><span class="line">forward-socks5t &#x2F; 127.0.0.1:1080 .</span><br><span class="line">listen-address 127.0.0.1:8118</span><br><span class="line">确保这两行的存在</span><br></pre></td></tr></table></figure></li>
<li><p>启动privoxy</p>
<ul>
<li>开启privoxy服务<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo service privoxy start</span><br></pre></td></tr></table></figure></li>
<li>设置http和https全局代理<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export http_proxy&#x3D;&#39;http:&#x2F;&#x2F;localhost:8118&#39;</span><br><span class="line">export https_proxy&#x3D;&#39;https:&#x2F;&#x2F;localhost:8118&#39;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl cip.cc</span><br></pre></td></tr></table></figure>
<p>会显示出你配置文件中vps的地址：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">IP      : x.x.x.x</span><br><span class="line">地址    : 日本  东京都  东京</span><br><span class="line">运营商  : amazon.com</span><br><span class="line"></span><br><span class="line">数据二  : 美国 | Amazon数据中心</span><br><span class="line"></span><br><span class="line">数据三  : 日本东京都东京 | 亚马逊</span><br><span class="line"></span><br><span class="line">URL     : http:&#x2F;&#x2F;www.cip.cc&#x2F;x.x.x.x</span><br></pre></td></tr></table></figure></li>
</ul>
<p>然后再可以这样玩下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl &quot;http:&#x2F;&#x2F;pv.sohu.com&#x2F;cityjson?ie&#x3D;utf-8&quot;</span><br></pre></td></tr></table></figure>
<p>搜狐的这个接口可以返回你的IP地址</p>
<h2 id="配置PAC"><a href="#配置PAC" class="headerlink" title="配置PAC"></a>配置PAC</h2><p>很明显的，我们不想没被墙的网站也走代理，这时就需要PAC了。</p>
<ul>
<li><p>安装GFWList2Privoxy</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install --user gfwlist2privoxy</span><br></pre></td></tr></table></figure></li>
<li><p>获取gfwlist文件，生成actionsfile</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cd &#x2F;tmp</span><br><span class="line">wget https:&#x2F;&#x2F;raw.githubusercontent.com&#x2F;gfwlist&#x2F;gfwlist&#x2F;master&#x2F;gfwlist.txt</span><br><span class="line">~&#x2F;.local&#x2F;bin&#x2F;gfwlist2privoxy -i gfwlist.txt -f gfwlist.action -p 127.0.0.1:1080 -t socks5</span><br><span class="line">sudo cp gfwlist.action &#x2F;etc&#x2F;privoxy&#x2F;</span><br></pre></td></tr></table></figure>
<p>哈，可以在gfwlist.action中找一下google，很多，是不是。恩，大名鼎鼎的facebook，youtube，netflix都在里面哦，天朝的GFW将这些全部墙了。<br>如果访问某些国外网站速度慢的话（比如时常抽疯的github），就将它加到里面去吧！</p>
</li>
</ul>
<p>有了配置文件之后，在<code>/etc/privoxy/config</code>文件中加上<code>actionsfile gfwlist.action</code>就可以了</p>
<ul>
<li>重启Privoxy，测试代理是否走pac模式<ul>
<li>是否能google<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget www.google.com</span><br></pre></td></tr></table></figure></li>
<li>是否能pac(显示自己ip)<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl &quot;http:&#x2F;&#x2F;pv.sohu.com&#x2F;cityjson?ie&#x3D;utf-8&quot;</span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li>注意<br>如果还是显示代理服务器的IP，则把/etc/privoxy/config中的forward-socks5 / 127.0.0.1:1080 .这一行注释了，然后重启privoxy<br>如果不注释这行，所有的流量都走代理，我们刚才做的pac模式，它就不走了。</li>
</ul>
<h2 id="docker中使用代理流量"><a href="#docker中使用代理流量" class="headerlink" title="docker中使用代理流量"></a>docker中使用代理流量</h2><p>嗯嗯，我的初心是为了在docker中编译sonic，自然需要让docker也能科学上网了。<br>创建docker的配置文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">vim  ~&#x2F;.docker&#x2F;config.json</span><br><span class="line">&#123;                  </span><br><span class="line">&quot;proxies&quot;:</span><br><span class="line">&#123;</span><br><span class="line">   &quot;default&quot;:</span><br><span class="line">   &#123;</span><br><span class="line">     &quot;httpProxy&quot;: &quot;http:&#x2F;&#x2F;localhost:8118&quot;,</span><br><span class="line">     &quot;httpsProxy&quot;: &quot;http:&#x2F;&#x2F;localhost:8118&quot;,</span><br><span class="line">     &quot;noProxy&quot;: &quot;localhost&quot;</span><br><span class="line">   &#125;</span><br><span class="line">&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>或者使用<code>docker run -e &quot;http_proxy=http://localhost:8118&quot; -e &quot;https_proxy=http://localhost:8118&quot;</code></p>
<p>docker默认是bridge的网络模式，端口是需要做转发映射的。为了直接用宿主机的ip和端口，我们换成用host的网络模式，让她和宿主机可以用同一个Network Namespace<br>也就是使用<code>docker run -e &quot;http_proxy=http://localhost:8118&quot; -e &quot;https_proxy=http://localhost:8118&quot; --net host</code>来启动一个container</p>
<p>注意到上面<code>https_proxy</code>使用的代理和<code>http_proxy</code>是一样的，这是因为我在使用中发现有如下报错：<br><img src="https://rancho333.gitee.io/pictures/timeout.png"><br>更改完之后就好了，原理暂时不清楚，看机缘更新吧！</p>
<p>参考资料：</p>
<p><a href="https://huangweitong.com/229.html">Linux 使用 ShadowSocks + Privoxy 实现 PAC 代理</a></p>
<p><a href="https://blog.diosfun.com/2018/09/21/Ubuntu18-04%E5%AE%89%E8%A3%85shadowsocks%E5%AE%A2%E6%88%B7%E7%AB%AF/">Ubuntu18.04安装shadowsocks客户端</a></p>
<p><a href="https://kebingzao.com/2019/02/22/docker-container-proxy/">docker 容器内使用宿主机的代理配置</a></p>
]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>科学上网</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux系统移植简述</title>
    <url>/2020/03/16/Linux%E7%B3%BB%E7%BB%9F%E7%A7%BB%E6%A4%8D%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>之前也做过一些移植性的东西，不过都是别人搭好框架，自己填充一些模块，这次有机会完成系统级的移植，非常感谢张总以及胡老师的指点帮助，收获良多！</p>
<span id="more"></span>
<h1 id="移植总述"><a href="#移植总述" class="headerlink" title="移植总述"></a>移植总述</h1><p>嵌入式系统移植分为四个大块，分别是构建交叉编译工具，rootfs的制作，kernel的配置、编译、移植，BootLoader的移植。需要移植的系统可以在MIPS上跑起来，我只需要顺着原有的编译框架完成ARM64的编译，之后再上板子做具体的调试。</p>
<h2 id="构建交叉编译工具"><a href="#构建交叉编译工具" class="headerlink" title="构建交叉编译工具"></a>构建交叉编译工具</h2><p>toolchain一般芯片厂家会提供，当然自己通过buildroot构建也是可以的。<br>使用buildroot构建交叉编译工具，下载buildroot2015</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">wget http:&#x2F;&#x2F;buildroot.uclibc.org&#x2F;downloads&#x2F;buildroot-2015.08.tar.gz</span><br></pre></td></tr></table></figure>
<p><code>make menuconfig ARCH=arm64</code>配置buildroot，将target和toolchain两项配置成如下所示<br><img src="https://rancho333.gitee.io/pictures/buildroot.png"><br>之后<code>make</code>等待完成即可，buildroot有些源码下载速度很慢，下载网站也不尽相同，比较麻烦，不像Linux发行版可以改成国内镜像软件源，有的可能会等待比较长的时间。<br>将生成的toolchain打包，释放到服务器docker编译环境中，如下所示：<br><img src="https://rancho333.gitee.io/pictures/toolchain.png"><br>之后可以根据container构建image将编译环境发布出去，大家就可以直接使用了。</p>
<h2 id="kernel的配置、编译、移植"><a href="#kernel的配置、编译、移植" class="headerlink" title="kernel的配置、编译、移植"></a>kernel的配置、编译、移植</h2><p>kernel的配置结果保存在<code>.config</code>文件中，根据实际的需求会选配一些内核选项，如开启nat以及veth相关的配置<br><img src="https://rancho333.gitee.io/pictures/nat.png"><br><img src="https://rancho333.gitee.io/pictures/veth.png"><br>这些配置实际上是系统构建完成后跑起来报错才知道需要的，只需要在<code>make menuconfig</code>中搜索对应关键字即可找到编译选项。<br>关于内核编译的一些说明，可以参考这篇文章<br><a href="https://rancho333.gitee.io/2020/03/11/kernel%E7%BC%96%E8%AF%91%E7%AE%80%E8%BF%B0/">kernel编译简述</a></p>
<h2 id="rootfs的制作"><a href="#rootfs的制作" class="headerlink" title="rootfs的制作"></a>rootfs的制作</h2><p>在这一步其实花的时间是最多的，因为这里涉及到大量的上层应用模块的编译，然后这些模块的依赖库在交叉工具链中是不存在的，还有部分是需要编译一些独立的Linux命令。解决办法很简单，下载源码，编译出库，之后放到交叉工具链和文件系统中即可。<br>这里说下开源代码交叉编译的经典三部曲<code>configure, make, make install</code>，在configure中会指定交叉编译工具，编译生成文件的install路径,关于动态库的一些理解可以查看这篇文章<br><a href="https://rancho333.gitee.io/2020/02/26/%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E5%BA%93%E4%BB%A5%E5%8F%8Aconstructor%E5%B1%9E%E6%80%A7%E7%9A%84%E4%BD%BF%E7%94%A8/">关于动态库以及constructor属性的使用</a><br>嗯，rootfs以前一直用buildroot来制作，这里发现一个不一样的方式</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 使用mktemp命令创建一个临时文件</span><br><span class="line">2. 使用shell命令构建文件系统，就是echo命令然后重定向到临时文件</span><br><span class="line">3. 使用gen_init_cpio和压缩软件构建cpio格式的压缩包</span><br><span class="line">4. 删除临时文件</span><br></pre></td></tr></table></figure>
<p><img src="https://rancho333.gitee.io/pictures/rootfs.png"></p>
<h2 id="BootLoader的移植"><a href="#BootLoader的移植" class="headerlink" title="BootLoader的移植"></a>BootLoader的移植</h2><p>给的开发板上直接烧有uboot，所以这里不涉及自己构建bootloader了。在bring up的过程中遇到一个问题卡了很久：<br><img src="https://rancho333.gitee.io/pictures/panic.png"><br>返回错误8的含义<code>文件没有可执行权限</code>,确认过busybox的执行权限，并且是静态编译，并且可以在同平台的其它机器上执行。<br>真实的错误是kernel在rootfs中没有找到文件系统，比较详细的描述见上文提到的<code>kernel编译简述</code>。</p>
<p>参考资料：<br><a href="https://www.cnblogs.com/kernel-style/p/3397705.html">linux init启动分析</a></p>
]]></content>
      <tags>
        <tag>系统移植</tag>
      </tags>
  </entry>
  <entry>
    <title>Linux路由信息学习</title>
    <url>/2021/02/08/Linux%E8%B7%AF%E7%94%B1%E4%BF%A1%E6%81%AF%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p><code>route</code>命令用来查看Linux内核路由表。</p>
<span id="more"></span>

<h1 id="表项内容说明"><a href="#表项内容说明" class="headerlink" title="表项内容说明"></a>表项内容说明</h1><p><code>route</code>命令输出如下，使用<code>-n</code>选项表示不解析名字，可以加快信息输出速度。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Kernel IP routing table</span><br><span class="line">Destination     Gateway         Genmask         Flags Metric Ref    Use Iface</span><br><span class="line">default         10.204.112.1    0.0.0.0         UG    0      0        0 ens160</span><br><span class="line">10.10.30.0      *               255.255.255.0   U     0      0        0 ens192</span><br><span class="line">10.204.112.0    *               255.255.254.0   U     0      0        0 ens160</span><br><span class="line">link-local      *               255.255.0.0     U     1000   0        0 ens192</span><br><span class="line">172.17.0.0      *               255.255.0.0     U     0      0        0 docker0</span><br></pre></td></tr></table></figure>
<p>字段解释如下：<br>| 字段 | 说明 |<br>| :— | :— |<br>| Destination | 目标网段或主机 |<br>| Gateway | 网关地址， *或全0表示目标是本主机所属的网络，不需要路由 |<br>| Genmask | 网络掩码 |<br>| Flags | U:路由时活动的；H:目标是个主机；G:路由指向网关；R:恢复动态路由产生的表项；D:由路由的后台程序动态的安装；M:由路由的后台程序修改; !:拒绝路由 |<br>| Metric | 路由距离，到达指定网络所需要的中转数(linux内核中没有使用) |<br>| Ref | 路由项引用次数(linux内核中没有使用) |<br>| Use | 此路由项被路由软件查找的次数 |<br>| Iface | 该路由表项的输出接口 |</p>
<p>Linux上有三种路由类型：</p>
<ul>
<li>主机路由。路由表中指向单个IP地址或主机名的路由记录。主机路由的Flags字段为H。</li>
<li>网络路由。代表主机可以到达的网络。网络路由的Flags字段为N。</li>
<li>默认路由。当主机不能再路由表中查找到目标主机的IP地址或网络路由时，数据包就被发送到默认路由上。默认路由的Flags字段为G。</li>
</ul>
<p>对于一个物理网卡，Linux默认只支持一条默认路由。当然可以通过route命令手动添加多条默认路由，当重新启动网口时，会把其它默认路由去掉，只剩下一条该网口生成的默认路由。</p>
<h1 id="常用命令"><a href="#常用命令" class="headerlink" title="常用命令"></a>常用命令</h1><h2 id="添加或删除路由"><a href="#添加或删除路由" class="headerlink" title="添加或删除路由"></a>添加或删除路由</h2><p>route {add | del } [-net|-host] [网域或主机] netmask [mask] [gw|dev]</p>
<p>route add default gw 192.168.5.1</p>
<p>route add -net 10.204.0.0/16 eth0<br>route add -net 10.204.0.0/26 gw 10.204.123.1</p>
<h2 id="查询路由信息"><a href="#查询路由信息" class="headerlink" title="查询路由信息"></a>查询路由信息</h2><p>route -nee</p>
<p>ee选项表示详细信息</p>
]]></content>
      <tags>
        <tag>路由</tag>
      </tags>
  </entry>
  <entry>
    <title>Makefile学习</title>
    <url>/2019/08/26/Makefile%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>学软件的时候接触过一些makefile，但是之后的工作中一直没怎么用上。最近在做白盒交换机SONiC以及ONL的编译工作，里面用makefile和python完成整个工程的编译，有些宏大与震撼，关键很多地方看不懂哇。系统的学习一下，这里作为笔记，参考的是陈皓的《跟我一起写Makefile》。</p>
<span id="more"></span>
<h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><p>会不会写makefile从一个侧面说明一个人是否具备完成大型工程的能力。</p>
<p>makefile关系到了整个工程的编译规则。源文件（类型、功能、模块）放在若干目录，makefile是编译规则，指定那些文件需要先编译，后编译，重新编译。其中也可以执行操作系统的命令。</p>
<p>make是解释makefile中指令的命令工具。</p>
<h2 id="关于程序的编译与链接"><a href="#关于程序的编译与链接" class="headerlink" title="关于程序的编译与链接"></a>关于程序的编译与链接</h2><p>编译流程：预处理（.i），编译(.s)，汇编(.o)，链接(binary)。</p>
<p>编译时，编译器需要的是语法的正确，函数与变量的声明的正确（告诉头文件所在的位置，定义应该放在C文件中）。一般来说，每个源文件都应该对应于一个中间目标文件（.o文件）。如果函数未被声明，编译器可以生成Obiect File。</p>
<p>链接时，主要链接函数与全局变量。将中间目标文件链接成应用程序。中间目标文件太多，将其打包，windows下这种包叫“库文件”(library file)，也就是.lib文件，在UNIX下是Archive File,也就是.a文件。在Object File中寻找函数的实现，如果找不到，就报错。</p>
<h2 id="Makefile介绍"><a href="#Makefile介绍" class="headerlink" title="Makefile介绍"></a>Makefile介绍</h2><p>Makefile规则：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">target ... : prerequisites ...</span><br><span class="line">    command</span><br><span class="line">    ...</span><br><span class="line">    ...</span><br></pre></td></tr></table></figure>
<p>target是目标文件，可以是Object File，也可以是执行文件，还可以是一个标签（Lablel）。<br>prerequisites即依赖。<br>command是make需要执行的命令，任意shell命令。</p>
<p>Makefile中核心内容：<br><em><strong>prerequisites中如果有一个以上的文件必target文件要新（或者target不存在）的话，command所定义的命令就会被执行</strong></em></p>
<p>Makefile自动推导功能，对于[.o]文件，他会把[.c]文件自动加在依赖关系中，并且[command]gcc -c file.c也会被推导出来。</p>
<h2 id="Makefile总述"><a href="#Makefile总述" class="headerlink" title="Makefile总述"></a>Makefile总述</h2>]]></content>
  </entry>
  <entry>
    <title>Markdown学习笔记</title>
    <url>/2019/07/14/Markdown%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="Markdown学习笔记"><a href="#Markdown学习笔记" class="headerlink" title="Markdown学习笔记"></a>Markdown学习笔记</h1><p>最早接触Markdown(下面简称md)标记语言是在有道云笔记上，当时的学习计划就是用md写的,后来看到github上readme基本上<br>都是用md写的，到如今搭建自己的Blog,md做为主要的编写blog方式，花点时间系统学习一下md。</p>
<span id="more"></span>

<h2 id="Markdown简介"><a href="#Markdown简介" class="headerlink" title="Markdown简介"></a>Markdown简介</h2><p>md是一种轻量级的标记语言，md编写的文档可以导出HYML、Word、图像、PDF等多种格式的文档,md编写的文档后缀名为<br>.md，markdown。<br>md可以用来撰写电子书，帮助文档或在论坛上发表消息。例如：GitHub、简书。<br>个人理解，md就是比较简单的格式化文本语言。</p>
<h2 id="Markdown标题"><a href="#Markdown标题" class="headerlink" title="Markdown标题"></a>Markdown标题</h2><ol>
<li>使用=和-标记一级和二级标题  </li>
</ol>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">这是一级标题  </span><br><span class="line">&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;   </span><br><span class="line">这是二级标题   </span><br><span class="line">-----------  </span><br></pre></td></tr></table></figure>
<p>个人一般不习惯这种用法，一般采用#来标记标题<br>2. 使用#标记<br>使用#可以表示1-6级标题，一级标题对应一个#号，如下   </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 一级标题   </span><br><span class="line">## 二级标题   </span><br><span class="line">### 三级标题   </span><br><span class="line">#### 四级标题   </span><br><span class="line">##### 五级标题  </span><br><span class="line">###### 六级标题  </span><br></pre></td></tr></table></figure>

<p>显示效果就不在这里贴图了，自己敲敲看下效果，注意#后面与标题之间有个空格，空格这种基本分割语法在md里面要注意。    </p>
<h2 id="Markdown段落与换行"><a href="#Markdown段落与换行" class="headerlink" title="Markdown段落与换行"></a>Markdown段落与换行</h2><p>md的换行就是在行尾加上两个以上的空格，然后换行写其他文字，有的md编辑器可能只需要回车就可以（自动加上两个空格？）,我用的是Visual Studio Code,需要自己加。段落的前后必须都是空行，空行指的是行内什么都没有。  </p>
<h2 id="字体"><a href="#字体" class="headerlink" title="字体"></a>字体</h2><p>md支持以下几种字体  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">*斜体文本*  </span><br><span class="line">_斜体文本_</span><br><span class="line">**粗体文本**  </span><br><span class="line">__粗体文本__  </span><br><span class="line">***粗斜体文本***  </span><br><span class="line">___粗斜体文本___    </span><br></pre></td></tr></table></figure>
<p><em>斜体文本</em><br><em>斜体文本</em><br><strong>粗体文本</strong><br><strong>粗体文本</strong><br><em><strong>粗斜体文本</strong></em><br><em><strong>粗斜体文本</strong></em><br>建议采用*或_一种风格来书写，我使用*.  </p>
<h2 id="分割线"><a href="#分割线" class="headerlink" title="分割线"></a>分割线</h2><p>在一行中使用三个以上的星号、减号、底线来建立一个分割线，行内不能有其它东西，但可以在符号之间插入空格。建议采取一种写法就行，我采用***.  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">***  </span><br></pre></td></tr></table></figure>
<hr>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">---  </span><br><span class="line">___  </span><br></pre></td></tr></table></figure>
<p>效果一样。    </p>
<h2 id="删除线"><a href="#删除线" class="headerlink" title="删除线"></a>删除线</h2><p>在文字两端分别加上两个波浪线，如    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">~~Cassiopeia~~  </span><br></pre></td></tr></table></figure>
<p><del>Cassiopeia</del>  </p>
<h2 id="下划线"><a href="#下划线" class="headerlink" title="下划线"></a>下划线</h2><p>md和HTML语法兼容，可以通过HTML的标签来实现效果，如下：   </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;u&gt;下划线&lt;\u&gt;  </span><br></pre></td></tr></table></figure>
<p><u>下划线</u>  </p>
<h2 id="脚注"><a href="#脚注" class="headerlink" title="脚注"></a>脚注</h2><p>脚注是对文本的补充说明，格式如下：    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">需要添加脚注的文字 [^tag]。  </span><br><span class="line">[^tag]: Rancho is a handsome boy!  </span><br></pre></td></tr></table></figure>
<p>需要添加脚注的文字 [^tag]。<br>[^tag]: Rancho is a handsome boy!<br>这里脚注显示不成功，不知道原因，在有道云里面真诚。    </p>
<h2 id="Markdown列表"><a href="#Markdown列表" class="headerlink" title="Markdown列表"></a>Markdown列表</h2><p>无序列表使用*、+、-作为列表标记。<br>有序列表使用数字加.号来表示，如：    </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 第一项  </span><br><span class="line">2. 第二项  </span><br><span class="line">3. 第三项  </span><br></pre></td></tr></table></figure>
<p>注意.号后面的空格。    </p>
<ol>
<li>第一项    </li>
<li>第二项    </li>
<li>第三项    <h3 id="列表嵌套"><a href="#列表嵌套" class="headerlink" title="列表嵌套"></a>列表嵌套</h3>列表嵌套在子列表中的选项添加四个空格：  </li>
<li>第一项    <ol>
<li>嵌套1  </li>
<li>嵌套2  </li>
</ol>
</li>
<li>第二项  <ol>
<li>嵌套1  </li>
<li>嵌套2    <h2 id="Markdown区块"><a href="#Markdown区块" class="headerlink" title="Markdown区块"></a>Markdown区块</h2>在段落开头使用&gt;符号，后面加一个空格  <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&gt; 区块测试1  </span><br><span class="line">&gt;&gt; 区块测试2  </span><br><span class="line">&gt;&gt;&gt; 区块测试3  </span><br></pre></td></tr></table></figure>
<blockquote>
<p>区块测试1  </p>
<blockquote>
<p>区块测试2  </p>
<blockquote>
<p>区块测试3  </p>
</blockquote>
</blockquote>
</blockquote>
<h2 id="Markdown代码块"><a href="#Markdown代码块" class="headerlink" title="Markdown代码块"></a>Markdown代码块</h2>使用```包裹一段代码，并指定一种语言(也可以不指定)<br>对于单行的代码块，用`包裹即可，代码块中的数据不会被md语法所解释。  <h2 id="Markdown链接"><a href="#Markdown链接" class="headerlink" title="Markdown链接"></a>Markdown链接</h2>使用方法如下:    <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[链接名称](链接地址)    </span><br><span class="line">或者    </span><br><span class="line">&lt;链接地址&gt;  </span><br></pre></td></tr></table></figure>
如：<br>这是我的Blog <a href="https://rancho333.gitee.io/">Rancho</a>    <h2 id="Markdown图片"><a href="#Markdown图片" class="headerlink" title="Markdown图片"></a>Markdown图片</h2>使用方法如下:    <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">![](https:&#x2F;&#x2F;rancho333.gitee.io&#x2F;pictures&#x2F;Rancho.png)  </span><br></pre></td></tr></table></figure>
<img src="https://rancho333.gitee.io/pictures/Rancho.png"><br>md没法指定图片的高度与宽度，可以使用<code>&lt;image&gt;</code>标签  </li>
</ol>
</li>
</ol>
<p>使用资源文件夹后，将图片资源放置在对应的文章资源文件夹里面，可以通过：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#123;% asset_img image_name.png image_name %&#125;</span><br></pre></td></tr></table></figure>
<p>来调用图片资源</p>
<h2 id="Markdown表格"><a href="#Markdown表格" class="headerlink" title="Markdown表格"></a>Markdown表格</h2><p>md使用|来分隔不同的单元格，使用-来分隔表头和其它行。在减号的不同侧加入:代表方向对齐。  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">| 左对齐 | 右对齐 | 居中对齐 |  </span><br><span class="line">| :---- | ----: | :-----:  |  </span><br><span class="line">| 单元格 | 单元格 | 单元格 |  </span><br><span class="line">| 单元格 | 单元格 | 单元格 |  </span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th align="left">左对齐</th>
<th align="right">右对齐</th>
<th align="center">居中对齐</th>
</tr>
</thead>
<tbody><tr>
<td align="left">单元格</td>
<td align="right">单元格</td>
<td align="center">单元格</td>
</tr>
<tr>
<td align="left">单元格</td>
<td align="right">单元格</td>
<td align="center">单元格</td>
</tr>
</tbody></table>
<hr>
<h2 id="Markdoen高级技巧"><a href="#Markdoen高级技巧" class="headerlink" title="Markdoen高级技巧"></a>Markdoen高级技巧</h2><h3 id="支持HTML元素"><a href="#支持HTML元素" class="headerlink" title="支持HTML元素"></a>支持HTML元素</h3><p>不在md覆盖范围之内的标签，可以使用HTML的标签，如<code>&lt;kbd&gt; &lt;b&gt; &lt;i&gt; &lt;em&gt; &lt;sup&gt; &lt;sub&gt; &lt;br&gt;</code><br>使用<kbd>Ctrl</kbd>+<kbd>Alt<kbd>+<kbd>Del</kbd>重启电脑  </p>
<h3 id="转义"><a href="#转义" class="headerlink" title="转义"></a>转义</h3><p>md使用很多特殊符号表示特定的意义，如果需要显示这些特定的符号需要借助转义字符，即反斜杠.用代码块也能得到相同的效果。  </p>
<h3 id="公式"><a href="#公式" class="headerlink" title="公式"></a>公式</h3><p>数学不好，看着头疼，这里就不介绍了！^-^ </p>
<h2 id="自动生辰目录"><a href="#自动生辰目录" class="headerlink" title="自动生辰目录"></a>自动生辰目录</h2><p>linux上安装<code>doctoc</code>可以根据md的标题自动生成目录, 使用方法为<code>doctoc file.md</code></p>
<p><strong>参考资料：</strong><br><a href="https://www.runoob.com/markdown/md-tutorial.html">菜鸟教程</a> </p>
]]></content>
      <categories>
        <category>编程语言</category>
      </categories>
      <tags>
        <tag>Markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>OSPF学习</title>
    <url>/2021/04/19/OSPF%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>跟着上文<a href="https://rancho333.gitee.io/2021/04/08/SONiC%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE%E7%AE%80%E8%BF%B0/">SONiC路由协议简述</a>, 这篇文章记录一下OSPF协议的学习内容。</p>
<span id="more"></span>

<p>这篇文档应当回答以下几个问题。</p>
<ol>
<li>什么是Router ID? 有什么作用？</li>
<li>为什么要划分区域？为何需要骨干区域？怎样合理划分区域？</li>
<li>cost值有什么作用？</li>
<li>LSA描述的网络类型有哪些？</li>
<li>为什么要选举DR/BDR? 它们有什么作用？</li>
</ol>
<h2 id="OSPF概述"><a href="#OSPF概述" class="headerlink" title="OSPF概述"></a>OSPF概述</h2><p>TCP/IP协议中，寻找一台计算机到另一台计算的路由时很重要的，有以下几个考量：</p>
<ol>
<li>要判断是否能找到路由</li>
<li>找到路由后找一条最短的路（花费最小）</li>
<li>不能自环</li>
<li>能动态处理路由的变化</li>
</ol>
<p>OSPF(open shortest path first，开放最短路径优先)是一种基于链路状态的动态路由协议, 最新的RFC是2328，协议的基本思路如下：在AS中每一台运行OSPF的路由器收集<em>各自的接口/邻接信息</em>称为链路状态，通过Flooding算法在整个系统广播自己的链路状态，使得整个系统内部维护一个同步LSDB，根据这一数据库，路由器计算出以自己为根，其它网络节点为叶的一根最短路径树，从而计算出自己到达系统内部可达的最佳路由。</p>
<p>相较于RIP周期性的洪泛自己的路由表，无法了解网络的拓扑结构，只是通过路由更新以及简单的机制来学习路由(依照传闻的更新)， OSPF交互的是链路状态，每台OSPF路由器都知晓网络拓扑。</p>
<p>一句话说明ospf协议， ospf就是寻找去某个终点计算机的最短路径的方法。</p>
<h3 id="ospf协议基本特征"><a href="#ospf协议基本特征" class="headerlink" title="ospf协议基本特征"></a>ospf协议基本特征</h3><ul>
<li>适应范围 —— OSPF支持各种规模的网络，最多可以支持几百台路由器</li>
<li>快速收敛 —— 当网路拓扑结构发生变化，OSPF立即发送更新报文，使之在AS中同步</li>
<li>无自环 —— OSPF通过收集到的链路状态用最短路径树算法计算路由，从算法本身保证了不会生成自环路由</li>
<li>子网掩码 —— OSPF在描述路由时携带网段的掩码信息，所以OSPF协议不受自然掩码的限制，对VLSM支持的很好</li>
<li>区域划分 —— 允许AS的网络划分成区域来划分，区域间传送的路由信息被进一步抽象，从而减少了占用网络的带宽以及CPU的计算压力</li>
<li>等价路由 —— 支持到同一目的地址的多条等价路由，这些等价路由会被同时发现和使用</li>
<li>路由分级 —— OSPF使用4类不同的路由，按优先级：区域内路由、区域间路由、第一类外部路由、第二类外部路由</li>
<li>支持验证 —— 支持基于接口的报文验证以保证路由计算的安全性</li>
<li>组播发送 —— OSPF在有组播发送能力的链路层上以组播地址发送协议报文，既达到了广播的作用，又最大程度的减少了对其它网络设备的干扰</li>
</ul>
<h3 id="ospf相关术语"><a href="#ospf相关术语" class="headerlink" title="ospf相关术语"></a>ospf相关术语</h3><ul>
<li>RouterID 是一个32-bits的无符号整数，用于唯一标识AS内的一台路由器，OSPF直接基于IP，协议号是89,对于Router ID：<ul>
<li>Router ID一般需要手工配置</li>
<li>如果没有配置，首先选取最大的loopback接口地址，其次选择最大的物理接口地址</li>
<li>如果一台路由器的Router ID在运行中改变，则必须重启OSPF协议或重启路由器才能使新的Router ID生效</li>
</ul>
</li>
<li>Area区域 区域号是一个32bits的整数，一般用十进制整数来标识<br>  ospf引入区域的概念是为了隔离和区分AS内的各部分，并由此减少路由器必须维护的整个AS的信息量（CPU计算和线路传输）。OSPF使用Area实现了分层——两层模式，即transit area和regular areas。transit area(backbone 或 area 0)负责的主要功能是IP包快速和有效的传输，互联OSPF其它区域类型。一般情况下，regular area不允许其他区域的流量通过它到达另外一个区域，必须穿越transit area。regular areas还可有很多子类型，如stub area，not-so-stubby area。<ul>
<li>ABR(area border router) 连接不同的area，区域之间通过ABR将一个区域内的已计算出的路由封装成Type3类的LSA发送到另一个区域来传递路由信息。此时LSA中包含的不再是链路状态信息，而是纯粹的路由信息。或者说，此时的OSPF是基于D-V算法而不是链路状态算法。D-V算法无法保证消除路由自环，<em>自环产生的主要是</em>因为生成该条路由信息的路由器没有加入生成者的信息，即每一条路由信息都无法知道最初是由谁所生成。OSPF协议在生成LSA时首先将自己的Router ID加入到LSA中，但是如果该路由信息传递超过两个区域后，就会丧失最初的生成者信息。<br>  解决方法是：所有ABR将本区域内的路由信息封装成LSA，统一的发送给一个特定的区域，再由该区域将这些信息转发给其它区域。在这个特定区域内，每一条LSA都确定的知道生成者信息。在其它区域内所有的到区域外的路由都会发送到这个特定区域中，所以就不会产生自环。</li>
<li>ASBR(autonomous system border router)：一个OSPF路由器，但它连接到另一个AS，或者在同一个AS的网络区域中，但运行不同于OSPF的IGP </li>
</ul>
</li>
<li>cost值 OSPF选择路径是依靠整个链路cost值的总和。计算方法是：10^8/链路带宽。越小优先级越高。缺省情况下，接口按照当前的波特率自动计算接口运行OSPF协议所需的开销。</li>
<li>DR/BDR：如果网络上有N台路由器，需要建立n*(n-1)/2个邻接关系，使用DR(designated router)来进行信息传递，所有路由器都只将路由信息发送给DR和BDR，再由DR将路由信息发送给本网段内其它路由器，这样只需要建立(n-2)*2+1个邻接关系。通过hello报文进行选举，priority大于0的进行选举，priority一样，router ID大的当选。DR不可被抢占，除非失效，失效后BDR接替成为DR，同时选举出新的BDR。DR是某个网段中概念，是针对路由器的接口而言的。两台DROther路由器之间不进行路由信息的交换，但仍互相发送HELLO报文，他们之间的邻居状态机停留在2-Way状态。</li>
</ul>
<h3 id="OSPF网络类型"><a href="#OSPF网络类型" class="headerlink" title="OSPF网络类型"></a>OSPF网络类型</h3><p>根据链路层协议类型，OSPF将网络分为四种类型：</p>
<ol>
<li>broadcast：链路层协议是Ethernet、FDDI、Token Ring,以组播的方式发送协议报文，选举DR/BDR.</li>
<li>NBMA(Non broadcast multiaccess):链路层协议是FR、ATM、HDLC或X.25。手工指定邻居。</li>
<li>p2p(point-to-point)：链路层协议是PPP或LAPB</li>
<li>p2mp(point-to-multipoint):没有一种链路层协议会被缺省的认为是p2mp类型，p2mp必然是由其它网络类型强制更改的，常见的做法是将非全联通的NBMA改为点到多点的网络。<br>由于现在链路层协议一般就是Ethernet，所以其它类型只做一个简单了解。</li>
</ol>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p><a href="http://www.h3c.com/cn/d_200805/605874_30003_0.htm">OSPF技术介绍</a><br><a href="http://ccietea.com/Folder_TechNotes/OSPF.pdf">OSPF笔记</a></p>
]]></content>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC中ARP测试用例简析</title>
    <url>/2021/04/26/SONiC%E4%B8%ADARP%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本文简要分析SONiC testbed中ARP测试用例的实现，作为对<a href="https://rancho333.gitee.io/2020/12/25/ARP%E5%8D%8F%E8%AE%AE%E7%AE%80%E8%BF%B0%E5%8F%8A%E5%BA%94%E7%94%A8/">ARP协议简述及应用</a>的补充。</p>
<span id="more"></span>
<h2 id="背景知识简述"><a href="#背景知识简述" class="headerlink" title="背景知识简述"></a>背景知识简述</h2><p>ARP直接基于以太帧进行封装，<code>type</code>类型为<code>0x0806</code>，报文很简单，只有两类：ARP request报文和ARP reply报文。其中request报文可分为三类：<br>    1. 单播request，参考rfc1122，一种arp缓存刷新机制<br>    2. 广播request，这也是常见的arp请求报文<br>    3. 免费arp报文，sender ip和destination ip相同</p>
<h2 id="测试用例简析"><a href="#测试用例简析" class="headerlink" title="测试用例简析"></a>测试用例简析</h2><p>在<code>sonic-mgmt/tests/arp</code>下共有4个测试文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test_arpall.py</span><br><span class="line">test_neighbor_mac_noptf.py</span><br><span class="line">test_neighbor_mac.py</span><br><span class="line">test_wr_arp.py</span><br></pre></td></tr></table></figure>
<p>本文会分析<code>test_arpall.py</code>文件，对于其它三个文件会简要说明一下，最后对测试失败的<code>test_wr_arp.py</code>做一个分析。</p>
<p><code>test_arpall.py</code>中设计了5种测试用例：</p>
<ol>
<li>发送单播arp request</li>
<li>发送广播arp request</li>
<li>发送不同网段的arp request(sender ip字段异常)</li>
<li>免费arp测试</li>
</ol>
<h3 id="单播arp-request测试"><a href="#单播arp-request测试" class="headerlink" title="单播arp request测试"></a>单播arp request测试</h3><p>测试代码在<code>sonic-mgmt/tests/arp/test_arpall.py</code>文件中，对该模块代码截取简析如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/arp_unicast_reply.png"></p>
<p>报文构造代码在<code>sonic-mgmt/ansible/roles/test/files/ptftests/arptest.py</code>文件中，对应的ARP包构造函数内容如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/verifyunicastarpreply.png"></p>
<p>基本流程就是构造单播arp request报文，之后获取dut的arp表，看发送arp request的端口arp条目是否存在。根据rfc1122，这是unicast poo(单播轮询)：定时向ARP缓存条目中的主机发送点到点的ARP请求报文，假如在N次连续超时时间过后，没有收到对应主机的ARP响应报文，则将此条目从ARP缓存中删除。</p>
<p>其实这样测试并不能测试出unicast poll的定义，和普通ARP 请求没啥区别。</p>
<h3 id="广播arp-request测试"><a href="#广播arp-request测试" class="headerlink" title="广播arp request测试"></a>广播arp request测试</h3><p>测试代码如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/arp_expect_reply.png"></p>
<p>对应的ARP包构造函数内容如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/expectreply.png"></p>
<p>如上面的分析，和单播arp请求没啥区别，虽然ser intf1的mac改了一下，但无关紧要。</p>
<h3 id="收到的arp报文请求的不是本接口mac"><a href="#收到的arp报文请求的不是本接口mac" class="headerlink" title="收到的arp报文请求的不是本接口mac"></a>收到的arp报文请求的不是本接口mac</h3><p>测试代码如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/arp_no_reply_other_intf.png"><br>这里asset判断的ip错了，应该是不等于10.10.1.22才对。</p>
<p>对应的ARP包构造函数内容如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/srcoutrangenoreply.png"></p>
<h3 id="收到的arp请求中的sender-ip与本接口不在同一网段"><a href="#收到的arp请求中的sender-ip与本接口不在同一网段" class="headerlink" title="收到的arp请求中的sender ip与本接口不在同一网段"></a>收到的arp请求中的sender ip与本接口不在同一网段</h3><p>和上面<code>收到的arp报文请求的不是本接口mac</code>的流程基本一致，只是将相同的arp request报文发给dut intf1。</p>
<h3 id="免费arp报文测试"><a href="#免费arp报文测试" class="headerlink" title="免费arp报文测试"></a>免费arp报文测试</h3><p>免费arp的测试分为两块，如果免费arp中的信息之前没有解析过，那么不应该响应免费arp报文，反之响应。</p>
<p>不响应的代码如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/garp_no_update.png"></p>
<p>对应的ARP包构造函数内容如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/garpnoupdate.png"></p>
<p>此时即使dut收到了免费arp报文，但是<code>10.10.1.7</code>的信息并不在dut的arp表中，所以不应该有响应动作。</p>
<p>响应的代码如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/garp_update.png"><br>可以看到先调用<code>ExpectReply</code>让<code>10.10.1.3</code>存在于dut的arp表中，之后再调用<code>GarpUpdate</code>更新mac，MAC地址由<code>00:06:07:08:09:0a</code>更新为<code>00:00:07:08:09:0a</code>。</p>
<p>对应的ARP包构造函数内容如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/garpupdate.png"><br>这里面修改了<code>10.10.1.3</code>对应的MAC地址。</p>
<h2 id="其它三个测试文件说明"><a href="#其它三个测试文件说明" class="headerlink" title="其它三个测试文件说明"></a>其它三个测试文件说明</h2><p>对于<code>test_neighbor_mac_noptf.py</code>，ptf作为dut的邻居，针对ipv4和ipv6两种场景，分别测试在DUT的redis中和arp表中能不能找到另据的arp entry。<br>对于<code>test_neighbor_mac.py</code>，ptf作为dut的邻居，使用相同的ip(ipv4)，映射两个不同的mac地址，分别测试这两个mac在redis中存不存在。<br>对于<code>test_wr_arp.py</code>测试热重启过程中的arp功能，首先在ptf上开启ferret server，之后让dut进入warm-reboot，在此过程中，ptf发送arp request，25秒内没有收到arp reply测试失败。</p>
<h2 id="测试结果说明"><a href="#测试结果说明" class="headerlink" title="测试结果说明"></a>测试结果说明</h2><p>以<code>10.204.112.27:8080</code>上的<code>seastone-t0</code>为例说明，测试结果如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/testbed_wrarp_seastone.png"></p>
<p>可以看到<code>test_wr_arp.py</code>测试失败了，结果不符合预期。wr_arp首先在ptf host上开启ferret服务，之后在dut上启动warm-reboot程序，当dut处于warm-reboot阶段时，向其vlan成员发送arp请求报文，25秒内任一vlan成没有响应则测试失败。</p>
<p>而在<code>seastone2-t0</code>上面，该项测试失败，但是原因不一样：</p>
<p><img src="https://rancho333.gitee.io/pictures/testbed_wrarp_seastone2.png"><br>此处是没有获取到ptf宣告的ip，这个网段应该由zebra下发到kernel，src字段为dut的loopback。</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC中OSPF使用简述</title>
    <url>/2021/04/23/SONiC%E4%B8%ADOSPF%E4%BD%BF%E7%94%A8%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>承接上文<a href="https://rancho333.gitee.io/2021/04/08/SONiC%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE%E7%AE%80%E8%BF%B0/">SONiC路由协议简述</a>，这边文章记录SONiC上使能OSPF的过程。</p>
<span id="more"></span>
<h2 id="实验过程"><a href="#实验过程" class="headerlink" title="实验过程"></a>实验过程</h2><h3 id="拓扑说明"><a href="#拓扑说明" class="headerlink" title="拓扑说明"></a>拓扑说明</h3><p>拓扑图如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/ospf-topology.png"></p>
<p>实验预期：</p>
<ol>
<li>三台设备上能建立ospf邻居，完成LSDB交换，建立ospf路由</li>
<li><code>192.168.1.2</code>能够<code>ping</code>通<code>192.168.2.2</code></li>
</ol>
<h3 id="启动OSPF"><a href="#启动OSPF" class="headerlink" title="启动OSPF"></a>启动OSPF</h3><p>在<code>bgp</code>容器中启动<code>ospf</code>进程：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;usr&#x2F;lib&#x2F;frr&#x2F;ospfd -A 127.0.0.1 -d</span><br></pre></td></tr></table></figure>
<p>参照<code>bgpd</code>的启动过程，将ospf添加到supervisor中，并指定配置文件，在<code>/etc/supervisor/conf.d/supervisord.conf</code>中添加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[program:ospfd]</span><br><span class="line">command&#x3D;&#x2F;usr&#x2F;lib&#x2F;frr&#x2F;ospfd -A 127.0.0.1 -f &#x2F;etc&#x2F;frr&#x2F;ospfd.conf</span><br><span class="line">priority&#x3D;5</span><br><span class="line">stopsignal&#x3D;KILL</span><br><span class="line">autostart&#x3D;false</span><br><span class="line">autorestart&#x3D;false</span><br><span class="line">startsecs&#x3D;0</span><br><span class="line">stdout_logfile&#x3D;syslog</span><br><span class="line">stderr_logfile&#x3D;syslog</span><br></pre></td></tr></table></figure>
<p>在<code>/usr/bin/start.sh</code>中添加：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">supervisorctl start ospfd</span><br></pre></td></tr></table></figure>
<p>创建ospf配置文件<code>/etc/frr/ospfd.conf</code>, 根据具体业务添加配置内容：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">frr version 7.2.1-sonic</span><br><span class="line">frr defaults traditional</span><br><span class="line">hostname lambda</span><br><span class="line">router ospf</span><br><span class="line"> network 192.168.1.0&#x2F;24 area 0</span><br></pre></td></tr></table></figure>

<h3 id="配置接口IP"><a href="#配置接口IP" class="headerlink" title="配置接口IP"></a>配置接口IP</h3><p>在SONiC命令行中可配置接口ip，命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">config interface ip add 192.168.2.1&#x2F;24</span><br></pre></td></tr></table></figure>
<p>zebra会通过netlink获取接口配置，反之在vty中配置接口ip不能同步到sonic。也可将配置写到配置文件中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&quot;INTERFACE&quot;: &#123;              </span><br><span class="line">        &quot;Ethernet1|192.168.1.1&#x2F;24&quot;: &#123;&#125;,</span><br><span class="line">        &quot;Ethernet2|192.168.2.1&#x2F;24&quot;: &#123;&#125;                                                                                                                                                                                                                                                                               </span><br><span class="line">    &#125;,      </span><br></pre></td></tr></table></figure>

<p>配置完成之后，在vty中可以看到使能了ospf的接口：</p>
<p><img src="https://rancho333.gitee.io/pictures/ospf-interface.png"></p>
<p>注意将接口的mtu配置成1500或者在ospf中关闭mtu check。</p>
<h3 id="配置ASIC"><a href="#配置ASIC" class="headerlink" title="配置ASIC"></a>配置ASIC</h3><p>SONiC中默认ospf报文不送CPU，这可能和各家的SDK初始化实现有关。在broadcom下我们需要做一些配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">fp qset add ipprotocol</span><br><span class="line">fp group create 20 21				    (20是优先级， 21是group-id)</span><br><span class="line">fp entry create 21 3000				    （3000是entry-id，这是一个全局的值，注意不能重叠）</span><br><span class="line">fp qual  3000 ipprotocol 89 0xffff		(指定copy-to-cpu的协议特征)</span><br><span class="line">fp action add 3000 CopyToCpu 0 0		（对匹配到特征的协议指定动作）</span><br><span class="line">fp entry install 3000					（使能配置）</span><br><span class="line">fp show entry 3000                        （验证配置）</span><br></pre></td></tr></table></figure>
<p>应当在ASIC中看到使能的配置：</p>
<p><img src="https://rancho333.gitee.io/pictures/ospf-asic.png"></p>
<p>sonic中提供了copp功能配置sdk下发这些报文上CPU等的控制操作，受当前实验版本限制暂不做这方面深入研究。</p>
<h3 id="功能验证"><a href="#功能验证" class="headerlink" title="功能验证"></a>功能验证</h3><p>查看邻居状态：</p>
<p><img src="https://rancho333.gitee.io/pictures/ospf-neighbour.png"></p>
<p>查看数据库信息：</p>
<p><img src="https://rancho333.gitee.io/pictures/ospf-database.png"></p>
<p>查看路由表：</p>
<p><img src="https://rancho333.gitee.io/pictures/ospf-route.png"></p>
<p>ping测试：</p>
<p><img src="https://rancho333.gitee.io/pictures/ospf-ping.png"></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>当前SONiC上ospf功能使能需要做三方面的配置：</p>
<ol>
<li>ospf自身，包括功能启用以及协议参数配置</li>
<li>启用ospf协议的接口</li>
<li>配置ASIC，协议报文上CPU</li>
</ol>
]]></content>
      <tags>
        <tag>通信协议</tag>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC启动简述</title>
    <url>/2021/01/29/SONiC%E5%90%AF%E5%8A%A8%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>sonic在初始化的时候是怎样识别platform的，<br>/host/machine.conf<br>/etc/sonic/config_db.json</p>
<span id="more"></span>
<p>/etc/rc.local</p>
<h2 id="platform相关"><a href="#platform相关" class="headerlink" title="platform相关"></a>platform相关</h2><p>在<code>device_info.py</code>中会通过读取<code>/host/machine.conf</code>配置文件来获取platform的名称</p>
<h2 id="hwsku相关"><a href="#hwsku相关" class="headerlink" title="hwsku相关"></a>hwsku相关</h2><p>在<code>device_info.py</code>中会通过读取ConfigDB来获取hwsku, 如果在<code>show version</code>中没有看到hwsku，那么需要配置config_db.json配置文件来加载配置信息，重启后生效。</p>
<h2 id="chassis相关"><a href="#chassis相关" class="headerlink" title="chassis相关"></a>chassis相关</h2><p>以pmon的docker的psud为例，先获取<code>platform_chassis</code>，对于chassis的初始化，关注platform_base.py、platform.py以及chassis.py这三个文件，其中chassis.py中完成chassis的实例化，一般包括syseeprom、watchdog、fan、thermal、psu、sfp、component。</p>
<p>chassis.py是厂商的sonic_platform包里面提供的文件，pmon的docker创建的时候会根据platform挂载对应的sonic_platform包，所以能保证加载正确的板子的外设。</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC添加新的device</title>
    <url>/2020/12/31/SONiC%E6%B7%BB%E5%8A%A0%E6%96%B0%E7%9A%84device/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>SONiC项目中，有时候厂商需要添加自己新的device上去。</p>
<ol>
<li>需要添加那些东西？</li>
<li>怎么编译进文件系统？<span id="more"></span></li>
<li>SONiC启动时是如何选择对应设备的文件？</li>
</ol>
<p>搞清楚这三个问题后，我们就可以对device进行裁剪（SONiC默认会将device目录下所有文件拷贝进文件系统）。</p>
<h1 id="目录结构及添加内容"><a href="#目录结构及添加内容" class="headerlink" title="目录结构及添加内容"></a>目录结构及添加内容</h1><p>与设备硬件耦合的文件夹有两个，分别是<code>platform</code>与<code>device</code>，<code>platform</code>描述ASIC，厂商设备驱动代码以及new platform API的适配；<code>device</code>描述厂商设备代码，其中包括端口配置，led配置，sai配置等信息，<code>plugins</code>文件夹是一些外设命令适配的python代码。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sonic-buildimage&#x2F;</span><br><span class="line">    platform&#x2F;            # asic相关，重点关注sai以及sonic-platform.bin</span><br><span class="line">        broadcom&#x2F;        </span><br><span class="line">    device              # 设备相关，对设备硬件特性的控制描述，如端口，led，console；以及和硬件相关的命令的底层适配接口，如填入eeprom的地址，之后使用SONiC的解析器进行解析。对于SONiC的命令体系，可以再写一篇文档</span><br><span class="line">        celestica&#x2F;</span><br></pre></td></tr></table></figure>

<p>在<code>platform</code>中有个<code>sonic-platform</code>的文件夹，这里面包含了eeprom、fan、psu等外设相关的文件，与<code>device</code>里面的文件实际上是有重复的，这可能是SONiC的历史遗留问题，在字节项目中有讨论过后续会将外设相关的处理全部放到<code>platform</code>中去。</p>
<p>对于端口适配这些内容不熟悉，在此只做简单介绍。</p>
<h1 id="编译相关"><a href="#编译相关" class="headerlink" title="编译相关"></a>编译相关</h1><h2 id="device的编译"><a href="#device的编译" class="headerlink" title="device的编译"></a>device的编译</h2><p><code>device</code>中的数据会打包到<code>sonic-device-data_1.0-1_all.deb</code>, 具体是在<code>src/sonic-device-data/Makefile</code>实现文件拷贝然后打包成deb</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$(addprefix $(DEST)&#x2F;, $(MAIN_TARGET)): $(DEST)&#x2F;% :                                       </span><br><span class="line">    pushd .&#x2F;src                     </span><br><span class="line">                                    </span><br><span class="line">    # Remove any stale data         </span><br><span class="line">    rm -rf .&#x2F;device                 </span><br><span class="line">                                    </span><br><span class="line">    # Create a new dir and copy all ONIE-platform-string-named dirs into it              </span><br><span class="line">    mkdir .&#x2F;device                  </span><br><span class="line">    cp -r -L ..&#x2F;..&#x2F;..&#x2F;device&#x2F;*&#x2F;* .&#x2F;device&#x2F;                                               </span><br><span class="line">                                    </span><br><span class="line">    # Create hwsku for virtual switch</span><br><span class="line">    for d in &#96;find -L ..&#x2F;..&#x2F;..&#x2F;device -maxdepth 3 -mindepth 3 -type d | grep -vE &quot;(plugins|led-code)&quot;&#96;; do \</span><br><span class="line">        cp -Lr $$d device&#x2F;x86_64-kvm_x86_64-r0&#x2F; ; \                                      </span><br><span class="line">        cp .&#x2F;sai.vs_profile device&#x2F;x86_64-kvm_x86_64-r0&#x2F;$$(basename $$d)&#x2F;sai.profile; \  </span><br><span class="line">        grep -v ^# device&#x2F;x86_64-kvm_x86_64-r0&#x2F;$$(basename $$d)&#x2F;port_config.ini | awk &#39;&#123;i&#x3D;i+1;print &quot;eth&quot;i&quot;:&quot;$$2&#125;&#39; &gt; device&#x2F;x86_64-kvm_x86_64-r0&#x2F;$$(basename $$d)&#x2F;lanemap.ini</span><br><span class="line">    done;                           </span><br><span class="line">                                    </span><br><span class="line">    # Build the package                                                                                                                                       </span><br><span class="line">    dpkg-buildpackage -rfakeroot -b -us -uc</span><br></pre></td></tr></table></figure>
<p>在<code>src/sonic-device-data/src/Makefile</code>中有config和media的测试</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test:</span><br><span class="line">    # Execute Broadcom config file test</span><br><span class="line">    pushd ..&#x2F;tests&#x2F;</span><br><span class="line">    for f in $$(find ..&#x2F;..&#x2F;..&#x2F;device -name &quot;*.config.bcm&quot;); do</span><br><span class="line">        .&#x2F;config_checker $$f</span><br><span class="line">    done</span><br><span class="line">    for f in $$(find ..&#x2F;..&#x2F;..&#x2F;device -name media_settings.json); do                                                                                           </span><br><span class="line">        .&#x2F;media_checker $$f</span><br><span class="line">    done</span><br><span class="line">    popd</span><br></pre></td></tr></table></figure>
<p>使用<code>dpkg -X target/debs/stretch/sonic-device-data_1.0-1_all.deb</code>或者在<code>fsroot/usr/share/sonic/device/</code>目录下可以发现<code>device</code>相关的文件。这些文件与设备目录上<code>/usr/share/sonic/device/</code>的文件相对应。<br>在<code>sonic_debian_extension.sh</code>脚本中会将其释放到根文件系统中去。<br><img src="https://rancho333.gitee.io/pictures/device_data.png"><br>注意，在slave.mk中操作一下才能看到脚本，否则它做为中间文件，编译完成后会被自动删除。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-       $(if $($*_DOCKERS),</span><br><span class="line">-               rm sonic_debian_extension.sh,</span><br><span class="line">-       )</span><br><span class="line">+#      $(if $($*_DOCKERS),</span><br><span class="line">+#              rm sonic_debian_extension.sh,</span><br><span class="line">+#      )</span><br><span class="line"> </span><br><span class="line">        chmod a+x $@</span><br><span class="line">        $(FOOTER)</span><br></pre></td></tr></table></figure>

<p>对于porting而言，可以修改Makefile中cmd的规则，只拷贝需要的device和只进行与之对应的test。</p>
<h2 id="platform的编译"><a href="#platform的编译" class="headerlink" title="platform的编译"></a>platform的编译</h2><p><code>slave.mk</code>是SONiC项目真正的Makefile，所有的编译规则在里面可以找到，<code>platform</code>的入口在：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ifneq ($(CONFIGURED_PLATFORM), undefined)</span><br><span class="line">include $(PLATFORM_PATH)&#x2F;rules.mk</span><br><span class="line">endif </span><br></pre></td></tr></table></figure>
<p>我们在执行<code>make configure PLATFORM=platform</code>时会指定platform，从而找到对应的rules.mk。</p>
<p><img src="https://rancho333.gitee.io/pictures/rules_mk.png"></p>
<p>这里面关注三个文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sai.mk                          # 指定SAI版本以及下载路径</span><br><span class="line">platform-modules-device.mk      # 指定设备platform源文件路径，编译打包成debian</span><br><span class="line">one-image.mk                    # 指定SONiC系统安装镜像名称</span><br></pre></td></tr></table></figure>
<p>sai由ASIC厂商维护，作为设备厂商，我们直接使用即可。Makefile中通过指定url在编译时下载指定版本sai，对于此类重要的模块文件，可以将之缓存到本地，指定本地url进行使用。</p>
<p>对于设备厂商的platform，通过在<code>rules.mk</code>中增删 <em><strong>platform-modules-device.mk</strong></em> 可以实现在文件系统中添加或删除设备厂商platform的<code>device</code>模块</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">diff --git a&#x2F;platform&#x2F;broadcom&#x2F;rules.mk b&#x2F;platform&#x2F;broadcom&#x2F;rules.mk</span><br><span class="line">index 8dd7b2c8..91e3afd3 100644</span><br><span class="line">--- a&#x2F;platform&#x2F;broadcom&#x2F;rules.mk</span><br><span class="line">+++ b&#x2F;platform&#x2F;broadcom&#x2F;rules.mk</span><br><span class="line">@@ -1,7 +1,7 @@</span><br><span class="line"> include $(PLATFORM_PATH)&#x2F;sai-modules.mk</span><br><span class="line"> include $(PLATFORM_PATH)&#x2F;sai.mk</span><br><span class="line">-include $(PLATFORM_PATH)&#x2F;platform-modules-dell.mk</span><br><span class="line">-include $(PLATFORM_PATH)&#x2F;platform-modules-arista.mk</span><br><span class="line">+#include $(PLATFORM_PATH)&#x2F;platform-modules-dell.mk</span><br><span class="line">+#include $(PLATFORM_PATH)&#x2F;platform-modules-arista.mk</span><br><span class="line"> include $(PLATFORM_PATH)&#x2F;platform-modules-ingrasys.mk</span><br></pre></td></tr></table></figure>

<p>通过在<code>one-image.mk</code>中增删<code>**_PLATFORM_MODULE</code>可以选择将在<code>platform-modules-device.mk</code>中编译好的对应机型的deb包拷贝到文件系统中。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">diff --git a&#x2F;platform&#x2F;broadcom&#x2F;one-image.mk b&#x2F;platform&#x2F;broadcom&#x2F;one-image.mk</span><br><span class="line">index 8cbf7269..edc51460 100644</span><br><span class="line">--- a&#x2F;platform&#x2F;broadcom&#x2F;one-image.mk</span><br><span class="line">+++ b&#x2F;platform&#x2F;broadcom&#x2F;one-image.mk</span><br><span class="line">@@ -54,8 +54,8 @@ $(SONIC_ONE_IMAGE)_LAZY_INSTALLS +&#x3D; $(DELL_S6000_PLATFORM_MODULE) \</span><br><span class="line">                                $(ALPHANETWORKS_SNH60B0_640F_PLATFORM_MODULE) \</span><br><span class="line">                                $(BRCM_XLR_GTS_PLATFORM_MODULE) \</span><br><span class="line">                                $(DELTA_AG9032V2A_PLATFORM_MODULE) \</span><br><span class="line">-                               $(JUNIPER_QFX5210_PLATFORM_MODULE) \</span><br><span class="line">-                               $(CEL_SILVERSTONE_PLATFORM_MODULE)</span><br><span class="line">+                               #$(JUNIPER_QFX5210_PLATFORM_MODULE) \</span><br><span class="line">+                               #$(CEL_SILVERSTONE_PLATFORM_MODULE)</span><br></pre></td></tr></table></figure>

<p>对于打包好的platform文件，会在<code>sonic_debian_extension.sh</code>中拷贝到文件系统中去<br><img src="https://rancho333.gitee.io/pictures/platform_module.png"></p>
<p>上面这张图片上就是裁剪过后只会拷贝<code>cel-b3010</code>这一款机型的platform。有兴趣的同学可以研究下是如何实现的。</p>
<p>在SONiC的安装镜像第一次启动时，会在<code>rc.local</code>中将其释放到文件系统中去.<br><img src="https://rancho333.gitee.io/pictures/platform_module_2.png"></p>
<p>对于<code>platform-modules-*_amd64.deb</code>，里面包含了device的驱动，会在systemd中添加服务完成驱动的加载。这个deb的生成规则参见<code>platform/broadcom/sonic-platform-modules-cel/debian/</code>，主要修改如下几个文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">rules</span><br><span class="line">control</span><br></pre></td></tr></table></figure>
<p>以及添加</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">platform-modules-ivystone.init</span><br><span class="line">platform-modules-ivystone.install</span><br><span class="line">platform-modules-ivystone.postinst</span><br></pre></td></tr></table></figure>

<p>注意编译<code>platform-modules-*_amd64.deb</code>的规则：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">CEL_DX010_PLATFORM_MODULE &#x3D; platform-modules-dx010_$(CEL_DX010_PLATFORM_MODULE_VERSION)_amd64.deb</span><br><span class="line">$(CEL_DX010_PLATFORM_MODULE)_SRC_PATH &#x3D; $(PLATFORM_PATH)&#x2F;sonic-platform-modules-cel</span><br><span class="line">$(CEL_DX010_PLATFORM_MODULE)_DEPENDS +&#x3D; $(LINUX_HEADERS) $(LINUX_HEADERS_COMMON)</span><br><span class="line">$(CEL_DX010_PLATFORM_MODULE)_PLATFORM &#x3D; x86_64-cel_seastone-r0</span><br><span class="line">SONIC_DPKG_DEBS +&#x3D; $(CEL_DX010_PLATFORM_MODULE)</span><br><span class="line">           </span><br><span class="line">CEL_HALIBURTON_PLATFORM_MODULE &#x3D; platform-modules-haliburton_$(CEL_HALIBURTON_PLATFORM_MODULE_VERSION)_amd64.deb</span><br><span class="line">$(CEL_HALIBURTON_PLATFORM_MODULE)_PLATFORM &#x3D; x86_64-cel_e1031-r0</span><br><span class="line">$(eval $(call add_extra_package,$(CEL_DX010_PLATFORM_MODULE),$(CEL_HALIBURTON_PLATFORM_MODULE)))</span><br></pre></td></tr></table></figure>
<p>在slave.mk中会有编译SONIC_DPKG_DEBS的命令，只有CEL_DX010_PLATFORM_MODULE是显示的添加到SONIC_DPKG_DEBS</p>
<h1 id="SONiC启动简述"><a href="#SONiC启动简述" class="headerlink" title="SONiC启动简述"></a>SONiC启动简述</h1><p>对于从onie下面安装SONiC，在onie下面会维护一个<code>machine.conf</code>文件，这里面有设备的详细信息，之后SONiC会根据这里的信息完成初始化的文件加载流程。</p>
<p>对于从SONiC下面直接安装SONiC，修改grub，暂不做深入研究。</p>
<p>对于systemd的初始化，SDK的初始化，platform/chassis的初始化，后续有需要在继续研究。</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC编译简述及优化</title>
    <url>/2020/12/15/SONiC%E7%BC%96%E8%AF%91%E7%AE%80%E8%BF%B0%E5%8F%8A%E4%BC%98%E5%8C%96/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>SONiC在docker中完成编译，docker image基于debian(jessie, stretch, buster)完成构建。201807及其之前的版本使用的是jessie, 202006及其之后的版本使用的是buster, 我们现阶段主要使用stretch。SONiC的编译大致分成三个阶段。</p>
<span id="more"></span>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. git submodules初始化。对应make init</span><br><span class="line">2. 编译环境构建。对应的是Makefile.work中的DOCKER_BASE_BUILD与DOCKER_BUILD，编译环境只需要在第一次使用时进行构建。</span><br><span class="line">3. 主目标编译（sonic-platform.bin）。这里面可以分为kernel编译，外部功能编译（platform, src等），根文件系统的构建。对应的是make target&#x2F;sonic-platform.bin.</span><br></pre></td></tr></table></figure>

<h1 id="submodules初始化优化建议"><a href="#submodules初始化优化建议" class="headerlink" title="submodules初始化优化建议"></a>submodules初始化优化建议</h1><p>执行<code>make init</code>之前，项目文件大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancho git]$ du -h --max-depth&#x3D;1</span><br><span class="line">76M     .&#x2F;bytedance-sonic</span><br></pre></td></tr></table></figure>
<p>执行之后的项目文件大小</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancho git]$ du -h --max-depth&#x3D;1</span><br><span class="line">1.9G     .&#x2F;bytedance-sonic</span><br></pre></td></tr></table></figure>
<p>整个过程耗时约22分钟（网络环境不同会有差异），总共27个外部modules。只会在第一次编译项目时进行构建。基于项目管控以及子模块自开发的角度，后续可以将modules迁移到内部gitlab上。字节项目中的sonic-platform-common模块现在就是这样管理的。</p>
<h1 id="编译环境构建的优化"><a href="#编译环境构建的优化" class="headerlink" title="编译环境构建的优化"></a>编译环境构建的优化</h1><p>SONiC通过Dockerfile对每个用户都构建一个编译环境，对于单用户环境这种方式合适，对于使用Linux服务器的<strong>多用户环境</strong>而言，这种方式很不合适，docker image应该给所有用户复用，而不是针对每个用户构建一个内容相同只是名字不同的image。</p>
<h2 id="缺点说明"><a href="#缺点说明" class="headerlink" title="缺点说明"></a>缺点说明</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 消耗大量存储资源。可使用docker images | grep sonic 查看。</span><br><span class="line">2. 消耗大量网络资源，构建时下载重复数据</span><br><span class="line">3. 消耗大量时间，通过源码完成编译环境的构建大概需要一小时，使用优化后的方法只需要一分钟乃至更少</span><br></pre></td></tr></table></figure>

<h2 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h2><p>复用相同版本的docker镜像进行编译</p>
<h2 id="如何操作"><a href="#如何操作" class="headerlink" title="如何操作"></a>如何操作</h2><h3 id="对于复用docker镜像搭建编译环境的用户"><a href="#对于复用docker镜像搭建编译环境的用户" class="headerlink" title="对于复用docker镜像搭建编译环境的用户"></a>对于复用docker镜像搭建编译环境的用户</h3><ol>
<li><p><code>docker images</code>查看服务器上是否有所需版本的image, image命名规则为:sonic-version-debian_version, tag为public，例如:sonic-201911-stretch:public，如果有了,跳过步骤2；</p>
</li>
<li><p>获取对应版本image的tar.gz文件</p>
<ol>
<li>我在10.204.112.46上搭建了一个文件服务器，201911-stretch的编译镜像存放在上面，可以通过该链接<code>http://10.204.112.46:8081/sonic-201911/sonic-201911-stretch.tar.gz</code>获取</li>
<li><code>gzip -d sonic-version-debian_version.tar.gz</code></li>
<li><code>docker load --input sonic-version-debian_version.tar</code></li>
</ol>
</li>
<li><p>修改Makefile, 文件位于项目根目录下</p>
<ol>
<li><p>修改Makefile文件如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">diff --git a&#x2F;Makefile b&#x2F;Makefile</span><br><span class="line">index 13a3f247..542f4077 100644--- a&#x2F;Makefile+++ b&#x2F;Makefile</span><br><span class="line">@@ -1,6 +1,6 @@ </span><br><span class="line"># SONiC make file </span><br><span class="line">-NOJESSIE ?&#x3D; 0</span><br><span class="line">+NOJESSIE ?&#x3D; 1</span><br></pre></td></tr></table></figure>
<p>如果是202006及其之后的版本，将stretch也注释掉。我们只需要用于编译的环境。</p>
</li>
<li><p>修改Makefile.work文件如下所示</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">diff --git a&#x2F;Makefile.work b&#x2F;Makefile.work</span><br><span class="line">index 14c433e4..e7232264 100644</span><br><span class="line">--- a&#x2F;Makefile.work</span><br><span class="line">+++ b&#x2F;Makefile.work</span><br><span class="line">@@ -78,10 +78,12 @@ SLAVE_DIR &#x3D; sonic-slave-stretch</span><br><span class="line">endif</span><br><span class="line">-   SLAVE_BASE_TAG &#x3D; $(shell CONFIGURED_ARCH&#x3D;$(CONFIGURED_ARCH) j2 $(SLAVE_DIR)&#x2F;Dockerfile.j2 &gt; $(SLAVE_DIR)&#x2F;Dockerfile &amp;&amp; sha1sum $(SLAVE_DIR)&#x2F;Dockerfile | awk &#39;&#123;print substr($$1,0,11);&#125;&#39;)</span><br><span class="line">-   SLAVE_TAG &#x3D; $(shell cat $(SLAVE_DIR)&#x2F;Dockerfile.user $(SLAVE_DIR)&#x2F;Dockerfile | sha1sum | awk &#39;&#123;print substr($$1,0,11);&#125;&#39;)</span><br><span class="line">-   SLAVE_BASE_IMAGE &#x3D; $(SLAVE_DIR)</span><br><span class="line">-   SLAVE_IMAGE &#x3D; $(SLAVE_BASE_IMAGE)-$(USER)</span><br><span class="line">+   #SLAVE_BASE_TAG &#x3D; $(shell CONFIGURED_ARCH&#x3D;$(CONFIGURED_ARCH) j2 $(SLAVE_DIR)&#x2F;Dockerfile.j2 &gt; $     (SLAVE_DIR)&#x2F;Dockerfile &amp;&amp; sha1sum $(SLAVE_DIR)&#x2F;Dockerfile | awk &#39;&#123;print substr($$1,0,11);&#125;&#39;)</span><br><span class="line">+   #SLAVE_TAG &#x3D; $(shell cat $(SLAVE_DIR)&#x2F;Dockerfile.user $(SLAVE_DIR)&#x2F;Dockerfile | sha1sum | awk &#39;&#123;print substr($$1,0,11);&#125;&#39;)</span><br><span class="line">+   SLAVE_TAG &#x3D; public</span><br><span class="line">+   #SLAVE_BASE_IMAGE &#x3D; $(SLAVE_DIR)</span><br><span class="line">+   #SLAVE_IMAGE &#x3D; $(SLAVE_BASE_IMAGE)-$(USER)</span><br><span class="line">+   SLAVE_IMAGE &#x3D; sonic-201911-stretch</span><br><span class="line"> </span><br><span class="line">OVERLAY_MODULE_CHECK :&#x3D; \</span><br><span class="line"> lsmod | grep -q &quot;^overlay &quot; &amp;&gt;&#x2F;dev&#x2F;null || \</span><br><span class="line">@@ -113,6 +115,7 @@ DOCKER_RUN :&#x3D; docker run --rm&#x3D;true --privileged \</span><br><span class="line"> -w $(DOCKER_BUILDER_WORKDIR) \</span><br><span class="line"> -e &quot;http_proxy&#x3D;$(http_proxy)&quot; \</span><br><span class="line"> -e &quot;https_proxy&#x3D;$(https_proxy)&quot; \</span><br><span class="line">+   -u root \</span><br><span class="line"> -i$(if $(TERM),t,)</span><br><span class="line"></span><br><span class="line">@@ -200,9 +202,9 @@ endif</span><br><span class="line">    @$(OVERLAY_MODULE_CHECK)</span><br><span class="line">    </span><br><span class="line">-       @docker inspect --type image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) &amp;&gt; &#x2F;dev&#x2F;null || \</span><br><span class="line">-           &#123; echo Image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) not found. Building... ; \</span><br><span class="line">-           $(DOCKER_BASE_BUILD) ; &#125;</span><br><span class="line">+       #@docker inspect --type image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) &amp;&gt; &#x2F;dev&#x2F;null || \</span><br><span class="line">+           #&#123; echo Image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) not found. Building... ; \</span><br><span class="line">+           #$(DOCKER_BASE_BUILD) ; &#125;</span><br><span class="line">        @docker inspect --type image $(SLAVE_IMAGE):$(SLAVE_TAG) &amp;&gt; &#x2F;dev&#x2F;null || \</span><br><span class="line">            &#123; echo Image $(SLAVE_IMAGE):$(SLAVE_TAG) not found. Building... ; \</span><br><span class="line">            $(DOCKER_BUILD) ; &#125;</span><br><span class="line">@@ -222,9 +224,9 @@ sonic-slave-build :</span><br><span class="line"> </span><br><span class="line">sonic-slave-bash :</span><br><span class="line">        @$(OVERLAY_MODULE_CHECK)</span><br><span class="line">-       @docker inspect --type image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) &amp;&gt; &#x2F;dev&#x2F;null || \</span><br><span class="line">-           &#123; echo Image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) not found. Building... ; \</span><br><span class="line">-           $(DOCKER_BASE_BUILD) ; &#125;</span><br><span class="line">+       #@docker inspect --type image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) &amp;&gt; &#x2F;dev&#x2F;null || \</span><br><span class="line">+           #&#123; echo Image $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG) not found. Building... ; \</span><br><span class="line">+           #$(DOCKER_BASE_BUILD) ; &#125;</span><br><span class="line">        @docker inspect --type image $(SLAVE_IMAGE):$(SLAVE_TAG) &amp;&gt; &#x2F;dev&#x2F;null || \</span><br><span class="line">            &#123; echo Image $(SLAVE_IMAGE):$(SLAVE_TAG) not found. Building... ; \</span><br><span class="line">            $(DOCKER_BUILD) ; &#125;</span><br><span class="line">@@ -232,7 +234,7 @@ sonic-slave-bash :</span><br><span class="line"> </span><br><span class="line">showtag:</span><br><span class="line">        @echo $(SLAVE_IMAGE):$(SLAVE_TAG)</span><br><span class="line">-       @echo $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG)</span><br><span class="line">+       #@echo $(SLAVE_BASE_IMAGE):$(SLAVE_BASE_TAG)</span><br><span class="line"></span><br></pre></td></tr></table></figure>
<p>将SLAVE_IMAGE和SLAVE_TAG修改为复用image及其tag，抛弃SLAVE_BASE_IMAGE的使用。</p>
</li>
<li><p>通过<code>make showtag</code>检查编译环境是否加载正确</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+++ Making showtag +++</span><br><span class="line">BLDENV&#x3D;stretch make -f Makefile.work showtag</span><br><span class="line">make[1]: Entering directory &#39;&#x2F;home&#x2F;rancho&#x2F;workdir&#x2F;SONIC-DEV&#x2F;sonic-buildimage&#39;</span><br><span class="line">sonic-201911-stretch:public</span><br><span class="line">make[1]: Leaving directory &#39;&#x2F;home&#x2F;rancho&#x2F;workdir&#x2F;SONIC-DEV&#x2F;sonic-buildimage&#39;</span><br></pre></td></tr></table></figure></li>
</ol>
</li>
</ol>
<h3 id="对于发布docker编译环境供大家使用的用户"><a href="#对于发布docker编译环境供大家使用的用户" class="headerlink" title="对于发布docker编译环境供大家使用的用户"></a>对于发布docker编译环境供大家使用的用户</h3><ol>
<li><p>按照原有的方式完成编译环境的构建</p>
</li>
<li><p>发布编译环境</p>
<ol>
<li>使用<code>docker tag image-id sonic-version-debian_version:tag</code>进行规法镜像命名</li>
<li>使用<code>docker rmi old_name:old_tag</code>删除生成的镜像tag</li>
<li>使用<code>docker save -o ~/sonic-version-debian_version.tar sonic-version-debian_version:public</code>提取镜像</li>
<li>使用<code>gzip sonic-version-debian_version.tar</code>压缩</li>
<li>将sonic-version-debian_version.tar.gz文件放到文件服务器上供大家使用</li>
</ol>
</li>
</ol>
<h1 id="对于主目标编译"><a href="#对于主目标编译" class="headerlink" title="对于主目标编译"></a>对于主目标编译</h1><p>这里面有个<code>target groups</code>的概念, 在slave.mk里面定义了很多目标组，如SONIC_MAKE_DEBS, SONIC_MAKE_FILES，这些目标组在具体的功能模块中被填充，之后被该组的cmd所执行。参见README.buildsystem.md将会有更好的理解。<br>对于根文件系统的构建，时间很久，主要是每次都会删除之前构建的rootfs然后使用<code>debootstrap</code>重新构建，后续如果需要进行上层功能调试这明显效率很低。这里可以通过替换调试功能所在docker完成快速版本迭代。以路由协议frr举例。</p>
<pre><code>1. make list | grep frr 找到 target/docker-fpm-frr.gz
2. 修改src/sonic-frr中的代码
3. make target/docker-fpm-frr.gz生成新的frr镜像
4. 在SONiC设备上`service bgp stop`停止docker-fpm-frr，并删除该container，删除docker-fpm-frr:latest镜像
5. 将新的镜像拷贝到设备中`docker load -i docker-fpm-frr.gz`，并为之打上latest的tag
6. `service bgp start`重启frr服务，进行代码验证
7. service bgp如果找不到对应的container，则会根据docker-fpm-frr:latest重新创建一个，所以如果需要版本回退，重4,5,6的动作即可
</code></pre>
]]></content>
      <categories>
        <category>SONiC</category>
      </categories>
      <tags>
        <tag>SONiC</tag>
        <tag>编译</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC路由协议简述</title>
    <url>/2021/04/08/SONiC%E8%B7%AF%E7%94%B1%E5%8D%8F%E8%AE%AE%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本文通过研究SONiC中已支持的路由协议BGP，了解SONiC中路由模块的工作流程，进而为支持SONiC中暂未支持的路由协议（ospf、rip、pim）的porting打下基础。以协议栈收包，协议栈状态机运转，协议栈表项生成下发至SDK为方向进行研究。</p>
<span id="more"></span>
<h2 id="SONiC中支持的协议"><a href="#SONiC中支持的协议" class="headerlink" title="SONiC中支持的协议"></a>SONiC中支持的协议</h2><p>SONiC中支持BGP、ECMP、LLDP、QoS、SNMP、NTP、DHCP、VxLAN、NAT、ARP等协议。其中，使用FRR作为默认路由协议栈。运行在<code>bdp</code>容器中。</p>
<h2 id="初步了解FRR"><a href="#初步了解FRR" class="headerlink" title="初步了解FRR"></a>初步了解FRR</h2><p>对于FRR的框架不做过多赘述，可以参见《FRR开源代码研究》，其脱胎于quagga。SONiC中FRR运行在<code>bgp</code>容器中，运行<code>docker exec -it bgp bash</code>进入该容器，但是SONiC中现在只支持BGP协议。执行<code>vtysh</code>进入FRR命令行，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@sonic:&#x2F;# vtysh </span><br><span class="line"></span><br><span class="line">Hello, this is FRRouting (version 7.2.1-sonic).</span><br><span class="line">Copyright 1996-2005 Kunihiro Ishiguro, et al.</span><br></pre></td></tr></table></figure>

<p>在<code>201911</code>分支上使用的是7.2.1, 在<code>~/rules/frr.mk</code>中可以看到。SONiC的master分支使用的FRR版本是7.5.1(sonic基于此进行porting),与FRR官方最新的<a href="https://github.com/FRRouting/frr/releases">release</a>保持一致。</p>
<p>在进行FRR模块调试的过程中，我们可以单独更新FRR模块。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancho sonic-buildimage]$ make list | grep frr</span><br><span class="line">&quot;ROUTING_STACK&quot;                   : &quot;frr&quot;</span><br><span class="line">target&#x2F;debs&#x2F;stretch&#x2F;frr_7.2.1-sonic-0_amd64.deb</span><br><span class="line">target&#x2F;debs&#x2F;stretch&#x2F;frr-pythontools_7.2.1-sonic-0_all.deb</span><br><span class="line">target&#x2F;debs&#x2F;stretch&#x2F;frr-dbgsym_7.2.1-sonic-0_amd64.deb</span><br><span class="line">target&#x2F;debs&#x2F;stretch&#x2F;frr-snmp_7.2.1-sonic-0_amd64.deb</span><br><span class="line">target&#x2F;debs&#x2F;stretch&#x2F;frr-snmp-dbgsym_7.2.1-sonic-0_amd64.deb</span><br><span class="line">target&#x2F;docker-fpm-frr.gz</span><br><span class="line">target&#x2F;docker-fpm-frr-dbg.gz</span><br></pre></td></tr></table></figure>

<h2 id="SONiC中路由模块的交互"><a href="#SONiC中路由模块的交互" class="headerlink" title="SONiC中路由模块的交互"></a>SONiC中路由模块的交互</h2><p>SONiC中路由模块交互如下图所示：</p>
<p><img src="https://rancho333.gitee.io/pictures/frr-sonic.png"> </p>
<ol>
<li>在BGP容器初始化时， zebra通过TCP socket连接到<code>fpmsyncd</code>。在稳定状态下，zebra、linux kernel、APPL_DB、ASIC_DB、ASIC中的路由表应该是完全一致的。<br>这里做一点说明，OSPF、BGP等路由进程会将自己选择出的路由发送给zebra，zebra通过计算筛选之后会通过netlink将之同步给kernel，同时zebra通过FPM(forwarding plane manger)将之同步给ASIC。zebra中运行FPM client，通过TCP socket与FPM server进行通信。FPM client端代码如下：<figure class="highlight c"><table><tr><td class="code"><pre><span class="line">    <span class="comment">//zebra_fpm.c</span></span><br><span class="line">    serv.sin_family = AF_INET;</span><br><span class="line">    serv.sin_port = htons(zfpm_g-&gt;fpm_port);                    <span class="comment">//fpm默认使用2620端口</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> HAVE_STRUCT_SOCKADDR_IN_SIN_LEN</span></span><br><span class="line">    serv.sin_len = <span class="keyword">sizeof</span>(struct sockaddr_in);                                     </span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* HAVE_STRUCT_SOCKADDR_IN_SIN_LEN */</span></span></span><br><span class="line">    <span class="keyword">if</span> (!zfpm_g-&gt;fpm_server)</span><br><span class="line">        serv.sin_addr.s_addr = htonl(INADDR_LOOPBACK);          <span class="comment">//FPM server一般部署在本机上</span></span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        serv.sin_addr.s_addr = (zfpm_g-&gt;fpm_server);</span><br></pre></td></tr></table></figure></li>
</ol>
<p>FRR定义了FPM的数据格式，类似于协议报文，用户自己实现FPM server，解析出client发送过来的路由数据，然后进行相应的处理。</p>
<ol start="2">
<li><p>Bgpd处理收到的协议报文，以bgp-update报文为例，将计算得到的路由信息发送给zebra</p>
</li>
<li><p>zebra根据自身的计算策略过滤该路由，如果通过zebra则生成route-netlink信息将路由信息发送给kernel</p>
</li>
<li><p>同时，zebra通过FPM接口将route-netlink信息发送给<code>fpmsyncd</code>，2,3,4的大致流程参见下图：<br><img src="https://rancho333.gitee.io/pictures/frr-bgpd.png"> </p>
</li>
<li><p>Fpmsyncd处理该信息并将之放入<code>APPL_DB</code><br>SONiC中FPM server在<code>fpmsyncd</code>中实现，源码在<code>sonic-swss</code>中：</p>
<figure class="highlight c"><table><tr><td class="code"><pre><span class="line"><span class="comment">//fpmsyncd.cpp  连接redis APPL_DB</span></span><br><span class="line"><span class="function">DBConnector <span class="title">db</span><span class="params">(<span class="string">&quot;APPL_DB&quot;</span>, <span class="number">0</span>)</span></span>; </span><br><span class="line"><span class="function">RedisPipeline <span class="title">pipeline</span><span class="params">(&amp;db)</span></span>;</span><br><span class="line"><span class="function">RouteSync <span class="title">sync</span><span class="params">(&amp;pipeline)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">//fpmlink.cpp  创建socket，做为FPM server</span></span><br><span class="line">addr.sin_family = AF_INET;                          </span><br><span class="line">addr.sin_port = htons(port);                        <span class="comment">//port为2620, 在fpm/fpm.h中定义</span></span><br><span class="line">addr.sin_addr.s_addr = htonl(INADDR_LOOPBACK);      <span class="comment">//部署在本地</span></span><br></pre></td></tr></table></figure></li>
</ol>
<p>编译过程中会打包到<code>swss_1.0.0_amd64.deb</code>，在<code>dockers/docker-fpm-frr/Dockerfile.j2</code>会将其安装到<code>docker-fpm-frr</code>镜像中。在BGP进程中可以看到该进程。在<code>/etc/supervisor/conf.d/supervisord.conf</code>中可以看到各服务的启动控制：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[program:bgpd]</span><br><span class="line">command&#x3D;&#x2F;usr&#x2F;lib&#x2F;frr&#x2F;bgpd -M bmp -A 127.0.0.1</span><br><span class="line">priority&#x3D;6</span><br><span class="line"></span><br><span class="line">[program:fpmsyncd]</span><br><span class="line">command&#x3D;fpmsyncd</span><br><span class="line">priority&#x3D;8</span><br></pre></td></tr></table></figure>

<ol start="6">
<li><p><code>orchagentd</code>作为APPL_DB的订阅者，它会收到fpmsyncd发布的信息</p>
</li>
<li><p>orchagentd作为一个中转站，会调用sairedis的APIs将信息发布到ASIC_DB</p>
</li>
<li><p><code>syncd</code>作为ASIC_DB的订阅者，它会收到orchagend发布的信息</p>
</li>
<li><p>Syncd调用SAI APIs将路由信息下发到SDK</p>
</li>
<li><p>最终新的路由规则在ASIC中生效</p>
</li>
</ol>
<p>FRR与SONiC的完整交互流程图示如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/route-flow.png"></p>
<h2 id="静态路由的实现"><a href="#静态路由的实现" class="headerlink" title="静态路由的实现"></a>静态路由的实现</h2><p>基于以上的SONiC路由实现流程，我们可以实现一个<code>FPM client</code>，按照ZAPI的格式封装netlink路由数据发送给<code>fpmsyncd</code>，之后在各个数据中转节点验证路由是否按设定的流程转发最终生效到ASIC。这样可以脱离<code>FRR</code>的协议栈逻辑，只借用FPM模块。</p>
<p>当然，我们可以直接通过FRR的配置文件或者<code>vtysh</code>来下发静态路由，有一个进程<code>staticd</code>用来处理静态路由。<br>路由下发的命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip route 192.168.2.0&#x2F;24 PortChannel0001</span><br></pre></td></tr></table></figure>
<p>验证一下命令是否生效：</p>
<p><img src="https://rancho333.gitee.io/pictures/show-ip-route.png"></p>
<p>看下在kernel中是否生效：</p>
<p><img src="https://rancho333.gitee.io/pictures/ip-route-show.png"></p>
<p>查看是否同步到<code>APPL_DB</code>中：</p>
<p><img src="https://rancho333.gitee.io/pictures/appl-db.png"></p>
<p>查看是否同步到<code>ASIC_DB</code>中：</p>
<p><img src="https://rancho333.gitee.io/pictures/asic-db.png"></p>
<p>查看是否下发到<code>ASIC</code>中：</p>
<p><img src="https://rancho333.gitee.io/pictures/asic-route.png"></p>
<p>可以看到路由信息按照<code>SONiC中路由模块的交互</code>中描述的进行处理下发。</p>
<h2 id="对于单播-OSPF、RIP-以及组播-PIM-的支持"><a href="#对于单播-OSPF、RIP-以及组播-PIM-的支持" class="headerlink" title="对于单播(OSPF、RIP)以及组播(PIM)的支持"></a>对于单播(OSPF、RIP)以及组播(PIM)的支持</h2><p>对于支持上述协议，需要回答几个问题：</p>
<ol>
<li>从哪里获取信息（端口状态变化、控制报文、数据报文是怎么送到协议栈的）</li>
<li>协议状态机变化 (问题怎么定位以及功能的支持程度, 至于测试，需要专业协议测试人员介入)</li>
<li>控制面信息如何生效到转发面 (协议栈控制信息同步到kernel与ASIC)</li>
</ol>
<p>SONiC默认只启动了<code>bgpd</code>和<code>staticd</code>这两个路由进程，尝试手动开启<code>ospf</code>、<code>rip</code>、<code>pim</code>并为发现异常：</p>
<p><img src="https://rancho333.gitee.io/pictures/frr-routes.png"></p>
<p>SONIC本身并未对FRR做什么修改，只是增加了一个FPM server模块，整个路由通路是没有问题的，理论上是<em>完全可以支持FRR中的其它路由协议</em>的，很好奇为什么微软不顺手把这些做了？<br>难道是因为数据中心中只要BGP+ECMP+VxLAN?</p>
<p>下面做一个工作量的评估（基于单个协议）</p>
<ol>
<li><p>协议学习2周</p>
</li>
<li><p>OSPF、PIM基于IP，使用protocol创建socket与keenel进行通信，RIP基于UDP，BGP基于TCP。ospf创建socket如下：</p>
</li>
</ol>
<p><img src="https://rancho333.gitee.io/pictures/ospf-sock.png"><br>控制报文调试1周，这玩意要是顺利应该就几分钟，大概率没啥问题。</p>
<ol start="3">
<li><p>看代码，了解协议状态机，了解常见的测试拓扑，搭建测试拓扑，生成路由信息，2周</p>
</li>
<li><p>打通路由下发，1周</p>
</li>
<li><p>协议维护，解bug，不定</p>
</li>
</ol>
<p>其实，从技术上说，很可能SONiC是已经支持上述路由协议了，只要开启相应进程，所以测试吧！说不定有惊喜！</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>broadcom_sdk_cmd</title>
    <url>/2021/01/19/broadcom-sdk-cmd/</url>
    <content><![CDATA[<h1 id="BCMShell简介"><a href="#BCMShell简介" class="headerlink" title="BCMShell简介"></a>BCMShell简介</h1><p>BCMShell是Broadcom公司对于ASIC的SDK命令解释器。利用该工具可以对ASIC所有的寄存器和内存进行读写操作，还可以利用脚本在ASIC上搭建各种复杂的网络环境。</p>
<span id="more"></span>

<h1 id="BCMShell的几种模式"><a href="#BCMShell的几种模式" class="headerlink" title="BCMShell的几种模式"></a>BCMShell的几种模式</h1><h2 id="BCMshell模式"><a href="#BCMshell模式" class="headerlink" title="BCMshell模式"></a>BCMshell模式</h2><p>拿到Broadcom源码后，根据OS上的kernel版本选择对应的内核头文件编译SDK，之后会得到几个文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bcm.user  bcm.user.dbg  linux-bcm-knet.ko  linux-kernel-bde.ko  linux-user-bde.ko  netserve</span><br></pre></td></tr></table></figure>
<p>参考SDK包运行环境中的<code>auto_load_user.sh</code>，安装对应驱动，启动<code>bcm.user</code>即可进入BCMShell命令行，提示如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BCM.0&gt; </span><br><span class="line">BCM.0&gt; exit</span><br></pre></td></tr></table></figure>
<p><code>exit</code>退回到shell。<br>如果OS是SONiC，执行<code>bcmsh</code>也可进入，通过<code>bcmcmd cmd</code>可以在shell下在BCMShell中执行命令。</p>
<h2 id="回退到shell模式"><a href="#回退到shell模式" class="headerlink" title="回退到shell模式"></a>回退到shell模式</h2><p>在BCMShell模式中通过命令<code>shell</code>可以进入shell里面执行命令，应该是将bcmshell放到后台运行，在shell中exit即可再次回到bcmshell。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BCM.0&gt; </span><br><span class="line">BCM.0&gt; shell</span><br><span class="line">root@sonic:&#x2F;home&#x2F;admin&#x2F;R1241-M0150-01_V0.0.2_Questone2F_SDK# exit</span><br><span class="line">exit</span><br><span class="line">BCM.0&gt; exit</span><br><span class="line">root@sonic:&#x2F;home&#x2F;admin&#x2F;R1241-M0150-01_V0.0.2_Questone2F_SDK# </span><br></pre></td></tr></table></figure>

<h2 id="cint模式"><a href="#cint模式" class="headerlink" title="cint模式"></a>cint模式</h2><p>在BCMShell模式中通过命令<code>cint</code>可以进入到C interpreter模式，可以在里面执行C函数，如gearbox的一些操作可以在里面完成，<code>exit;</code>回退道bcmshell。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BCM.0&gt; </span><br><span class="line">BCM.0&gt; cint</span><br><span class="line">Entering C Interpreter. Type &#39;exit;&#39; to quit.</span><br><span class="line"></span><br><span class="line">cint&gt; exit;</span><br><span class="line">BCM.0&gt; </span><br></pre></td></tr></table></figure>

<h1 id="BCMShell的一些特点"><a href="#BCMShell的一些特点" class="headerlink" title="BCMShell的一些特点"></a>BCMShell的一些特点</h1><ol>
<li>不区分大小写</li>
<li>支持缩写</li>
</ol>
<p><code>?</code>可以显示所有命令。以<code>PortStat</code>为例：PortStat和portstat等效，缩写规则是大写字母是可缩写项，PortStat可缩写为ps</p>
<h1 id="命令说明"><a href="#命令说明" class="headerlink" title="命令说明"></a>命令说明</h1><p>BCMShell命令可以分为五类：</p>
<ol>
<li>帮助命令</li>
<li>show命令</li>
<li>低级命令：对寄存器/RAM进行读写的命令</li>
<li>端口命令：与端口相关的命令</li>
<li>芯片MAC学习，通信协议相关的命令</li>
</ol>
<h2 id="帮助命令"><a href="#帮助命令" class="headerlink" title="帮助命令"></a>帮助命令</h2><p>总共有五种帮助命令使用方法，使用一种即可<code>cmd + ?</code>，如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BCM.0&gt; ps ?</span><br><span class="line">Usage (PortStat): Display info about port status in table format.</span><br><span class="line">    Link scan modes:</span><br><span class="line">        SW &#x3D; software</span><br><span class="line">        HW &#x3D; hardware</span><br><span class="line">    Learn operations (source lookup failure control):</span><br><span class="line">        F &#x3D; SLF packets are forwarded</span><br><span class="line">        C &#x3D; SLF packets are sent to the CPU</span><br><span class="line">        A &#x3D; SLF packets are learned in L2 table</span><br><span class="line">        D &#x3D; SLF packets are discarded.</span><br><span class="line">    Pause:</span><br><span class="line">        TX &#x3D; Switch will transmit pause packets</span><br><span class="line">        RX &#x3D; Switch will obey pause packets</span><br></pre></td></tr></table></figure>

<h2 id="show命令"><a href="#show命令" class="headerlink" title="show命令"></a>show命令</h2><p>常用show命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">show c                  查看ASIC各个端口收发包情况，可以加子命令过滤</span><br><span class="line">show ip                 查看ip报文统计计数</span><br><span class="line">show icmp               查看icmp报文统计计数</span><br><span class="line">show arp                查看arp报文统计计数</span><br><span class="line">show udp   </span><br><span class="line">show tcp</span><br><span class="line">show routes             查看子网路由表和主机路由表</span><br><span class="line"></span><br><span class="line">show unit               查看芯片信息</span><br><span class="line">show params             查看当前芯片驱动配置参数</span><br><span class="line">show features           查看当前芯片的特性</span><br></pre></td></tr></table></figure>

<h2 id="低级命令"><a href="#低级命令" class="headerlink" title="低级命令"></a>低级命令</h2><p>低级命令的作用主要是对寄存器和RAM进行读写。</p>
<h3 id="对寄存器进行读写"><a href="#对寄存器进行读写" class="headerlink" title="对寄存器进行读写"></a>对寄存器进行读写</h3><table>
<thead>
<tr>
<th align="left">寄存器类别</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">PCIC</td>
<td align="left">PCI配置寄存器</td>
</tr>
<tr>
<td align="left">PCIM</td>
<td align="left">PCI内存映射寄存器</td>
</tr>
<tr>
<td align="left">SOC</td>
<td align="left">交换芯片寄存器与内存</td>
</tr>
<tr>
<td align="left">PHY</td>
<td align="left">PHY寄存器</td>
</tr>
</tbody></table>
<p>寄存器常用命令如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">getreg          获取寄存器的值</span><br><span class="line">listreg         显示所支持的寄存器信息</span><br><span class="line">setreg          设置寄存器的值</span><br></pre></td></tr></table></figure>

<h3 id="对内存表进行读写"><a href="#对内存表进行读写" class="headerlink" title="对内存表进行读写"></a>对内存表进行读写</h3><p>内存表读操作： dump<br>内存表写操作： write</p>
<h2 id="端口命令"><a href="#端口命令" class="headerlink" title="端口命令"></a>端口命令</h2><p>端口命令主要是端口设置<code>PORT</code>命令和端口显示<code>PortStat</code>命令。举例如下：<br>设置xe0 loopback：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">BCM.0&gt; port xe0 lb&#x3D;phy</span><br></pre></td></tr></table></figure>

<h2 id="高级命令"><a href="#高级命令" class="headerlink" title="高级命令"></a>高级命令</h2><p>高级命令可以对协议等复杂功能进行设置，如ACL，OAM等。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">l2 show                                             显示mac地址表</span><br><span class="line">l2 add port&#x3D;ge2 macaddress&#x3D;0x000000000001 vlan&#x3D;1   在ge2端口静态添加mac地址</span><br></pre></td></tr></table></figure>
]]></content>
  </entry>
  <entry>
    <title>hexo中踩过的坑</title>
    <url>/2019/07/25/hexo%E4%B8%AD%E8%B8%A9%E8%BF%87%E7%9A%84%E5%9D%91/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我们都是站在前人的肩膀上看的更远，走的更高。在这里记录下通过Hexo搭建个人博客，通过markdown写博客的过程中踩的一些坑，希望对看到这篇文章的你有些帮助！</p>
<span id="more"></span>

<h3 id="关于代码块"><a href="#关于代码块" class="headerlink" title="关于代码块"></a>关于代码块</h3><p>```后面不要留空格，不然不会把它当做代码块的定界符来处理，会把后面的内容都当做代码块来处理。</p>
<h3 id="关于表格"><a href="#关于表格" class="headerlink" title="关于表格"></a>关于表格</h3><p>在表格开头留个空行，不然可能不对表格进行渲染。<br>在表格结束留个空行，不然可能对表格之后的内容进行越界渲染。</p>
]]></content>
      <categories>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>踩坑</tag>
        <tag>hexo</tag>
        <tag>markdown</tag>
      </tags>
  </entry>
  <entry>
    <title>igmp-snooping学习</title>
    <url>/2019/09/10/igmp-snooping%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>恩，18年做了半年的组播，算入门吧！最近有个igmp snooping（下面简称igsp）的bug，是个机缘接触一下igsp！</p>
<span id="more"></span>


<h2 id="使用需求简述"><a href="#使用需求简述" class="headerlink" title="使用需求简述"></a>使用需求简述</h2><p>很多情况下，组播报文要不可避免的经过一些二层交换设备，尤其是在局域网环境里。如下图：</p>
<p><img src="https://rancho333.gitee.io/pictures/environment.png"></p>
<p>上图中switch会将组播报文当做广播在vlan内进行flood，这是因为组播报文的目的地址为组播地址，在二层设备上学习不到这一类的MAC表项，这样不但浪费网络带宽，而且影响网络信息安全。配置igsp后，二层组播设备可以侦听和分析组播用户和上游路由器之间的IGMP报文，根据这些信息建立二层组播转发表项，控制组播数据报文的转发。</p>
<h2 id="IGSP基本原理"><a href="#IGSP基本原理" class="headerlink" title="IGSP基本原理"></a>IGSP基本原理</h2><p>IGSP是二层组播的基本功能，可以实现组播数据在链路层的转发和控制。当主机和上游三层设备之间传递IGMP协议报文通过二层组播设备时，IGSP分析报文携带的信息，根据这些信息建立和维护组播转发表，从而指导组播数据在数据链路层按需转发。<br><img src="https://rancho333.gitee.io/pictures/mc_data.png"></p>
<h2 id="IGSP相关概念"><a href="#IGSP相关概念" class="headerlink" title="IGSP相关概念"></a>IGSP相关概念</h2><p><img src="https://rancho333.gitee.io/pictures/concept.png"><br>如上图所示，三层设备router从组播源接收数据并向下游转发，在二层组播涉笔Switch A和Switch B上分别运行IGSP，Host A,B,C为组播成员。下面说下IGSP中的几个重要概念。</p>
<ul>
<li><p>路由器端口（Router Port）<br>如Switch A和Switch B上蓝色圆圈表示的接口。<br>路由器端口指二层组播设备上 <em><strong>朝向</strong></em> 组播路由器的接口。二层组播设备从该接口接受IGMP和PIM协议报文以及组播数据报文。<br>由协议生成的路由器端口叫做动态路由器端口，手动配置的路由器端口叫做静态路由器端口。<br>收到源地址不为0.0.0.0的IGMP普遍组查询报文或PIM Hello报文的接口都被视为动态路由器端口（呃，ENOS中IGSP貌似没有处理PIM报文的地方）。</p>
</li>
<li><p>成员端口（Member port）<br>如Switch A，B上黄色方框表示的接口。又被称为组播成员端口，表示二层组播设备上朝向组播成员一侧的端口，二层组播设备往此接口发送组播数据报文。<br>由协议生成的成员端口叫做动态成员端口，手动配置的成员端口叫做静态成员端口。<br>收到IGMP report报文的接口，二层组播设备会将其标识为动态成员端口。</p>
</li>
</ul>
<p>路由器端口，成员端口，组播地址和vlan编号是二层组播转发表项的基本信息。</p>
<p>如果使用了组播vlan功能，入vlan为组播vlan，出vlan为主机所在的用户vlan。否则入vlan和出vlan均为主机所在的vlan。<br>哈，后面在ENOS中添加组播vlan功能，这里先了解一下了！</p>
<h2 id="IGSP工作机制"><a href="#IGSP工作机制" class="headerlink" title="IGSP工作机制"></a>IGSP工作机制</h2><p>这里说明IGSP对不同协议报文的处理。</p>
<ul>
<li><p>IGMP普遍组查询报文<br>IGMP querier定期向本地网段内的所有主机与路由器（目的地址为224.0.0.1）发送IGMP普遍组查询报文，以查询该网段有哪些组播组成员。处理方式：</p>
<ul>
<li>向VLAN内除接收接口意外的其它所有接口转发，并对接收接口做如下处理：<ul>
<li>如果路由器端口列表中尚未包含该接口，则将其添加进去，并启动老化定时器</li>
<li>如果路由器端口列表中已包含该动态路由器端口，则重置老化定时器</li>
</ul>
</li>
</ul>
</li>
<li><p>IGMP成员报告报文<br>两种情况：</p>
<ul>
<li>成员收到IGMP普遍组查询报文后，回应IGMP报告报文</li>
<li>成员主动向IGMP查询器发送IGMP报告报文以声明加入该组播组<br>处理方式：<br>向vlan内所有的路由器端口转发。（注意，其它主机不会收到IGMP成员报告报文，需要在二层组播设备上使能report suppres抑制report和leave报文。）从报文中解析出主机要加入的组播组地址，并对接收接口做如下处理：<ul>
<li>如果不存在该组对应的转发表项，则创建转发表，将该接口作为成员端口添加到出接口列表中，并启动老化定时器。</li>
<li>如果已存在该组对应的转发表，且出接口列表中已包含该动态成员端口，则重置其老化定时器。</li>
</ul>
</li>
</ul>
</li>
<li><p>IGMP成员离开报文<br>两个阶段：</p>
<ul>
<li>运行IGMPv2或IGMPv3的成员发送IGMP leave报文，通知IGMP查询器自己离开某个组播组</li>
<li>IGMP查询器向该组播组发送特定组查询报文<br>处理方式：<br>判断离开的组是否存在对应的转发表象，以及转发表象出接口列表是否包含报文的接收接口：</li>
<li>如果不存在该组对应的转发表象，或者该组对应转发表项的出接口列表中不包含接收接口，二层组播设备不转发该报文，直接丢弃。</li>
<li>如果存在对应的转发表项并且表项包含该接口，向vlan内的所有路由器端口转发。</li>
</ul>
</li>
</ul>
<p>对于IGMP离开报文的接收接口，二层组播设备在其老化时间内：<br>    * 如果从该接口收到了主机响应IGMP特定组查询报文的报告报文，表示接口下还有该组成员，重置老化时间。<br>    * 如果没有收到，则在老化超时后，将接口从该组的转发表项出接口列表中删除。</p>
<p>参考资料：<br><a href="https://support.huawei.com/enterprise/zh/doc/EDOC1000141440/cabd652a">华为IGSP配置</a><br><a href="https://blog.51cto.com/lifulin/2073218">组播IGMP Snooping理论知识详解</a></p>
]]></content>
      <tags>
        <tag>通信协议</tag>
        <tag>igmp snooping</tag>
      </tags>
  </entry>
  <entry>
    <title>kernel编译简述</title>
    <url>/2020/03/11/kernel%E7%BC%96%E8%AF%91%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>在ENOS系统移植的过程中，对于Linux kernel，涉及到kernel的配置，编译，以及二进制镜像uImage的生成。这篇文章分为两块：</p>
<span id="more"></span>
<ol>
<li>内核配置系统浅析</li>
<li>vmlinux,uImage,Image的关系或区别</li>
</ol>
<h1 id="内核配置系统浅析"><a href="#内核配置系统浅析" class="headerlink" title="内核配置系统浅析"></a>内核配置系统浅析</h1><p>Linux采用模块化的内核配置系统，保证了内核的可扩展性。Linux内核的配置系统由三个部分组成，分别是：</p>
<ol>
<li>Makefile：分部在Linux内核源码中的Makefile，定义Linux内核的编译规则</li>
<li>配置文件（.config, Kconfig等）</li>
<li>配置工具<ol>
<li>配置命令解释器，对配置脚本中使用的配置命令进行解释</li>
<li>配置用户界面，分为基于字符（make config）,基于Ncurses图形界面（make menuconfig），基于Xwindows图形界面（make xconfig）</li>
</ol>
</li>
</ol>
<h2 id="Makefile"><a href="#Makefile" class="headerlink" title="Makefile"></a>Makefile</h2><p>Makefile的作用是根据配置的情况，构造出需要编译的源文件列表，然后分别编译，并把目标代码链接到一起，最终形成Linux内核二进制文件。kernel中Makefile相关的文件有：</p>
<ol>
<li>顶层Makefile，是整个内核配置、编译的总体控制文件，产生vmlinux文件和内核模块（module）</li>
<li>.config：内核配置文件，是执行完内核配置的结果，如果没有指定kernel根目录下没有.config，可以在make时指定特定的配置文件进行编译，之后也会在根目录下产生.config</li>
<li>arch/*/Makefile：不同CPU体系的Makefile，系统移植需要多关注一些这部分</li>
<li>各子目录下的Makefile，如drivers下的，负责所在子目录下源代码的管理</li>
<li>Rules.make：规则文件，被所有的Makefile使用</li>
</ol>
<p>用户通过make config后，这里实际就是收集各目录下的Kconfig/deconfig文件生成配置界面，供用户进行功能选择，最后产生<code>.config</code>，如果.config文件存在，则是直接通过.config生成配置界面。顶层Makefile读入.config中的配置选择进行具体模块的编译。顶层Makefiel中会包含具体arch的Makefile<br><img src="https://rancho333.gitee.io/pictures/arch.png"><br>Rules.make其实就是不同模块之间会共用到的Makefile规则。</p>
<p>在ENOS中，系统架构人员将生成好的ARCH的config文件存放ARCH的目录下，上层开发人员编译时直接使用指定的config文件编译即可。<br><img src="https://rancho333.gitee.io/pictures/config.png"><br>之后在指定的<code>O</code>目录下会生成编译过程中生成的文件，这样可以避免污染源码（make clean不能清除么），或者是更便于管理和模块化考虑。<br>如果需要进行kernel的二次配置，需要到<code>O</code>目录下去执行make menuconfig，之后将重新生成的<code>.config</code>拷回<code>ARCH</code>目录覆盖之前的配置文件。这是基于ARCH缺省配置的一种应用，在向内核代码增加了新的功能后，如果新功能对于这个ARCH是必需的，就需要修改此ARCH的缺省配置，修改方法如下：</p>
<ol>
<li>备份.config文件</li>
<li>cp arch/arm/deconfig .config</li>
<li>修改.config</li>
<li>cp .config arch/arm/deconfig</li>
<li>恢复.config</li>
</ol>
<h3 id="配置变量CONFIG"><a href="#配置变量CONFIG" class="headerlink" title="配置变量CONFIG_*"></a>配置变量CONFIG_*</h3><p>.config文件中用配置变量等式来说明用户的配置结果，等式左边是模块/功能,右侧是控制选项，有三种：</p>
<ol>
<li><code>y</code>表示后本编译选项对用的内核代码被静态编译进Linux内核</li>
<li><code>m</code> 表示本编译选项对应的内核代码被编译成模块</li>
<li><code>n</code>表示不选择此编译选项<br>如果根本没有选择某模块，该模块是被注释掉的</li>
</ol>
<h1 id="vmlinux-uImage-Image的关系或区别"><a href="#vmlinux-uImage-Image的关系或区别" class="headerlink" title="vmlinux,uImage,Image的关系或区别"></a>vmlinux,uImage,Image的关系或区别</h1><p>Linux内核有多种格式的镜像，包括vmlinux、Image、zImage、bzImage、uImage、xipImage、bootpImage等。<br>vmlinux是编译出来的最原始的内核文件，未经压缩，vm代表virtual memory Linux支持虚拟内存；<br>Image是经过objcopy处理的只包含二进制数据的内核代码，未经压缩，不是elf格式；objcopy的实质是将所有的符号和 重定位信息都抛弃，只剩下二进制数据。<br>zImage是vmlinux加上解压代码经gzip压缩而成，是ARM linux常用的一种压缩镜像文件。这种格式的Linux镜像多存放在NAND上。bzImage与之类似，只不过是采用了压缩率更高的算法。<br>uImage是uboot专用的镜像文件，它是在zImage之前加上一个长度为0x40的tag，里面包含了镜像文件的类型、加载位置、生成时间、大小等信息。通过mkimage命令可以制作uImage。<br>xipImage多放在NorFlash上直接运行。<br>这里只是一些简单的描述，有待在今后的项目中去加深理解各种格式的使用，存在肯定是有其对应的使用场景的！<br><img src="https://rancho333.gitee.io/pictures/vmlinux.png"></p>
<h1 id="对于文件系统的一点理解"><a href="#对于文件系统的一点理解" class="headerlink" title="对于文件系统的一点理解"></a>对于文件系统的一点理解</h1><p>加在这里可能不是很符合这篇文章的主题！<br>Linux下一切皆文件。Linux系统中任何文件系统的挂载必须满足两个条件：挂载点和文件系统。rootfs之所以存在，是因为需要在VFS机制下给系统提供最原始的挂载点。<br>rootfs其实就是文件系统顶层的<code>/</code>，使用pwd命令后看到的第一个字符，它有三个特点：</p>
<ol>
<li>它是系统自己创建并加载的第一个文件系统，是Linux内核自己创建的，并不是我们常说的外部根文件系统，将外部根文件系统解压或者说挂载到<code>/</code>后就是用户能看到的Linux文件系统，里面有很多的文件夹，如’etc’、’bin’等。<em>不能被unmount或者删除</em>，通过<code>cat /proc/mounts</code>也可以看出。下述的rootfs特指<code>/</code></li>
<li>该文件系统的挂载点就是它自己的根目录项对象</li>
<li>该文件系统仅仅存在于内存中<br>VFS是Linux文件系统实现遵循的一种机制，rootfs是一种是一种具体实现的文件系统，Linux下所有文件系统的实现都必须符合VFS机制（符合VFS的接口），这是二者的真正关系。</li>
</ol>
<p>Linux系统移植过程有一项是制作根文件系统，这里所谓的根文件系统实际上是外部根文件系统，用来释放到rootfs里面。有几个概念<code>ramfs initramfs</code>，ramfs是linux中的一个内存文件系统,initramfs是一种压缩（可以是lzma，zip等，看kernel的支持情况）的cpio格式的归档文件，initrd（initramdisk）也是一中ramfs镜像文件，它是用来在启动过程中初始化系统的，它可以被卸载。区别如下：</p>
<ol>
<li>它必须是和kernel分离的一种形式存在</li>
<li>他只是一个zip压缩的文件系统，而不是cpio文件</li>
<li>initrd中的/initrd程序只是做一些setup操作并最后返回到kernel中执行，而initramfs中的/init执行完后不返回到kernel</li>
</ol>
<p>对于initramfs，也就是系统移植时需要制作的文件系统。它存在于两处，一种是内核编译后自动生成的内部initramfs(在/usr目录下)，另一种是用户自己制作的，通过cmdline将地址传递给kernel的外部initramfs<br>对于内部initramfs，这个文件系统里面实际上啥也没有：<br><img src="https://rancho333.gitee.io/pictures/initramfs_kernel.png"><br>rootfs挂载之后，首先会先释放这个内部的initramfs到rootfs（很显然啥也干不了！<em>没搞清楚为什么会存在，但肯定有原因！</em>）,然后kernel会尝试在rootfs中寻找/init，一旦找到就执行init，kernel也就完成了启动工作，之后init就会接管接下来的工作。如果kernel找不到，就会去找外部initramfs然后释放（uboot下通过initrd参数指定位置）或者按照标准做法解析参数<code>root=</code>（这里面是解压好到某个介质分区的文件系统），试图找到一个文件系统并挂载到rootfs，之后就init。</p>
<p>所以我们实际使用的肯定是外部文件系统了，对于外部的文件系统，我们可以通过不同的方法将它挂载到rootfs。</p>
<ol>
<li>制作一个独立的cpio.lzma包，然后告诉bootloader它的地址，通过cmdline将参数传递给kernel</li>
<li>制作一个独立的包，通过mkimge(只针对于uboot)将kernel+initramfs+dtb打包成一个文件，在uboot下启动（实验过可行）</li>
<li>用外部的initramfs替换kernel自动生成的initramfs，有两种方法：<ol>
<li>先编译kernel，让它生成内部intramfs，然后制作外部initramfs，拷贝替换掉，最后重新编译内核。外部initramfs就会和kernel编成一个文件。ENOS里面使用的是这种方法。</li>
<li>使用内核编译选项CONFIG_INITRAMFS_SOURCE指定根文件系统路径，即kernel会根据给定的文件生成内部initramfs，这里面又有集中不同的给定方式，这里不表。<br><img src="https://rancho333.gitee.io/pictures/kernel_initramfs.png"><br>外部initramfs替换内部initramfs之后，kernel会在第一时间找到/init,所以<code>root=，initrd=</code>这些参数都不会起作用了。</li>
</ol>
</li>
</ol>
<p>参考资料：<br><a href="https://www.ibm.com/developerworks/cn/linux/kernel/l-kerconf/">Linux内核配置系统浅析</a><br><a href="https://blog.csdn.net/ultraman_hs/article/details/52838989">zImage和uImage的区别联系</a><br><a href="https://blog.csdn.net/rikeyone/article/details/52048972">ramfs,rootfs,initramfs,initrd</a><br><a href="https://blog.csdn.net/sunjing_/article/details/53081306">initramfs的使用方法</a></p>
]]></content>
      <tags>
        <tag>kernel</tag>
      </tags>
  </entry>
  <entry>
    <title>mpls学习</title>
    <url>/2021/02/09/mpls%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="MPLS简介"><a href="#MPLS简介" class="headerlink" title="MPLS简介"></a>MPLS简介</h1><p>MPLS(multiprotocol label switching，多协议标签交换)起源于IPv4，最初是为了提高转发速度而提出的（早期路由是只能由软件处理的），其核心技术可扩展到多种网络协议，包括IPv6，IPX(internet packet exchange，网际报文交换)和CLNP(connectionless network protocol,无连接网络协议)等。MPLS中的<em>M</em>指的就是支持多种网络协议。</p>
<span id="more"></span>
<h1 id="概念说明"><a href="#概念说明" class="headerlink" title="概念说明"></a>概念说明</h1><h2 id="转发等价类"><a href="#转发等价类" class="headerlink" title="转发等价类"></a>转发等价类</h2><p>MPLS作为一种分类转发技术，将具有相同转发处理方式的分组归位一类，称为FEC(forwarding equivalence class，转发等价类)。相同FEC的分组在MPLS中将获得完全相同的处理。<br>FEC的划分方式非常灵活，可以是源地址、目的地址、源端口、目的端口、协议类型或VPN等为划分依据的任意组合。例如，在传统的采用最长匹配算法的IP转发中，到同一个目的地址的所有报文就是一个FEC。</p>
<h2 id="标签"><a href="#标签" class="headerlink" title="标签"></a>标签</h2><p>标签是一个长度固定，仅具有本地意义的短标识符，用于唯一标识一个分组所属的FEC。一个标签只能代表一个FEC。标签长度为4个字节，结构如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/mpls_packet.png"></p>
<p>字段解释如下：</p>
<table>
<thead>
<tr>
<th align="left">字段</th>
<th align="left">解释</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Label</td>
<td align="left">标签字段，长度为20bits，用来标识一个FEC</td>
</tr>
<tr>
<td align="left">Exp</td>
<td align="left">3bits, 保留， 协议中没有明确规定， 通常用作CoS</td>
</tr>
<tr>
<td align="left">S</td>
<td align="left">1bit, MPLS支持多重标签，值为1时表示为最底层标签</td>
</tr>
<tr>
<td align="left">TTL</td>
<td align="left">8bits, 和IP分组中的TTL意义相同，用来防止环路</td>
</tr>
</tbody></table>
<p>如果链路层协议具有标签域，如ATM的VPI/VCI,则标签封装在这些域中；否则，标签封装在链路层头和网络层数据之间的一个垫层。这样，任意链路层都能够支持标签。下图是标签在分组中的封装位置。</p>
<p><img src="https://rancho333.gitee.io/pictures/mpls_packet_location.png"></p>
<h2 id="标签交换路由器"><a href="#标签交换路由器" class="headerlink" title="标签交换路由器"></a>标签交换路由器</h2><p>LSR(label switching router,标签交换路由器)是MPLS网络中的基本单元，所有LSR都支持MPLS技术。</p>
<h2 id="标签交换路径"><a href="#标签交换路径" class="headerlink" title="标签交换路径"></a>标签交换路径</h2><p>一个转发等价类在MPLS网络中经过的路径称为LSP(label switched path，标签交换路径)。在一条LSP上，沿数据传送的方向，相邻的LSR分别称为上游LSR和下游LSR。如下图所示，R2是R1的下游LSR，相应的R1是R2的上有LSR。</p>
<p><img src="https://rancho333.gitee.io/pictures/mpls_lsr.png"><br>LSP在功能上与ATM和帧中继(frame relay)的虚电路相同，是从MPLS网络的入口到出口的一个单向路径，LSP中的每个节点由LSR组成。</p>
<h2 id="标签分发协议"><a href="#标签分发协议" class="headerlink" title="标签分发协议"></a>标签分发协议</h2><p>LDP(label distribution protocol，标签分发协议)是MPLS的控制协议，它相当于传统网络中的信令协议，负责FEC的分类、标签的分配以及LSP的建立和维护等一系列操作。MPLS可以使用多种标签发布协议，包括专为标签发布而制定的协议，例如：LDP、CR-LDP(constraint-based routing using LDP,基于约束路由的LDP)；也包括现有协议扩展后支持标签发布的，例如：BGP、RSVP(resource reservation protocol，资源预留协议)。同时，还可以手工配置静态LSP。<br>LDP有两个重要的作用：</p>
<ol>
<li>给本地路由信息分配标签，进行绑定生成LIB表</li>
<li>传递LSR之间的绑定信息，生成LFIB表</li>
</ol>
<h2 id="LSP隧道技术"><a href="#LSP隧道技术" class="headerlink" title="LSP隧道技术"></a>LSP隧道技术</h2><p>MPLS支持LSP隧道技术。一条LSP的上游LSR和下游LSR，尽管他们之间的路径可能并不在路由协议所提供的路径上，但MPLS允许在他们之间建立一条新的LSP，这样，上游LSR和下游LSR分别就是这条LSP的起点和终点。这时，上游LSR和下游LSR间就是LSP隧道，它避免了采用传统的网络层封装隧道。如上图中LSP <code>R2-&gt;R21-&gt;R22-&gt;R3</code>就是R2、R3间的一条隧道。如果隧道经由的路由与逐跳从路由协议中取得的路由一致，这种隧道就称为逐跳路由隧道(Hop by Hop routed tunnel)，否则称为显示路由隧道(explicitly routed tunnel)。</p>
<h2 id="多层标签栈"><a href="#多层标签栈" class="headerlink" title="多层标签栈"></a>多层标签栈</h2><p>如果分组在超过一层的LSP隧道中传送，就会有多层标签，形成标签栈(label stack)。在每一隧道的入口和出口，进行标签的入栈(push)和出栈(pop)操作。标签按照<code>后进先出</code>(last-in-first-out)方式组织标签，MPLS从栈顶开始处理标签。<br>MPLS对标签栈的深度没有限制，若一个分组的标签深度为m，则位于栈底的标签为1级标签，位于栈顶的标签为m级标签。未压入标签的分组可看作标签栈为空(即标签栈深度为0)的分组。</p>
<h1 id="MPLS体系结构"><a href="#MPLS体系结构" class="headerlink" title="MPLS体系结构"></a>MPLS体系结构</h1><h2 id="MPLS网络结构"><a href="#MPLS网络结构" class="headerlink" title="MPLS网络结构"></a>MPLS网络结构</h2><p>如下图所示，MPLS网络的基本构成单元是LSR，由LSR构成的网络称为MPLS域。位于MPLS域边缘、连接其它用户网络的LSR称为LER(label edge router, 边缘LSR)，区域内部的LSR称为核心LSR。核心LSR可以是支持MPLS的路由器，也可以是由ATM交换机等升级而成的ATM-LSR。域内部的LSR之间使用MPLS通信，MPLS域的边缘由LER与传统IP技术进行适配。<br>分组在入口LER被压入标签后，沿着由一系列LSR构成的LSP传送，其中，入口LER被称为ingress，出口LER被称为egress，中间的节点则称为transit。</p>
<p><img src="https://rancho333.gitee.io/pictures/mpls_network.png"><br>结合上图简要介绍MPLS基本工作过程：</p>
<ol>
<li>首先，LDP和传统路由协议(如OSPF、ISIS等)一起，在各个LSR中为有业务需求的FEC建立路由表和LIB(label information base，标签信息表)</li>
<li>入口LER接收分组，完成第三层功能，判定分组所属的FEC，并给分组加上标签，形成MPLS标签分组</li>
<li>接下来，在LSR构成的网络中，LSR根据分组上的标签以及LFIB(label forwarding information base，标签转发表)进行转发，不对标签分组进行任何第三层处理</li>
<li>最后，在MPLS出口LER去掉分组中的标签，继续进行后面的IP转发</li>
</ol>
<p>MPLS并不是一种业务或者应用，它本质上是一种隧道技术，也是一种将标签交换转发和网络层路由技术集于一身的路由与交换技术平台，这个平台不仅支持多种高层协议与业务，而且，在一定程度上可以保证信息传输的安全性。</p>
<h2 id="MPLS节点结构"><a href="#MPLS节点结构" class="headerlink" title="MPLS节点结构"></a>MPLS节点结构</h2><p><img src="https://rancho333.gitee.io/pictures/mpls_node.png"></p>
<p>如上图所示，MPLS节点由两部分组成：</p>
<ul>
<li>控制平面(control plane)：负责标签的分配、路由的选择、标签转发表的建立、标签交换路径的建立、拆除等工作</li>
<li>转发平面(forwarding plane)：依据标签转发表对收到的分组进行转发</li>
</ul>
<p>对于普通的LSR，在转发平面只需要进行标签分组的转发，需要使用到LFIB。对于LER，在转发平面不仅需要进行标签分组的转发，也需要进行IP分组的转发，所以既会使用到LFIB，也会使用到FIB表。</p>
<h2 id="MPLS与路由协议"><a href="#MPLS与路由协议" class="headerlink" title="MPLS与路由协议"></a>MPLS与路由协议</h2><p>LDP通过逐跳方式建立LSP时，利用沿途各LSR路由转发表中的信息来确定下一跳，而路由转发表中的信息一般是通过IGP、BGP等路由协议收集的。LDP并不直接和各种路由协议关联，只是间接使用路由信息。另一方面，通过对BGP、RSVP等已有协议进行扩展，也可以支持标签的分发。<br>在MPLS的应用中，也可能需要对某些路由协议进行扩展。例如，基于MPLS的VPN应用需要对BGP进行扩展，使BGP能够传播VPN的路由信息；基于MPLS的TE(traffic engineering,流量工程)需要对OSPF或IS-IS协议进行扩展，以便携带链路状态信息。</p>
<h2 id="MPLS的应用"><a href="#MPLS的应用" class="headerlink" title="MPLS的应用"></a>MPLS的应用</h2><p>最初，MPLS技术结合了二层交换与三层路由技术，提高了路由查找速度。但随着ASIC的发展，路由查找速度已经不成为阻碍网络发展的瓶颈。这使得MPLS在提高转发速度方面不具备明显的优势。<br>但由于MPLS结合了IP网络强大的三层路由功能和传统二层网络高效的转发机制，在转发平面采用面向连接的方式，与现有二层网络转发方式非常相似，这些特点使得MPLS能够很容易的实现IP与ATM、帧中继等二层网络的无缝融合，并为QoS、TE、VPN等应用提供更好的解决方案。</p>
<h3 id="基于MPLS的VPN"><a href="#基于MPLS的VPN" class="headerlink" title="基于MPLS的VPN"></a>基于MPLS的VPN</h3><p>传统的VPN一般是通过GRE、L2TP、PPTP等隧道协议来实现私有网络间数据流在公网上的传送，LSP本身就是公网上的隧道，因此，用MPLS来实现VPN有天然的优势。基于MPLS的VPN就是通过LSP将私有网络的不同分支连接起来，形成一个同一的网络。基于MPLS的VPN还支持对不同的VPN间的互通控制。<br><img src="https://rancho333.gitee.io/pictures/mpls_vpn.png"></p>
<p>上图是基于MPLS的VPN的基本结构</p>
<ul>
<li>CE可以是路由器，也可以是交换机或主机</li>
<li>PE位于骨干网络<br>PE负责对VPN用户进行管理，建立各PE间的LSP连接，同一VPN用户各分支间路由分派，PE间的路由分派通常是用LDP或扩展的BGP协议实现。<br>基于MPLS的VPN支持不同分支间的IP地址复用，并支持不同VPN间互通。与传统的路由相比，VPN路由中需要增加分支和VPN的标识信息，这就需要对BGP协议进行扩展，以携带VPN路由信息。</li>
</ul>
]]></content>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title>shell_tips_tricks</title>
    <url>/2021/02/20/shell-tips-tricks/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>这篇文章用来记录shell的一些使用技巧，使用场景</p>
<span id="more"></span>

<h1 id="Tips-amp-Tricks"><a href="#Tips-amp-Tricks" class="headerlink" title="Tips &amp; Tricks"></a>Tips &amp; Tricks</h1><h2 id="获取shell脚本所在的目录"><a href="#获取shell脚本所在的目录" class="headerlink" title="获取shell脚本所在的目录"></a>获取shell脚本所在的目录</h2><p><code>dirname &quot;$(realpath &quot;$(BASH_SOURC[0])&quot;)&quot;</code><br>$0或者$(BASH_SOURC[0])表示当前脚本，<code>realpath</code>获取脚本的绝对路径，<code>dirname</code>将文件名的最后一个组件去掉。</p>
]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell变量</title>
    <url>/2021/02/22/shell%E5%8F%98%E9%87%8F/</url>
    <content><![CDATA[<ul>
<li><a href="#shell%E5%8F%98%E9%87%8F">shell变量</a></li>
<li><a href="#%E5%8F%98%E9%87%8F%E7%9B%B8%E5%85%B3%E7%9A%84%E4%B8%80%E4%BA%9B%E5%91%BD%E4%BB%A4">变量相关的一些命令</a></li>
<li><a href="#%E7%89%B9%E6%AE%8A%E5%8F%98%E9%87%8F">特殊变量</a></li>
<li><a href="#%E5%B8%B8%E8%A7%81%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F">常见环境变量</a></li>
</ul>
<h1 id="shell变量"><a href="#shell变量" class="headerlink" title="shell变量"></a>shell变量</h1><p>标准的UNIX变量分为两类，环境变量和shell变量。广义上而言，<code>shell变量</code>只应用于当前的shell实例，是用来设置短期工作情况的; <code>环境变量</code>有更长远的意义，这些变量在登录时设置，在整个会话期都是有效的。一般约定，环境变量使用大写变量表示，shell变量使用小写表示。</p>
<span id="more"></span>

<p>通过<code>printenv</code>命令列出所有的环境变量，<code>set</code>命令列出所有的shell变量。环境变量中存储的更多是永久性的变量,例如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HOME&#x3D;&#x2F;home&#x2F;rancho</span><br></pre></td></tr></table></figure>
<p>这些变量很少改变，而shell变量存储本地的、临时性的、shell特有的变量,如：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">PWD&#x3D;&#x2F;tmp            #切换到不同的文件夹下查看该变量，该变量的值就是pwd命令的打印</span><br></pre></td></tr></table></figure>

<p>shell变量是shell专有的变量，不会被子进程继承，环境变量才会被继承。</p>
<h1 id="变量相关的一些命令"><a href="#变量相关的一些命令" class="headerlink" title="变量相关的一些命令"></a>变量相关的一些命令</h1><p>对于几个关于变量的命令的说明：</p>
<ul>
<li>set             设置和显示shell变量（包括环境变量，shell变量，函数定义, 等效于declare</li>
<li>env,printenv    显示环境变量</li>
<li>export          将shell变量导出为环境变量, 显示导出成环境变量的shell变量，并显示变量属性，等效于declare -x</li>
</ul>
<p>对于变量，其核心的点</p>
<ul>
<li>变量对应的值</li>
<li>变量的作用域</li>
</ul>
<p>其中，shell变量的值只能为字符串，可以用<code>declare -i</code>强制声明为数值、<br>关于变量作用域：<br>shell变量与环境变量的作用域差异主要体现在子shell继承上面；<code>source</code>或<code>.</code>与直接执行脚本的作用域差异主要体现在对当前shell环境的设置上面<br>shell命令行或shell脚本中定义的变量均为全局的，哪怕是在shell函数中定义的变量也是全局的shell变量，这与其它编程语言不同，在shell函数中使用内建命令<code>local</code>声明的变量作用域只在函数中，<code>local</code>命令也只能在函数中使用<br>同时，这一点也是很合理的，对于普通程序，如<code>ls</code>，程序执行完内存就释放了，所以里面的变量都没了；而<code>bash</code>本身也是一个程序，它并没有结束，所以里面的变量还在，如果你<code>exit</code>退出了，变量也就没了。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancho ~]$ type -t local</span><br><span class="line">builtin</span><br><span class="line">[rancho ~]$ local a&#x3D;10</span><br><span class="line">-bash: local: can only be used in a function</span><br></pre></td></tr></table></figure>
<p>如果变量的作用域只想在脚本内生效，使用完之后用<code>unset</code>将之释放</p>
<p>此外，使用<code>var=value cmd</code>方式定义的变量作用域只在cmd的执行环境中。</p>
<h1 id="特殊变量"><a href="#特殊变量" class="headerlink" title="特殊变量"></a>特殊变量</h1><p>shell上有一些特殊变量，这些变量由shell自身动态维护，不允许用户手动修改。</p>
<p>这些特殊变量没有变量名，而是使用变量引用去使用这些变量。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$1,$2,$N：          脚本的位置参数</span><br><span class="line">$0:                 shell或shell脚本的名称，注意BASH_SOURCE变量</span><br><span class="line">$*:                 扩展为位置参数，“$*”等价于“$1 $2 $3 ... $N”</span><br><span class="line">$@:                 扩展为位置参数，“$@”等价于“$1” &quot;$2&quot; &quot;$3&quot; ... &quot;$N&quot;</span><br><span class="line">$#:                 位置参数的个数</span><br><span class="line">$$:                 当前shell进程的PID，在某些shell(如小括号开启的子shell)下会被继承。注意BASHPID变量</span><br><span class="line">$?:                 最近一个前台命令的退出状态码</span><br><span class="line">$!:                 最近一个后台命令的退出代码</span><br><span class="line">$-:                 当前shell环境的一些特殊设置，如是否是交互式，一般是himBH, 比如可以设置set -x,变成himxBH，取消set +x</span><br></pre></td></tr></table></figure>

<h1 id="常见环境变量"><a href="#常见环境变量" class="headerlink" title="常见环境变量"></a>常见环境变量</h1><p><code>$TERM</code>变量表示终端类型，值会是以下之一：</p>
<ul>
<li>xterm             一般是这个值</li>
<li>vt220             是xterm的子集，不支持颜色，可以top命令后输入z测试</li>
<li>xterm-color       如果在老系统，并且屏幕颜色不对时用这个类型</li>
<li>putty,konsole     使用终端模拟器</li>
<li>screen            if running inside GNU screen（or tmux）</li>
<li>linux             通过linux串口登录 ctrl+alt+f1</li>
</ul>
]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell核心机制之子shell与shell环境</title>
    <url>/2021/02/22/shell%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6%E4%B9%8B%E5%AD%90shell%E4%B8%8Eshell%E7%8E%AF%E5%A2%83/</url>
    <content><![CDATA[<h1 id="深入了解shell必备的两个知识点"><a href="#深入了解shell必备的两个知识点" class="headerlink" title="深入了解shell必备的两个知识点"></a>深入了解shell必备的两个知识点</h1><p>子shell与shell环境是深入了解shell所必备的两个知识点。shell的实现方式有多种，如bash，sh，zsh等，这些软件本质就是一个shell解释器，最常用的是bash，因为其在几乎所有的Linux发行版中都预安装了。<br>子shell是shell命令的运行机制，而shell环境是shell命令的运行环境，就是我们常说的环境变量了。</p>
<span id="more"></span>
<h1 id="命令类型与子shell"><a href="#命令类型与子shell" class="headerlink" title="命令类型与子shell"></a>命令类型与子shell</h1><p>并不是在shell里执行的所有命令都会在子shell里执行，我们需要先认识一下shell命令分类。</p>
<p><code>type</code>命令可以可以显示出命令的类型，对于不同的类型shell解释器有不同的处理方式。命令类型有以下几种：</p>
<ul>
<li>alias(shell alias)</li>
<li>function(shell functions)，shell函数</li>
<li>builtin(shell builtin)，shell内建命令</li>
<li>file(disk file)，磁盘文件，需要有可执行权限，我们安装的第三方软件一般就是这种类型，在PATH下找到，这个是外部命令，如ssh、ls</li>
<li>keyword(shell reserved word)，shell保留关键字，如for、done、while等，在shell脚本中很常用</li>
</ul>
<p><code>type</code>的常用参数如下</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-t      打印命令类型，上述5种类型之一</span><br><span class="line">-a      打印所有包含该命令的文件位置</span><br></pre></td></tr></table></figure>

<p>shell对于不同的命令类型，处理方式如下：</p>
<ul>
<li>file(外部命令)的执行：先fork shell子进程，在后在子shell进程中exec调用外部命令</li>
<li>function、builtin、keyword: 这些命令依赖于shell进程，没有shell进程，他们都没有意义。他们都是直接在当前shell进程内执行的，不会创建新的子shell进程来执行</li>
<li>alias:在命令解析阶段替换成对应的内容，然后重新执行命令解析</li>
</ul>
<p>当alias、keyword、function、builtion、file冲突时，会按照优先级进行执行，优先级从左至右依次递减。</p>
<p>对于使用子shell方式执行cmd</p>
<ol>
<li>当前shell进程fork创建一个子shell进程，子shell继承父shell大量属性，如变量</li>
<li>子shell进程通过exec调用执行cmd, 并用cmd代码替换刚才创建的子shell进程(子shell进程继承自父shell进程的属性会被覆盖)，于是子shell进程就变成cmd进程，所以父shell的子进程变成了cmd进程</li>
<li>父shell进程wait子cmd进程退出</li>
</ol>
<p>伪代码描述如下, 以执行<code>ls -lah</code>命令为例：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pid &#x3D; fork();</span><br><span class="line">if(pid &#x3D;&#x3D; 0 ) &#123;</span><br><span class="line">    &#x2F;&#x2F;子进程中，调用exec</span><br><span class="line">    exec(&quot;ls -lah&quot;)</span><br><span class="line">&#125; else if (pid &gt; 0) &#123;</span><br><span class="line">    &#x2F;&#x2F;父进程中，waitpid等待子进程退出</span><br><span class="line">    waitpid(pid);</span><br><span class="line">&#125; </span><br></pre></td></tr></table></figure>

<p>通过<code>$BASHPID</code>可以查看当前bash进程的pid，从而判断在那个shell(父还是子).</p>
<h1 id="shell命令的运行环境"><a href="#shell命令的运行环境" class="headerlink" title="shell命令的运行环境"></a>shell命令的运行环境</h1><p>每个shell进程有一个自己的运行环境，不同的shell进程有不同的shell环境。shell解析命令行、调用命令行的过程都在这个环境中完成。</p>
<p>shell运行环境由配置文件来完成初始化，bash会读取的配置文件有：</p>
<ul>
<li>/etc/profile</li>
<li>/etc/profile.d/*.sh</li>
<li>~/.bash_profile</li>
<li>~/.bashrc</li>
<li>/etc/bashrc</li>
</ul>
<p>shell分为login shell、non-login shell与interactive shell、non-interactive shell，不同的shell加载的配置文件是不同的。</p>
<p>环境主要体现在对环境的设置，包括但不限于环境的设置有：</p>
<ul>
<li><code>cd /tmp</code>表示设置当前shell环境的工作目录</li>
<li>shopt或set命令进行shell的功能设置，可在配置文件中找到相关设置</li>
<li>环境变量设置<ul>
<li>主要用于shell进程和其子进程之间的数据传递</li>
<li>子进程（不仅仅是子shell进程）可以继承父shell环境中的环境变量</li>
<li>环境变量通常以大写字母定义，非一定</li>
<li>使用bash内置命令<code>export</code>可以定义环境变量</li>
<li>命令前定义变量<code>var=value cmd</code>，表示定义一个专属环境变量，该环境变量只能在cmd进程环境中可以访问，cmd进程退出后，var环境变量也消失</li>
</ul>
</li>
<li><code>export var=value</code>表示在当前shell环境下定义一个环境变量var，以便让子进程继承这个变量</li>
</ul>
<p>每当提到shell内置命令，就要想到这个命令的作用有可能是在当前shell环境下进行某项设置<br>shell内置命令不会创建新进程，而是直接在当前shell环境内部执行<br>内置命令<code>source</code>或<code>.</code>执行脚本时，表示在当前shell环境下执行脚本内容，即脚本中所有设置操作都会直接作用于当前shell环境<br>父shell环境可能影响子shell环境，但子shell环境一定不影响父shell环境，比如子shell脚本中的环境变量不会粘滞到父shell环境中</p>
<h2 id="shell环境-属性设置"><a href="#shell环境-属性设置" class="headerlink" title="shell环境/属性设置"></a>shell环境/属性设置</h2><p><code>bash</code>也是一个程序，一个命令，它可以通过设置选项来修改其某些属性，这些属性可以提高bash的安全性和可维护性。</p>
<ul>
<li>-u        遇到未定义的变量抛出错误，bash默认忽略它，当作空来处理</li>
<li>-x        显示bash执行的执行命令，在前面用<code>+</code>来区分命令和命令的输出；如果遇到-u的错误，不会打印该命令(测试所得)</li>
<li>-e        脚本发生错误，终止执行</li>
</ul>
<p>这里注意一个特殊场景即管道命令，bash会把管道命令最后一个子命令的返回值作为整个命令的返回值，也就是说，只要最后一个命令不失败，管道命令总是会执行成功。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line">set -eux</span><br><span class="line">demo | echo adsad</span><br><span class="line">echo afe</span><br></pre></td></tr></table></figure>
<p>此处<code>demo</code>未定义，执行失败，但是<code>echo adsad</code>会执行成功，所以管道命令<code>demo | echo adsad</code>的返回值是<code>0</code>,脚本接下来的命令<code>echo afe</code>会继续执行，<code>set -e</code>在这里就失效了。使用<code>set -o pipefaile</code>可以解决这种情况，只要一个子命令失败，整个管道命令就失败，脚本就会终止执行。注意配合<code>set -e</code>一起使用才会生效，即<code>set -o pipeline</code>是<code>set -e</code>的一个补丁。</p>
<p>养成好习惯，在所有bash脚本开头加上</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set -euxo pipefail</span><br></pre></td></tr></table></figure>

<p>如果有意让退出状态不为0的程序使用<code>cmd || true</code></p>
<p>此外，shell可以关闭模式扩展</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">set -o noglob</span><br><span class="line">或者</span><br><span class="line">set -f</span><br></pre></td></tr></table></figure>

<h1 id="关于引号"><a href="#关于引号" class="headerlink" title="关于引号"></a>关于引号</h1><p>子shell和shell环境是shell机制方面的核心，其实引号在shell中的重要性与之可比肩。<br>在许多编程语言中，引号被用来表明：包含在里面的文本会被解析成字符串。但是在shell中，只有一种数据类型就是字符串。因此，字符串相关的引号和转义，对bash来说就非常重要。</p>
<p>引号的功能：</p>
<ul>
<li>防止保留字符被替换，如<code>echo &#39;$&#39;</code></li>
<li>防止域分割和通配符，如包含空格的文件名</li>
<li>参数扩展，如<code>&quot;$@&quot;</code></li>
</ul>
<p>有三种标准的引号(如果算上转义是4种)，和2种非标准的bash扩展用法。</p>
<ul>
<li>单引号(single quotes)：移除在单引号之间所有字符的特殊含义, 避免被bash自动扩展。单引号之间的所有东东都会变成字符串(literal string)，唯一不能安全的被单引号修饰的字符就是单引号本身，即使使用了转义符也不行</li>
<li>双引号(double quotes)：双引号中不会进行文件名扩展，但是三个字符除外<code>$</code> <code>反引号</code> <code>\</code>，如果开启了<code>!</code>引用历史命令，则<code>!</code>也除外。大部分特殊字符在双引号中会失去特殊含义，变成普通字符，如<code>*</code></li>
<li>反引号(<code>backticks</code>)：这是命令替换语法的遗产，现在使用<code>$(...)</code>替代，但因为历史问题，现在依然被允许使用</li>
<li>转义符()：将<code>\</code>放在元字符($、&amp;、*、)前面去掉其特殊含义，如 <code>echo \$？</code>, 在双引号和没有引号中有效，在单引号中无效.反斜杠除了用于转义，还可以表示一些不可打印的字符<ul>
<li>\a    响铃</li>
<li>\b    退格</li>
<li>\n    换行</li>
<li>\r    回车</li>
<li>\t    制表符<br>所以在命令结尾结尾加上<code>\</code>，其实就是在换行符前加上转义，使得换行符变成一个普通字符，bash会将其当作空格处理，从而可以将一行命令写成多行。</li>
</ul>
</li>
</ul>
<p>这里举一个<code>find</code>使用的小例子：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancho test]$ ls</span><br><span class="line">a.c  c  deb  kernel  linux  make  python  shell</span><br><span class="line"></span><br><span class="line">[rancho test]$ find .&#x2F; -name &quot;*.c&quot;</span><br><span class="line">.&#x2F;shell&#x2F;a.c</span><br><span class="line">.&#x2F;shell&#x2F;b.c</span><br><span class="line">.&#x2F;a.c</span><br><span class="line">.&#x2F;deb&#x2F;zhw-1.0.0&#x2F;a.c</span><br><span class="line">.&#x2F;python&#x2F;a.c</span><br><span class="line">.&#x2F;linux&#x2F;a.c</span><br><span class="line">.&#x2F;c&#x2F;syntax.c</span><br><span class="line"></span><br><span class="line">[rancho test]$ find .&#x2F; -name *.c</span><br><span class="line">.&#x2F;shell&#x2F;a.c</span><br><span class="line">.&#x2F;a.c</span><br><span class="line">.&#x2F;deb&#x2F;zhw-1.0.0&#x2F;a.c</span><br><span class="line">.&#x2F;python&#x2F;a.c</span><br><span class="line">.&#x2F;linux&#x2F;a.c</span><br><span class="line">[rancho test]$ </span><br></pre></td></tr></table></figure>
<p>第一次使用find，传给它的参数是<code>*.c</code>，find会在当前目录下面去找所有以<code>.c</code>结尾的文件<br>第二次使用find, 传给它的参数是<code>a.c</code>，注意当前目录下面有<code>a.c</code>，所以<code>*.c</code>会被shell模式扩展为<code>a.c</code>；如果当前目录下没有<code>.c</code>文件，则扩展失败，原样输出<code>*.c</code>，这时候和用双引号修饰效果是一样的。<br>shell模式扩展完之后才会调用命令，所以一定要主要哪些词元是给shell做模式扩展的，哪些是直接传递给命令的，我们通过引号进行标识告知bash。</p>
<h1 id="shell核心知识点"><a href="#shell核心知识点" class="headerlink" title="shell核心知识点"></a>shell核心知识点</h1><p>最开始是想记录下<code>子shell</code>与<code>shell环境</code>这两个知识点的，后来越来越多的发现自己不知道某些知识点或者知识点认识模糊，shell笔记也有好几个文件了，这里列举一下shell中比较重要的知识点。</p>
<ul>
<li>子shell</li>
<li>shell命令执行环境</li>
<li>模式扩展(通配符扩展、变量扩展、子命令扩展、算术扩展)，expansion，globbing and word splitting</li>
<li>引用(引号和转义)</li>
<li>shell变量(变量引用，变量替换)</li>
<li>退出和退出状态</li>
<li>各种test(文件测试、字符串测试、数值测试)</li>
<li>循环和分支</li>
<li>shellcheck   这个并不是shell的知识点，而是一个shell脚本的检查工具，python，C都有这种检查工具，可以很好的帮我们检查一些通用的易错的语法问题，强烈建议使用</li>
</ul>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://wangdoc.com/bash/">Bash脚本教程</a><br><a href="https://google.github.io/styleguide/shellguide.html">Google shell脚本代码规法</a><br><a href="https://coolshell.cn/articles/19219.html">打造高效工作环境-shell篇</a></p>
]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell脚本执行的几种方式</title>
    <url>/2021/02/20/shell%E8%84%9A%E6%9C%AC%E6%89%A7%E8%A1%8C%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<h1 id="shell脚本执行的几种方式"><a href="#shell脚本执行的几种方式" class="headerlink" title="shell脚本执行的几种方式"></a>shell脚本执行的几种方式</h1><p>shell脚本有三种执行方式</p>
<span id="more"></span>
<h2 id="filename-或-filename"><a href="#filename-或-filename" class="headerlink" title="./filename 或 filename"></a>./filename 或 filename</h2><p>这种方式是我们在CLI中最常使用的方式，要求脚本具有<em>可执行</em>权限。类似于执行二进制程序，需要让shell找到文件的具体位置。这种执行方式是重新启动一个子shell，在子shell中执行此脚本。子shell继承父shell的环境变量，但子shell新建的、改变的变量不会带回父shell，除非使用export。</p>
<h2 id="source-filename-或-filename"><a href="#source-filename-或-filename" class="headerlink" title="source filename 或 . filename"></a>source filename 或 . filename</h2><p>这种方式一般用在脚本中定义shell环境变量，比如修改<code>.bashrc</code>后使用source执行一下，将改动生效到当前shell中。<br>这个命令其实只是简单的读取脚本里面的语句依次在当前shell里面执行，没有新建子shell。脚本里面所有新建、改变变量的语句都会保存在当前shell里面。</p>
<h2 id="bash-filename-或-sh-filename，两者等效"><a href="#bash-filename-或-sh-filename，两者等效" class="headerlink" title="bash filename 或 sh filename，两者等效"></a>bash filename 或 sh filename，两者等效</h2><p>这种方式与./filename执行方式的唯一区别是，filename不需要可执行权限。</p>
<h1 id="关于-0和BASH-SOURCE"><a href="#关于-0和BASH-SOURCE" class="headerlink" title="关于$0和BASH_SOURCE"></a>关于$0和BASH_SOURCE</h1><p><code>$0</code>保存了被执行脚本的程序名称, 在脚本中<code>basename $0</code>可以获取脚本的文件名。用source方式执行的脚本不适用，$0为<code>-bash</code>。<br>但是，除了$0之外，bash还提供了一个数组变量<code>BASH_SOURCE</code>,程序名以入栈的方式存储在BASH_SOURCE中，即最后一个执行的脚本是BASH_SOURCE[0]或BASH_SOURCE，等价于$0。<br>在嵌套脚本的调用中，使用<code>BASH_SOURCE[0]</code>获取当前脚本的路径，使用<code>BASH_SOURCE[-1]</code>或<code>$0</code>获取顶层脚本的路径</p>
]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell语法简析</title>
    <url>/2021/02/20/shell%E8%AF%AD%E6%B3%95%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<h1 id="问题说明"><a href="#问题说明" class="headerlink" title="问题说明"></a>问题说明</h1><p>在shell下遇到一个赋值的问题</p>
<span id="more"></span>

<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancho ~]$ a&#x3D;10</span><br><span class="line">[rancho ~]$ demo$a&#x3D;$(echo 123)</span><br><span class="line">demo10&#x3D;123: command not found</span><br></pre></td></tr></table></figure>

<h1 id="shell下的命令格式"><a href="#shell下的命令格式" class="headerlink" title="shell下的命令格式"></a>shell下的命令格式</h1><p>shell下我们常用的命令格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var&#x3D;value           #变量赋值，例如a&#x3D;1</span><br><span class="line">cmd [args]          #命令执行，例如ls -l</span><br><span class="line">&gt;redirection        #重定向,例如:&gt;a.c </span><br></pre></td></tr></table></figure>

<p>实际上，bash中的一个简单命令的完整格式如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">var&#x3D;value ... cmd args &gt;redirection ...</span><br></pre></td></tr></table></figure>
<p>一个完整的简单命令由三部分组成：变量赋值部分、命令和参数部分、重定向部分，只是很多时候我们会省略一些部分的内容。<br>其中：</p>
<ul>
<li>变量赋值和重定向可以有多个</li>
<li>变量赋值必须在cmd前面，并且变量名必须符合bash要求的命令规则<ul>
<li>定义变量时，普通变量名是字母、数字、下划线的组合，且不能以数字开头</li>
<li>调用变量时，在变量名前加<code>$</code>，shell有一部分特殊变量如<code>$0 $1 $$</code></li>
</ul>
</li>
</ul>
<p>对于变量赋值：</p>
<ul>
<li>如果有变量赋值而没有命令执行部分，则变量赋值在当前shell下生效</li>
<li>如果有变量赋值也有命令执行部分，则变量赋值只作用于改命令，对当前shell无影响</li>
<li>如果变量名不符合bash的命令规范，则不认为是变量赋值语句，而是当作cmd部分</li>
</ul>
<h1 id="问题说明-1"><a href="#问题说明-1" class="headerlink" title="问题说明"></a>问题说明</h1><p><code>demo$a</code>不是一个有效的变量名，所以会当作cmd来执行，但是在执行之前会从左到右执行shell命令解析规则，得到<code>demo10=123</code>，之后将其作为命令进行执行，找不到改命令从而报错。类似的，输入<code>123das=10</code>也会报这种错误。</p>
]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>shell重定向</title>
    <url>/2021/02/23/shell%E9%87%8D%E5%AE%9A%E5%90%91/</url>
    <content><![CDATA[<h1 id="shell重定向"><a href="#shell重定向" class="headerlink" title="shell重定向"></a>shell重定向</h1><p>shell重定向即重新确定数据的流向，是通过改变文件描述符目标来实现的，如流向<code>1</code>的数据让其流向<code>/tmp/a.c</code>。</p>
<span id="more"></span>
<p>shell中，基础重定向有以下几种方式：</p>
<ul>
<li><p><code>[n]&gt;file</code>：覆盖式输出重定向，输出到fd=n的数据改变流向输出到file文件中，file不存在则创建，file存在则先清空再写入数据</p>
<ul>
<li>n可省略，默认值为<code>1</code>，即标准输出覆盖重定向到file中</li>
<li><code>&gt;&gt;</code>表示追加式输出重定向</li>
</ul>
</li>
<li><p><code>[n]&lt;file</code>:输入重定向，以读取模式打开文件并分配fd=n,file不存在则报错</p>
<ul>
<li>n可省略，默认值为0，即直接冲file中读数据</li>
<li>通常程序只是从0中都数据，所以当n不等于0时，需要多做一步<code>3&lt;file &lt;&amp;3</code></li>
</ul>
</li>
</ul>
<p><code>cat</code>命令中经常使用到重定向，要明白<code>cat file</code>和<code>cat &lt;file</code>的区别。cat命令会读取指定的文件然后输出到标准输出，如果没有指定，则从标准输入读取数字符，然后输出字符。<code>cat file</code>是直接读取file这个文件中的内容，<code>cat &lt;file</code>是file文件被读取后内容重定向到标准输入，然后cat从标准输入读取到里面的数据，虽然结果都一样，但是里面的内容不一样。一个很经典的在shell脚本中创建配置文件的方式：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">cat &lt;&lt;EOF&gt;a.c           #这一行的EOF表示doc的起始符</span><br><span class="line">zhw</span><br><span class="line">wan</span><br><span class="line">EOF                     #这一行的doc表示doc的终止符，前后必须一致</span><br></pre></td></tr></table></figure>

<p>这里需要解释一下，输入重定向是<code>&lt;</code>，除此之外，还有<code>&lt;&lt;</code>与<code>&lt;&lt;&lt;</code>，我们一般也就用到<code>&lt;&lt;</code>.<br><code>&lt;&lt;</code>符号表示here doc。也就是说，它后面跟的是一篇文档，就像一个文件一样，只不过这个文件的内容是临时定义在<code>&lt;&lt;</code>符号后面的。here doc常用语指定多行数据输入。<br>既然是文档，就有文档的起始符和终止符，这中间的内容全部是文档的内容，文档内容会被作为标准输入的数据读取。起始符和终止符可以随意定义，但是前后必须一致，一般用<code>EOF</code>来表示。</p>
<p><code>&lt;&lt;&lt;</code>表示here string,即后面跟的是字符串，注意</p>
<ul>
<li>双引号包围的字符串shell会对其进行解释</li>
<li>单引号包围的字符串shell不会对其进行解释</li>
</ul>
<p>在脚本中创建配置文件还可以使用<code>tee</code>命令,tee从标准输入中读取数据，然后写到标准输出和0或多个文件中去。换言之，tee可以实现数据多重定向。实现如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">tee a.c &lt;&lt;EOF</span><br><span class="line">zhw</span><br><span class="line">wan</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure>]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>sonic-testbed的理解</title>
    <url>/2021/03/02/sonic-testbed%E7%9A%84%E7%90%86%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>这篇文章用来记录对sonic testbed的一些理解以及一些较核心的知识点。</p>
<span id="more"></span>

<p>sonic-mgmt代码运行在docker-sonic-mgmt环境中中，镜像在sonic-buildimage中编译生成，docker-ptf也是在里面生成的。docker-sonic-mgmt环境集成了ansible-playbook、pytest、spytest等所需的依赖。</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>一些shell基础知识</title>
    <url>/2020/03/06/%E4%B8%80%E4%BA%9Bshell%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>最开始接触到的命令行是windows的cmd，一次用它来查ip感觉很神奇。后来接触到Linux，vim，从起初的抵触不适应，到后来的得心应手。使用命令行，离计算机更近。这篇文章记录一下shell下面的一些细节。分为</p>
<span id="more"></span>
<ol>
<li>标准输入和命令参数的区别</li>
<li>在后台运行的命令退出终端也就全部退出了</li>
<li>单引号和双引号表示字符串的区别</li>
<li>有的命令和<code>sudo</code>一起用就<code>command not found</code></li>
</ol>
<h1 id="标准输入和参数的区别"><a href="#标准输入和参数的区别" class="headerlink" title="标准输入和参数的区别"></a>标准输入和参数的区别</h1><p>最初遇到这个问题的时候是在shell下面使用<code>管道</code>操作，例如：<code>find ./ -name &quot;*.c&quot; | xargs grep -rn zhw</code>,这条命令的含义是：在当前路径下的所有<code>.c</code>文件中查找<code>zhw</code>关键字，注意这里在管道的右侧加了关键字<code>xargs</code>，表示将<code>find</code>找到的结果作为<em>参数</em>传递给<code>grep</code>，grep是不接受标准输入的。</p>
<p>标准输入就是编程语言中诸如<code>scanf</code>或者<code>readline</code>获取到的信息；而参数是指程序的<code>main</code>函数传入的<code>args</code>字符串数组。管道符和重定向符都是将数据作为程序的标准输入，下面这个示例：<br><img src="https://rancho333.gitee.io/pictures/grep.png"></p>
<ol>
<li>grep要搜索的文件作为参数是可选的，<code>-r</code>可以在当前路径下递归查找</li>
<li>find不加xargs和直接grep效果是一样的，说明没有指定查找文件，而使用xargs则指定了查找文件作为参数传递给grep</li>
</ol>
<p>这里多说一点：<br><img src="https://rancho333.gitee.io/pictures/find.png"><br>通常使用find命令查找特定的文件，然后再这些文件中用grep去匹配关键字，但是如果find的结果是空，那么通过xargs方式就相当于没有给grep指明特定查找文件（它就会在当前目录递归）,而通过<code>-exec</code>则表示对匹配的文件执行该参数所给出的shell命令，此时grep实际并没有执行，这才符合我们的预期结果。</p>
<p>上面两个小例子，理解问题的本质是多么的重要，基础打牢固，花哨的东西就随便玩了！<br>除了<code>xargs</code>可以读取数据作为命令参数外，通过<code>$(cmd)</code>形式也能达到同样的效果，例如：<br><img src="https://rancho333.gitee.io/pictures/grep.png"></p>
<p><code>$(cmd)</code>读取<code>cmd</code>命令输出的数据作为参数。</p>
<p>最后说一下如何区分命令能够接受标准输入还是参数：如果命令能够让终端阻塞，说明该命令能接受标准输入，反之就是不接受。<code>rm</code>命令是不接受标准输入的。<br><img src="https://rancho333.gitee.io/pictures/block.png"></p>
<h1 id="后台运行程序"><a href="#后台运行程序" class="headerlink" title="后台运行程序"></a>后台运行程序</h1><p>如果一些服务需要长时间运行，比如main函数里面有个<code>while(1)</code>的死循环，程序运行后命令行会阻塞。在命令后加上<code>&amp;</code>后程序就可以在后台运行而不会阻塞命令行。底层的原理或者说这是怎么实现的呢？</p>
<p>每一个命令行终端都是一个shell进程，每当有命令需要执行是shell会fork一个子进程去执行命令，而shell进程会阻塞，等待子shell进程退出才重新响应。写一个很简单的demo</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">void main()                                                                                           </span><br><span class="line">&#123;</span><br><span class="line">    while(1)</span><br><span class="line">    &#123;&#125;  </span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>加上<code>&amp;</code>后，只是让shell进程不再阻塞，可以继续响应你的新命令，但是当你关掉这个shell命令行中终端后，依附于它的所有子进程都会退出。如下：<br><img src="https://rancho333.gitee.io/pictures/ps.png"><br>但是如果<code>(cmd &amp;)</code>这样来运行命令，则是将<code>cmd</code>挂到一个<code>systemd</code>系统守护进程下，这样即使当终端退出后，对于刚才的命令也没有影响。如下：<br><img src="https://rancho333.gitee.io/pictures/nohup.png"><br>不过<code>nohup cmd &amp;</code>的做法似乎常见一些，原理类似。此外还可以试试<code>tmux</code>这个小工具，如果利用晚上的时候在服务器编译大型项目，这玩意挺好用的，不用担心断网（终端被kill）。</p>
<h1 id="单引号和双引号的区别"><a href="#单引号和双引号的区别" class="headerlink" title="单引号和双引号的区别"></a>单引号和双引号的区别</h1><p>使用<code>set -x</code>命令，可以开启shell的命令回显。</p>
<p>对于单引号：所见即所得，会将单引号内的内容原样输出</p>
<p>对于双引号：把双引号内的内容输出出来；如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容来。</p>
<p>不加引号：不会将含有空格的字符串视为一个整体输出, 如果内容中有命令、变量等，会先把变量、命令解析出结果，然后在输出最终内容来，如果字符串中带有空格等特殊字符，则不能完整的输出，需要改加双引号，一般连续的字符串，数字，路径等可以用。所以在写shell脚本的时候一定注意使用小括号和双引号哈！</p>
<p>示例如下：<br><img src="https://rancho333.gitee.io/pictures/ds.png"></p>
<h1 id="sudo-找不到命令"><a href="#sudo-找不到命令" class="headerlink" title="sudo 找不到命令"></a>sudo 找不到命令</h1><p>有时候普通用户可以印的命令，加上<code>sudo</code>之后却报错<code>command not found</code>，原因在于这个命令仅存在与该用户的环境变量PATH中。解决方法是：</p>
<ol>
<li>使用绝对路径调用命令</li>
<li>将命令添加到需要使用的用户的环境变量中<br>同样的道理，root用户或其他用户的命令另外一些用户也可能找不到。</li>
</ol>
<p>参考资料：<br><a href="https://mp.weixin.qq.com/s/Nj58VYQc955bFukrt4Jm2Q">关于Linux shell你必须知道的</a></p>
]]></content>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title>中断学习</title>
    <url>/2020/03/10/%E4%B8%AD%E6%96%AD%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>在ENOS系统移植的过程中需要调试CPU和交换芯片的中断，这里记录一下对中断的学习！</p>
<span id="more"></span>
<h1 id="中断简介"><a href="#中断简介" class="headerlink" title="中断简介"></a>中断简介</h1><p>Linux内核需要对连接到计算机上的所有硬件设备进行管理，他们之间需要互相通信，一般有两种方案可以实现。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 轮询（polling）内核定期对设备的状态进行查询，然后做出相应的处理</span><br><span class="line">2. 中断（interrupt）让硬件在需要的时候向内核发出信号（变内核主动为硬件主动）</span><br></pre></td></tr></table></figure>
<p>轮询是周期性的重复执行，大量耗用CPU的时间，效率比较低，对于实时性比较高的操作，肯定是不适用的。</p>
<p>从物理学的角度看，中断是一种电信号，由硬件设备产生，并直接送入中断控制器（如8259A）的输入引脚上，然后再由中断控制器向CPU发送相应的信号。处理器检测到该信号，便中断当前正在处理的工作，转而去处理中断。对于软件开发人员，一般需要用到的就是中断号和中断处理函数。</p>
<p>提一下，PCIE可以通过MSI(message signaled interrupts)方式实现中断：<br><img src="https://rancho333.gitee.io/pictures/msi.png"><br>CPu里面有一段特殊的寄存器空间，往这个寄存器里面写数据，就会触发CPU中断。pci设备经过配置以后，一旦需要上报中断就会往cpu这种寄存器里面写一个值，触发cpu中断。</p>
<p>中断的处理流程：</p>
<ol>
<li>保存现场</li>
<li>执行中断</li>
<li>恢复被中断进程的现场，继续执行</li>
</ol>
<h2 id="中断分类"><a href="#中断分类" class="headerlink" title="中断分类"></a>中断分类</h2><p>中断可分为同步（synchronous）中断和异步（asynchronous）中断：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">1. 同步中断是当指令执行时由CPU控制单元产生，之所以称为同步，是因为只有在一条指令执行完毕后CPU才会发出中断，而不是在代码指令执行期间，比如系统调用</span><br><span class="line">2. 异步中断是指由其他硬件设备依照CPU时钟信号随机产生，即意味着中断能够在指令之间产生，例如键盘中断</span><br></pre></td></tr></table></figure>
<p>同步中断称为异常（exception），异常可分为故障（fault）、陷阱（trap）、终止（abort）三类。<br>异步中断被称为中断（interrupt）,中断可分为可屏蔽中断（Maskable interrupt，外部设备产生的）和非屏蔽中断（Nomaskable interrupt，计算机内部硬件产生的）<br>异常是CPU发出的中断信号，与中断控制器无关，不能被屏蔽。</p>
<p>广义上讲中断可分为四类：中断、故障、陷阱、终止。它们之间的异同点参照下表。</p>
<table>
<thead>
<tr>
<th align="left">类别</th>
<th align="left">原因</th>
<th align="left">异步/同步</th>
<th align="left">返回行为</th>
</tr>
</thead>
<tbody><tr>
<td align="left">中断</td>
<td align="left">来自I/O设备的信号</td>
<td align="left">异步</td>
<td align="left">总是返回到下一条指令</td>
</tr>
<tr>
<td align="left">陷阱</td>
<td align="left">有意的异常</td>
<td align="left">同步</td>
<td align="left">总是返回到下一条指令</td>
</tr>
<tr>
<td align="left">故障</td>
<td align="left">潜在可恢复的错误</td>
<td align="left">同步</td>
<td align="left">返回到当前指令</td>
</tr>
<tr>
<td align="left">终止</td>
<td align="left">不可恢复的错误</td>
<td align="left">同步</td>
<td align="left">不会返回</td>
</tr>
</tbody></table>
<h2 id="中断控制器"><a href="#中断控制器" class="headerlink" title="中断控制器"></a>中断控制器</h2><p>常见的中断控制器有两种，两片8259A外部芯片’级联’和多级I/O APIC系统，见下图：<br><img src="https://rancho333.gitee.io/pictures/interrupt_ctl.png"><br>至于硬件实现细节这里不做过多描述。辨别一个系统是否正在使用I/O APIC，可以使用如下命令查看：<br><img src="https://rancho333.gitee.io/pictures/interrupts.png"><br>可以看到第6列上显示的是IO-APIC,如果上面显示的是XY-APIC，说明系统正在使用8259A芯片。<br>对上面文件的输出，解释如下：</p>
<ol>
<li>第一列表示IRQ中断号</li>
<li>第二、三、四、五列表示相应的CPu核心被中断的次数</li>
<li>第六列表示使用控制器</li>
<li>第七列表示硬件中断号和中断触发方式（电平或边沿）</li>
<li>第八列表示中断名称</li>
<li>有一些IRQ号会表示为NMI，LOC之类的，这是系统保留的，用户无法访问和配置</li>
</ol>
<p>此外，<code>/proc/interrupts</code>文件中列出的是当前系统使用的中断情况，如果某个中断处理没有安装（包括安装后卸载的），是不会显示的。但是<code>/proc/stat</code>会记录机器从启动开始各个中断序号发生中断的次数。</p>
<h2 id="中断向量"><a href="#中断向量" class="headerlink" title="中断向量"></a>中断向量</h2><p>x86中支持256种中断，将这些中断源按照0到255的顺序对没中中断进行编号，这个标号叫做中断向量，通常用8位无符号整数来存储这个向量。中断号与中断向量一一映射。<br>中断号和中断向量概念不同。当I/O设备把中断信号发送个中断控制器时，与之关联的是一个中断号；而当中断控制器将该中断信号传递给CPU时，与之关联的是一个中断向量。中断号是以中断控制器的角度而言的；中断向量则是以CPU的角度而言的。<br>通常，Intel将编号为0～31的向量分配给异常和非屏蔽中断。</p>
<h2 id="中断服务例程"><a href="#中断服务例程" class="headerlink" title="中断服务例程"></a>中断服务例程</h2><p>在响应一个具体的中断时，内核会执行一个函数，这个函数被称为中断服务例程（interrupt service routine, ISR）。每一个设备的驱动程序中都会定义相关的中断服务例程。</p>
<p>现今的中断处理流程都会分为两部分:上半部分（top half）和下半部分（bottom half），原因如下：</p>
<ol>
<li>中断可以随时打断CPU对其它程序的执行，如果被打断的代码对系统很重要，那么此时中断处理程序的执行时间应该越短越好</li>
<li>中断处理程序在执行时，会屏蔽同条中断线上的中断请求；如果设置了IRQF_DISABLE，那么该中断服务程序执行时是会屏蔽其他所有其它的中断请求。那么此时应该让中断处理程序执行的越快越好。</li>
</ol>
<p>这样划分是有一定原因的，因为我们必须有一个快速、异步而且简单的处理程序专门来负责对硬件的中断请求作出快速响应，与此同时也要完成那些对时间要求很严格的操作。而那些对时间要求相对宽松，其它的剩余工作则会在稍后的任意时间执行，也就是所谓的下半部分执行。</p>
<p>上半部分只能通过中断处理程序实现，下半部分可以通过多种机制来完成：小任务（tasklet），工作队列，软中断，不管是哪种机制，他们均为下半部分提供了一种执行机制，比上半部分灵活多了，至于何时执行，则由内核负责。</p>
<h1 id="第一个中断测试程序"><a href="#第一个中断测试程序" class="headerlink" title="第一个中断测试程序"></a>第一个中断测试程序</h1><p>了解了下中断的基本概念，下面就写一个小demo来实际测试一下吧。代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;linux&#x2F;init.h&gt;                 </span><br><span class="line">#include &lt;linux&#x2F;kernel.h&gt;          </span><br><span class="line">#include &lt;linux&#x2F;module.h&gt;               </span><br><span class="line">#include &lt;linux&#x2F;moduleparam.h&gt;          </span><br><span class="line">#include &lt;linux&#x2F;interrupt.h&gt;       </span><br><span class="line">#include &lt;linux&#x2F;stat.h&gt;                 </span><br><span class="line">#include &lt;linux&#x2F;slab.h&gt;                                                                                                                                                                                           </span><br><span class="line">                                   </span><br><span class="line">static int irq &#x3D; 1;                 &#x2F;&#x2F;保存中断号irq</span><br><span class="line">static char *devname &#x3D; NULL;        &#x2F;&#x2F;保存中断名称*devname</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;利用宏module_param来接受参数</span><br><span class="line">module_param(irq, int, 00644);      &#x2F;&#x2F;S_IRUGO&#x3D;00644</span><br><span class="line">module_param(devname, charp, 00644);</span><br><span class="line">                                   </span><br><span class="line">&#x2F;&#x2F;定义一个结构体，在request_irq函数中的void *dev_id经常设置为结构体或NULL</span><br><span class="line">struct dev_info&#123;                   </span><br><span class="line">    int irq_id;                    </span><br><span class="line">    char *dev_name;                </span><br><span class="line">&#125;;                                 </span><br><span class="line">                                   </span><br><span class="line">struct dev_info *mydev_info &#x3D; NULL;</span><br><span class="line">                                   </span><br><span class="line">&#x2F;&#x2F;声明中断处理函数（上半部分）  </span><br><span class="line">static irqreturn_t myirq_handler(int irq, void *dev);</span><br><span class="line">                                   </span><br><span class="line">static int __init myirq_init(void)</span><br><span class="line">&#123;                                  </span><br><span class="line">    printk(&quot;zhw test:Module is working ...\n&quot;);</span><br><span class="line">    &#x2F;&#x2F;分配struct dev_info结构体内存</span><br><span class="line">    mydev_info &#x3D; kmalloc(sizeof(struct dev_info), GFP_KERNEL);</span><br><span class="line">    if(!mydev_info)                </span><br><span class="line">    &#123;                              </span><br><span class="line">        printk(&quot;kmalloc failed!\n&quot;);</span><br><span class="line">        return -1;                 </span><br><span class="line">    &#125;                              </span><br><span class="line">    memset(mydev_info, 0, sizeof(struct dev_info));</span><br><span class="line">    mydev_info-&gt;irq_id &#x3D; irq;   </span><br><span class="line">    &#x2F;&#x2F;分配结构体struct dev_info-&gt;char *dev_name内存</span><br><span class="line">    mydev_info-&gt;dev_name &#x3D; kmalloc(10, GFP_KERNEL);</span><br><span class="line">    if(!mydev_info-&gt;dev_name)   </span><br><span class="line">    &#123;                              </span><br><span class="line">        printk(&quot;kmalloc 1 failed!\n&quot;);</span><br><span class="line">        return -1;                 </span><br><span class="line">    &#125;                              </span><br><span class="line">    mydev_info-&gt;dev_name &#x3D; devname;</span><br><span class="line"></span><br><span class="line">    if(request_irq(irq, &amp;myirq_handler, IRQF_SHARED, devname, mydev_info))</span><br><span class="line">    &#123;</span><br><span class="line">        printk(&quot;%s request IRQ:%d failed\n&quot;, devname, irq);</span><br><span class="line">        return -1;</span><br><span class="line">    &#125;</span><br><span class="line">    printk(&quot;%s request IRQ:%d success..\n&quot;, devname ,irq);</span><br><span class="line">    return 0;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">static void __exit myirq_exit(void)</span><br><span class="line">&#123;</span><br><span class="line">    printk(&quot;unloading my module ..\n&quot;);</span><br><span class="line">    free_irq(irq, mydev_info);</span><br><span class="line">    printk(&quot;freeing IRQ %d\n&quot;, irq);</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">static irqreturn_t myirq_handler(int irq, void *dev)</span><br><span class="line">&#123;</span><br><span class="line">    struct dev_info mydev;</span><br><span class="line">    static int count &#x3D; 1;</span><br><span class="line">    mydev &#x3D; *(struct dev_info *)dev;</span><br><span class="line"> </span><br><span class="line">    printk(&quot;key:%d\n&quot;, count);</span><br><span class="line">    printk(&quot;devname:%s. devid:%d\n is working..\n&quot;, mydev.dev_name, mydev.irq_id);</span><br><span class="line">    printk(&quot;ISR is leaving\n&quot;);</span><br><span class="line">    count++;</span><br><span class="line">    return IRQ_HANDLED;</span><br><span class="line">&#125;</span><br><span class="line"> </span><br><span class="line">module_init(myirq_init);</span><br><span class="line">module_exit(myirq_exit);</span><br><span class="line"> </span><br><span class="line">MODULE_LICENSE(&quot;GPL&quot;);</span><br></pre></td></tr></table></figure>
<p>因为中断程序一般包含在某个设备的驱动程序中，所以这个程序本质就是一个内核模块。这里面主要就是驱动的初始化，退出，以及中断服务例程（ISR）。这里共享键盘的中断号，x86下键盘的中断号是1.<br>Makefile如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">obj-m:&#x3D;first_interrupt.o                                                                                                                                                                                          </span><br><span class="line">KDIR:&#x3D;&#x2F;lib&#x2F;modules&#x2F;$(shell uname -r)&#x2F;build</span><br><span class="line">PWD:&#x3D;$(shell pwd)</span><br><span class="line"> </span><br><span class="line">default:</span><br><span class="line">    $(MAKE) -C $(KDIR) M&#x3D;$(PWD) modules</span><br><span class="line"> </span><br><span class="line">clean:</span><br><span class="line">    rm -rf .*.cmd *.o *.mod.c *.ko .tmp_versions</span><br></pre></td></tr></table></figure>

<p>使用方法：</p>
<ol>
<li>cat /proc/interrupts查看中断号，注意如果是使用ssh或telent到linux上的是不会响应键盘中断的，需要使用虚拟机来实验</li>
<li>加载驱动<code>sudo insmod ./first_interrupt.ko irq=1 devname=zhwirq</code></li>
<li>查看驱动<code>lsmod | grep first</code>,查看中断<code>cat /proc/interrupts | grep zhw</code></li>
<li>dmesg查看内核日志文件，dmesg | tail -20<br><img src="https://rancho333.gitee.io/pictures/dmesg.png"></li>
<li>卸载驱动<code>sudo rmmod first_interrupt</code></li>
</ol>
<p>加载驱动后，先进行驱动初始化，之后每当有键盘中断触发后，都会进入ISR，卸载驱动后不会再触发。</p>
<p>参考资料：<br><a href="https://www.linuxidc.com/Linux/2014-03/98012.htm">Linux下的中断（interrupt） 简介</a><br><a href="http://edsionte.com/techblog/archives/1495">中断入门</a><br><a href="https://blog.csdn.net/wordwarwordwar/article/details/81182910">PCI&amp;PCIE MSI中断</a><br><a href="http://control.blog.chinaunix.net/uid-22666248-id-3052413.html">第一个中断驱动程序</a><br><a href="https://blog.csdn.net/yzytr/article/details/77659302">如何编译内核ko</a></p>
]]></content>
      <tags>
        <tag>中断</tag>
      </tags>
  </entry>
  <entry>
    <title>关于Ubuntu的软件源source.list学习</title>
    <url>/2019/07/25/%E5%85%B3%E4%BA%8EUbuntu%E7%9A%84%E8%BD%AF%E4%BB%B6%E6%BA%90source-list%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h2 id="背景说明"><a href="#背景说明" class="headerlink" title="背景说明"></a>背景说明</h2><p>最近参与到公司的白盒交换机项目中，需要编译ONL和sonic，其中软件源的设置让我非常头疼，编译依赖有很大的问题。决定深入学习一下Linux软件源.主机环境为ubuntu16.04.  </p>
<span id="more"></span>

<h2 id="软件库存储文件-list"><a href="#软件库存储文件-list" class="headerlink" title="软件库存储文件*.list"></a>软件库存储文件*.list</h2><p>ubuntu使用apt来管理软件包，apt将软件库存储在如下文件中:  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;etc&#x2F;apt&#x2F;sources.list</span><br><span class="line">&#x2F;etc&#x2F;apt&#x2F;sources.list.d&#x2F;目录中带.list后缀的文件</span><br></pre></td></tr></table></figure>
<p>可以通过man sources.lis来查看apt的完整存储机制。  </p>
<h2 id="sources-list格式和写法"><a href="#sources-list格式和写法" class="headerlink" title="sources.list格式和写法"></a>sources.list格式和写法</h2><ol>
<li>以<code>#</code>开头的行是注释行  </li>
<li>以deb或deb-src开头的是<code>apt respository</code>，具体格式为：  </li>
<li>deb：二进制包仓库  </li>
<li>deb-src：二进制包的源码库,不自己看程序或者编译，deb-src可以不要。  </li>
<li>URI: 库所在的地址，可以是网络地址，也可以是本地的镜像地址  </li>
<li>codename：ubuntu版本的代号，可以通过命令<code>lsb_release -a</code>来查看当前系统的代号  </li>
<li>components：软件的性质(free或non-free等)  </li>
</ol>
<h3 id="ubuntu系统代号"><a href="#ubuntu系统代号" class="headerlink" title="ubuntu系统代号"></a>ubuntu系统代号</h3><p>codename是ubuntu不同版本的代号</p>
<table>
<thead>
<tr>
<th align="center">版本号</th>
<th align="center">代号(codename)</th>
</tr>
</thead>
<tbody><tr>
<td align="center">10.04</td>
<td align="center">lucid</td>
</tr>
<tr>
<td align="center">12.04</td>
<td align="center">precise</td>
</tr>
<tr>
<td align="center">14.04</td>
<td align="center">trusty</td>
</tr>
<tr>
<td align="center">14.10</td>
<td align="center">utopic</td>
</tr>
<tr>
<td align="center">16.04</td>
<td align="center">xenial</td>
</tr>
<tr>
<td align="center">18.04</td>
<td align="center">bionic</td>
</tr>
</tbody></table>
<h3 id="deb说明"><a href="#deb说明" class="headerlink" title="deb说明"></a>deb说明</h3><p>deb后面的内容有三大部分：deb URI section1 section2<br>以<code>deb http://us.archive.ubuntu.com/ubuntu/ xenial main restricted</code>为例进行说明。<br>URI是库所在的地址，支持http，fpt以及本地路径,访问<code>http://us.archive.ubuntu.com/ubuntu/</code>可以看到如下信息：<br><img src="https://rancho333.gitee.io/pictures/ubuntu.png"><br><code>dists</code>和<code>pool</code>这两个目录比较重要。<code>dists</code>目录包含了当前库的所有软件包的索引。这些索引通过codename分布在不同的文件夹中。例如<code>xenial</code>所在的目录。<br><img src="https://rancho333.gitee.io/pictures/xenial.png"><br>上图中的文件夹名其实就是对应了section1，我们可以根据需要填写不同的section1.<br>这里面的文件都是用以下格式命名的：  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">codename</span><br><span class="line">codename-backports    #unsupported updates</span><br><span class="line">codename-proposed	  #pre-released updates</span><br><span class="line">codename-security	  #important security updates</span><br><span class="line">codename-updates	  #recommanded updates</span><br></pre></td></tr></table></figure>

<p>打开其中一个任一文件夹，例如<code>xenial-updates</code>:<br><img src="https://rancho333.gitee.io/pictures/xenial.png"><br>里面有<code>main,multiverse,restricted,universe</code>文件夹，这些文件夹对应deb后面的section2,里面包含了不同软件包的索引。它们的区别在于：  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">main：完全的自由软件</span><br><span class="line">restricted: 不完全的自由软件</span><br><span class="line">universe: ubuntu官方不提供支持与补丁，全靠社区支持</span><br><span class="line">multiverse: 非自由软件，完全不提供支持和补丁</span><br></pre></td></tr></table></figure>

<p>打开main目录下的binary-i386子目录下的Packages.gz文件，可以看到如下内容：<br><img src="https://rancho333.gitee.io/pictures/packages.png"><br>说明：Packages.gz这个文件其实就是一个“索引”文件,里面记录了各种包的包名(Package)、运行平台(Architecture)、版本号（Version）、依赖关系(Depends)、deb包地址(Filename)等。Filename指向的是源服务器pool目录下的某个deb。猜测：<code>apt-get install</code>某个软件是，其实就是基于这些Packages.gz来计算依赖关系，然后根据其中的filename地址来下载所需的deb，最后执行<code>dpkg -i pacckage.deb</code>来完成软件包的安装。  </p>
<h2 id="替换源"><a href="#替换源" class="headerlink" title="替换源"></a>替换源</h2><p>先将默认的sources.list进行备份，然后仿照下表修改源：  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line"># 默认注释了源码镜像以提高 apt update 速度，如有需要可自行取消注释</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic main restricted universe multiverse</span><br><span class="line"># deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic main restricted universe multiverse</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic-updates main restricted universe multiverse</span><br><span class="line"># deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic-updates main restricted universe multiverse</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic-backports main restricted universe multiverse</span><br><span class="line"># deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F; bionic-backports main restricted universe multiverse</span><br><span class="line">deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic-security main restricted universe multiverse</span><br><span class="line"># deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic-security main restricted universe multiverse</span><br><span class="line"></span><br><span class="line"># 预发布软件源，不建议启用</span><br><span class="line"># deb https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic-proposed main restricted universe multiverse</span><br><span class="line"># deb-src https:&#x2F;&#x2F;mirrors.aliyun.com&#x2F;ubuntu&#x2F; bionic-proposed main restricted universe multiverse</span><br></pre></td></tr></table></figure>

<h2 id="国内镜像网站"><a href="#国内镜像网站" class="headerlink" title="国内镜像网站"></a>国内镜像网站</h2><p>这里推荐两个国内镜像网站，一个是<a href="http://mirrors.tuna.tsinghua.edu.cn/">清华源</a>，一个是<a href="https://mirrors.aliyun.com/">阿里源</a><br>找到对应的源后，清华源可以点击源名称后的问号获取源路径，阿里源可以点击源名称所在行的帮助获取源路径。<br>注意事项：<br>    清华源中源路径默认使用https,需要安装apt-transport-https软件包，否则修改为http进行使用</p>
<h2 id="unmet-dependencies"><a href="#unmet-dependencies" class="headerlink" title="unmet dependencies"></a>unmet dependencies</h2><p>在执行命令<code>apt-get -y build-dep linux</code>时出现<code>unmet dependencies</code>错误，如下图所示：</p>

<p>解决方法：<br>    在镜像服务器上可以查询到2.99版本存在，将<code>apt-get</code>命令换成<code>aptitude</code>命令，使用<code>apt-get install -y apt-utils aptitude</code>安装<code>aptitude</code></p>
<h2 id="Hash-Sum-Mismatch"><a href="#Hash-Sum-Mismatch" class="headerlink" title="Hash Sum Mismatch"></a>Hash Sum Mismatch</h2><p>在使用阿里源编译sonic源码的时候(debian:stretch)，出现<code>Hash Sum Mismatch</code>的报错。如下图所示：</p>


<p>有些网络服务商，特别是一些小区网络的服务商，为了减少流量费用和提高对常见网络资源的访问速度，很多都搞了这么个东西出来<br>但是他们的缓存策略有问题，只比对文件路径，不考虑域名/IP地址，也没怎么考虑过文件内容更新后的同步，即缓存服务器上的内容和实际文件的内容可能不一致。<br>即对于<a href="http://example.com/a/b/c.dat%E8%BF%99%E4%B9%88%E4%B8%80%E4%B8%AA%E6%96%87%E4%BB%B6%EF%BC%8C%E5%A6%82%E6%9E%9C%E8%A2%AB%E6%94%B6%E5%85%A5%E7%BC%93%E5%AD%98%EF%BC%8C%E9%82%A3%E4%B9%88%E4%BD%A0%E8%AE%BF%E9%97%AE%E5%85%B6%E4%BB%96%E4%BB%BB%E6%84%8F%E5%9F%9F%E5%90%8D%E4%B8%8B%E7%9A%84/a/b/c.dat%E6%96%87%E4%BB%B6%E9%83%BD%E4%BC%9A%E5%8E%BB%E8%AF%BB%E5%8F%96%E8%A2%AB%E7%BC%93%E5%AD%98%E7%9A%84%E6%96%87%E4%BB%B6%E3%80%82%E5%A6%82%E6%9E%9Chttp://example.com/a/b/c.dat%E6%9C%89%E4%BA%86%E6%94%B9%E5%8F%98%EF%BC%8C%E7%BC%93%E5%AD%98%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E7%9A%84%E5%AF%B9%E5%BA%94%E6%96%87%E4%BB%B6%E4%B8%8D%E4%B8%80%E5%AE%9A%E8%83%BD%E8%B7%9F%E7%9D%80%E6%9B%B4%E6%96%B0%E3%80%82">http://example.com/a/b/c.dat这么一个文件，如果被收入缓存，那么你访问其他任意域名下的/a/b/c.dat文件都会去读取被缓存的文件。如果http://example.com/a/b/c.dat有了改变，缓存服务器上的对应文件不一定能跟着更新。</a><br>而ubuntu大部分源的文件路径是一致的，所以如果163源中的 <a href="http://mirrors.163.com/ubuntu/dists/tru">http://mirrors.163.com/ubuntu/dists/tru</a> … ources.bz2 被收入缓存，那么你访问官方源 <a href="http://archive.ubuntu.com/ubuntu/dists/">http://archive.ubuntu.com/ubuntu/dists/</a> … ources.bz2 时，由于路径都是/ubuntu/dists/trusty/main/source/Sources.bz2，还是获取的是缓存服务器上的缓存文件。这个可用wget验证。如果缓存服务器上文件过时了，就会出现Hash Sum Mismatch。<br>解决方法：<br>    1.更换源，换成清华源就没问题了<br>    2.使用https协议</p>
<h2 id="关于pypi国内源"><a href="#关于pypi国内源" class="headerlink" title="关于pypi国内源"></a>关于pypi国内源</h2><p>哈，顺便在这里提一下pip的国内源啦，就不单独写篇文章了。<br>python使用pip作为包管理工具，类似于debian/ubuntu的apt-get/aptitude和redhat的yum。国内镜像网站可以在上面找到。替换方法如下：<br>临时使用：<br>    <code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple some-package</code><br>设为默认：<br>升级 pip 到最新的版本 (&gt;=10.0.0) 后进行配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">pip install pip -U</span><br><span class="line">pip config set global.index-url https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple</span><br></pre></td></tr></table></figure>
<p>如果您到 pip 默认源的网络连接较差，临时使用本镜像站来升级 pip：<br><code>pip install -i https://pypi.tuna.tsinghua.edu.cn/simple pip -U</code></p>
<p>如果不升级pip,那么可以修改pip的配置文件：<br>修改 ~/.pip/pip.conf (没有就创建一个文件夹及文件)<br>内容如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[global]</span><br><span class="line">index-url &#x3D; https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn&#x2F;simple</span><br><span class="line">[install]</span><br><span class="line">trusted-host &#x3D; https:&#x2F;&#x2F;pypi.tuna.tsinghua.edu.cn</span><br></pre></td></tr></table></figure>

<p><strong>参考资料：</strong><br><a href="https://forum.ubuntu.org.cn/viewtopic.php?t=465499">ubuntu论坛</a></p>
]]></content>
      <categories>
        <category>Linux相关</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>软件源</tag>
      </tags>
  </entry>
  <entry>
    <title>关于动态库以及constructor属性的使用</title>
    <url>/2020/02/26/%E5%85%B3%E4%BA%8E%E5%8A%A8%E6%80%81%E5%BA%93%E4%BB%A5%E5%8F%8Aconstructor%E5%B1%9E%E6%80%A7%E7%9A%84%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>在做linux系统移植的过程中逐步加深了对动态编译和静态编译的理解，今天这里记录一下如何将自己的代码编译成动态库供其他程序使用。顺道记录一下遇到的一个好玩的东西：C语言中的constructor属性，是<code>__attribute__</code>的attr_list中的一员。</p>
<span id="more"></span>

<h2 id="将自己的模块编译生成so"><a href="#将自己的模块编译生成so" class="headerlink" title="将自己的模块编译生成so"></a>将自己的模块编译生成so</h2><p>示例模块分成两个部分，cons.c和cons.h,cons.c的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;cons.h&quot;</span><br><span class="line"></span><br><span class="line">void before_main()</span><br><span class="line">&#123;</span><br><span class="line">        printf(&quot;%s\n&quot;, __FUNCTION__);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">void after_main()</span><br><span class="line">&#123;</span><br><span class="line">        printf(&quot;after main!\n&quot;);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>cons.h的代码如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &lt;stdio.h&gt;</span><br><span class="line"></span><br><span class="line">void before_main() __attribute__((constructor)); </span><br><span class="line">void after_main();</span><br></pre></td></tr></table></figure>
<p>使用命令<code>gcc cons.c -fPIC -shared -o  libcons.so</code>编译生成动态库文件。</p>
<h2 id="使用动态进行编译"><a href="#使用动态进行编译" class="headerlink" title="使用动态进行编译"></a>使用动态进行编译</h2><p>动态库一般是封装了一些常用的模块或功能，我们在需要调用动态库的代码中先加入需要调用函数所在的头文件（这些头文件是与动态库一起发布的），然后在编译的时候链接该库就可以了。调用库的示例代码demo.c:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;cons.h&quot;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">        printf(&quot;%s\n&quot;, __FUNCTION__);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用命令<code>gcc demo.c -o demo -L./ -lcons</code>进行编译，其中<code>-L</code>指明了查找动态库的路径，<code>-lcons</code>指明动态库的名字，它的组成是<code>-l</code>加上动态库真实名字的<code>lib</code>与<code>.so</code>之间的字符串，如<code>libcons.so</code>就是<code>-l+cons</code>。<br>使用<code>ldd demo</code>查看程序所依赖动态库的具体情况（是否存在，查找路径等）：<br><img src="https://rancho333.gitee.io/pictures/ldd.png"></p>
<p>发现demo与libcons.so之间并未产生依赖关系，这里猜测是demo.c中并没有显示的使用到libcons.so中的资源，所以即使加上<code>-lcons</code>编译选项，编译器也会对之进行优化。那么我们修改demo.c中的代码为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">#include &quot;cons.h&quot;</span><br><span class="line"></span><br><span class="line">void main()</span><br><span class="line">&#123;</span><br><span class="line">        printf(&quot;%s\n&quot;, __FUNCTION__);</span><br><span class="line">        after_main();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>这里加上对函数<code>after_main</code>的调用，再使用ldd查看：<br><img src="https://rancho333.gitee.io/pictures/ldd.png"></p>
<p>发现ldd中虽然已经有了libcons.so的信息，但是是<code>not found</code>，执行<code>demo</code>当然也会报这个库找不到。这是因为我们的库所在的路径并没有加到<em>查找库所在路径</em>的环境中，类似于shell的命令查找规则<em>PATH</em>环境变量，这里可以将路径添加到环境变量中或者将库拷贝到已知的查找路径中。用户添加的一般拷到<code>/usr/lib</code>下，这里再回到上面编译demo.c的地方，如果事先将库拷到系统路径中，那么久不用加<code>-L</code>指定路径了。如果是做嵌入式开发，记得一定要把库拷到开发板上哦。动态库在程序编译和执行的时候都会用的。</p>
<p>再次ldd看下并执行：<br><img src="https://rancho333.gitee.io/pictures/ldd.png"></p>
<p>可以正常执行打印出函数名字了，但是有点奇怪的是没有调用befor_main函数为什么也会打印出来呢。</p>
<h2 id="constructor关键字"><a href="#constructor关键字" class="headerlink" title="constructor关键字"></a>constructor关键字</h2><p>回到上面去看看before_main函数的声明，发现有个<code>__attribute__((constructor))</code>。</p>
<h3 id="attribute-介绍"><a href="#attribute-介绍" class="headerlink" title="__attribute__介绍"></a>__attribute__介绍</h3><p>__attribute__可以设置函数属性(Function Attribute)、变量属性(Variable Attribute)和类型属性(Type Attribute)。__attribute__前后都有两个下划线，并且后面会紧跟一对原括弧，括弧里面是相应的__attribute__参数<br><em><strong>attribute__语法格式为：__attribute</strong> ( ( attribute-list ) )</em></p>
<p>若函数被设定为constructor属性，则该函数会在main（）函数执行之前被自动的执行。类似的，若函数被设定为destructor属性，则该函数会在main（）函数执行之后或者exit（）被调用后被自动的执行。</p>
<p>所以记得了before_main在main函数之前执行的哦，以前一直只记得main函数是程序的入口。这次移植调试发现在main函数之前就coredump了，查了好半天才定位出来。</p>
<p>好玩的东西很多，遇到奇怪的东西很多时候心里会打鼓，但越来越坚定：代码里没有玄学！</p>
]]></content>
      <tags>
        <tag>动态库so</tag>
        <tag>attribute属性</tag>
      </tags>
  </entry>
  <entry>
    <title>关于终端回显的问题</title>
    <url>/2021/01/05/%E5%85%B3%E4%BA%8E%E7%BB%88%E7%AB%AF%E5%9B%9E%E6%98%BE%E7%9A%84%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>在嵌入式设备调试中，经常会使用console口对设备进行管理。使用vim进行文件编辑时，会发现屏幕回显有问题，例如，行显示不会逐步递增到屏幕底端，列显示时换行错乱。这是tty设置的<code>rows</code>与<code>cols</code>与实际的屏幕尺寸不适配。</p>
<span id="more"></span>
<h1 id="对于console连接"><a href="#对于console连接" class="headerlink" title="对于console连接"></a>对于console连接</h1><p>我们可以使用<code>stty -a</code>查看stty的所有配置信息，其中第一行包括波特率，终端的大小（以字符为基准）。也可以直接使用<code>stty size</code>查看终端的大小。</p>
<p><img src="https://rancho333.gitee.io/pictures/stty.png"></p>
<p>对于常见的远程登录软件，如<code>xshell</code>和<code>secure CRT</code>会在软件底端显示出当前终端的大小，我们按照这个数值进行设定即可。之后<code>reset</code>终端设置。如果显示依然不正常，最大化窗口然后再恢复即可。</p>
<h1 id="对于ssh或telent连接"><a href="#对于ssh或telent连接" class="headerlink" title="对于ssh或telent连接"></a>对于ssh或telent连接</h1><p>为什么使用ssh或者telnet连接时不会出现这种终端显示的问题呢，因为ssh当窗口大小发生变化后，会自动的调整stty的数值。可以尝试调整窗口大小，然后<code>stty size</code>查看终端大小与软件显示的窗口大小进行比较。</p>
<h1 id="写在后面"><a href="#写在后面" class="headerlink" title="写在后面"></a>写在后面</h1><p>Linux的TTY子系统其实是一个很复杂的点。其中包括的知识点有<code>行编辑</code>、<code>进程组</code>、<code>会话组</code>、<code>信号控制</code>、<code>流控制与I/O阻塞</code>、<code>TTY配置</code>等。</p>
]]></content>
      <tags>
        <tag>stty</tag>
      </tags>
  </entry>
  <entry>
    <title>加弘跑团</title>
    <url>/2020/12/21/%E5%8A%A0%E5%BC%98%E8%B7%91%E5%9B%A2/</url>
    <content><![CDATA[<p>为什么要跑步？<br>我最开始跑步是为了减肥，现在我更多的认为规律性的跑步是一种健康的生活方式，是一种极易获取的运动。对跑步，我谈不上热爱，但我已经习惯了生活有它的一席之地。我知道跑步之前的生活状态，也知道现在的生活状态，所以我离不开跑步。</p>
<span id="more"></span>

<p>提及跑步，可以轻易找到各种各样的好处，这里不赘述。但是随便跑个几公里，一周只跑一两次其实很难看到你想要的效果。如果加大跑量，跑步有时候可能会损伤你的膝盖，还会让你得上一些奇奇怪怪的病，什么足底筋膜炎，跟腱炎，髂胫束摩擦综合症，跑完一个半马，你可能下楼梯都困难。</p>
<p>跑步是痛苦的，长跑更是意志力的对抗赛。只有在熬过最初的苦痛，可以边跑边聊天，可以只用鼻子呼吸的时候，你才不会感觉那么煎熬，这之前是可以称作跑步痛苦期。如果想着提高配速，增加距离，再突破瓶颈，那便得再痛苦一番。跑步也不能拯救我们，跑步是花钱的运动，专业跑鞋很贵，所以好好工作才能好好跑步。</p>
<p>跑步是痛苦的，只有认识到跑步的痛苦之后，然后依然热爱并且坚定的选择，才能持久的进行。跑步的快乐，只有在获得正向反馈之后，熬过跑步痛苦期之后，才能真正体会到。</p>
<p>所以，为什么要跑步？请寻找你内心的信念，让它支撑你熬过开始跑步时的痛苦。</p>
<p>什么叫跑步？<br>跑步，跑马拉松并不会让我们高人一等，也不是只有跑十公里以上才叫跑步。每个人跑步的需求也是不一样的。有严肃跑者，将跑步当作兴趣来培养，动辄全马百公里超马越野跑，追求成绩追求PB；也有休闲跑者，三五好友或携妻带子，三两公里，微风微汗，也是开心畅快。<br>不用神话跑步，学音乐，学舞蹈，学英语都可以让我们变得更好。无论是严肃的跑者还是休闲的跑者，跑起来，都是跑步。跑步是一项包容性很大的活动。不用管配速，不用管距离，跑起来就好。</p>
<p>了解了一下，加弘跑团中有跑过上马的老马, 有早起晨跑的大佬，有希望进阶的跑者，有刚接触跑步的菜鸟。大家相聚一起，一起跑，想来是件很欢快的事情。加弘跑团刚成立，需要大家一起去将跑团运行起来。下面对跑团的运行以及接下来的安排做一些简要说明，欢迎大家补充优化。</p>
<ol>
<li><p>本周4（12月24号）进行加弘跑团第一次分享会，具体时间地点会通知，有以下几点：</p>
<ol>
<li>大家相互认识一下，确定跑团人员，购买跑团队服，还有大家赶紧拉人头</li>
<li>分享跑步基础知识，包括但不限于跑步姿势，预防伤害，跑步场地，跑步时间与饮食</li>
<li>跑步装备介绍，包括但不限于跑鞋（袜子），跑衣，手表<br>备注：分享人待定</li>
</ol>
</li>
<li><p>活动组织形式</p>
<ol>
<li>每月组织一次线下活动，时间可以是周末或者有意义的节假日或其它，地点待确定。不能参加的可以通过线上方式参与</li>
<li>线下活动会视经费情况安排补给，供大家补充体力</li>
<li>不定期安排比赛活动，视经费情况安排奖品</li>
</ol>
</li>
<li><p>暂定元旦进行加弘跑团第一次线下活动</p>
</li>
</ol>
<p>为了跑团的良好运行，请大家以任何形式联系我提供建议。关于知识分享，请大佬主动认领！<br>期待大家越跑越健康；期待大家跑一个冬天，帅一个夏天；期待有一天在马拉松的赛道上看到加弘跑团的旗帜！</p>
]]></content>
      <tags>
        <tag>跑步</tag>
      </tags>
  </entry>
  <entry>
    <title>对SONiC项目的认识</title>
    <url>/2021/02/25/%E5%AF%B9SONiC%E9%A1%B9%E7%9B%AE%E7%9A%84%E8%AE%A4%E8%AF%86/</url>
    <content><![CDATA[<h1 id="SONiC简介"><a href="#SONiC简介" class="headerlink" title="SONiC简介"></a>SONiC简介</h1><p>不做过多赘述，SONiC本质就是一个Linux交换机网络操作系统，它有两个特点。</p>
<span id="more"></span>
<p>第一，它是基于SAI的，在没有SAI之前所有的芯片都要通过自己的SDK与上层软件进行通信，相当于用自己的“方言”与上层操作系统通信，SAI把这个“方言”标准化，大家的芯片用同样的语言同上层的控制软件交流，因为有了SAI，所以才能建立一个操作系统。有了SAI之后，适配ASIC的工作由芯片厂商完成，白盒交换机厂商推出一款新产品所花费的时间大大缩短。</p>
<p>第二，基于Docker，Sonic有丰富的扩展性。依托于Linux,Docker生态，Sonic孕育了丰富的管理软件和解决方案。而其自身也于Redis, Quagga, LLDP等开源技术碰撞出更多火花。</p>
<p>2016年，SONiC的理念就是将传统交换机OS拆分成多个容器化组件的解决方案，进而也定义了控制面的容器化架构，囊括了组件和编程接口。</p>
<p>2017年微软对SONiC的性能进行了大幅升级，全面支持IDV，并且融合了更多的容器特性。</p>
<p>2018年微软又在管理性上下了大力气（如ConfigDB）</p>
<h1 id="对SONiC项目的学习"><a href="#对SONiC项目的学习" class="headerlink" title="对SONiC项目的学习"></a>对SONiC项目的学习</h1><p>相比于传统Linux交换机操作系统几十M的镜像大小，SONiC镜像动辄几百M甚至超1G，这也说明了里面包含的内容极其庞杂。如果有比较深厚的Linux功底，上手会很快。因为里面大多是Linux本质性、不变性和可复用性的东西。以自己对SONiC项目的认知，将其划分为5个大块比较合适。分别是：</p>
<ul>
<li>SONiC的编译</li>
<li>SONiC的安装</li>
<li>SONiC的bring up</li>
<li>SONiC的上层应用</li>
<li>TestBed自动化测试</li>
</ul>
<h2 id="SONiC的编译"><a href="#SONiC的编译" class="headerlink" title="SONiC的编译"></a>SONiC的编译</h2><p>这一步本身就是一个庞大的源码编译出Linux安装镜像的过程，类比于LFS。这里可以借用嵌入式操作系统移植的4个步骤用来辅助说明。</p>
<ol>
<li>交叉编译环境的制作。一般而言，SONiC的宿主机与目标机都是x86，所以没有交叉编译这种说法，但是sonic是支持ARM和ARM64的，只是现阶段我没玩过。值得关注的是，SONiC在编译之前会制作一个docker用来打包编译环境，之后所有的编译在里面完成。</li>
<li>kernel的配置、编译、移植。SONiC在kernel编译时会指定config，参见kernel的Makefile，我们可以按需修改。</li>
<li>根文件系统的制作。SONiC使用debootstrap完成文件系统的基础架构，之后会将编译好的deb包，whl包等target释放或拷贝到rootfs中去，最终生成的sonic-platform.bin是一个fs.zip、fs.squashfa、docker.tar.gz以及初始化脚本的打包可执行文件。</li>
<li>bootloader的移植。裸机装bios没有玩过，SONiC盒子需要在bios之上安装一个ONIE，ONIE本质是一个小的Linux，提供SONiC安装环境</li>
</ol>
<p>对于这一部分，如果有一个比较全面的概览，当有porting或任何需要修改源码的需求时，将会有一定方向性。SONiC的编译框架主要由shell脚本，Makefile，Dockefile以及j2模板文件构成，需要有一定的Makefile、shell脚本基础。</p>
<h2 id="SONiC的安装"><a href="#SONiC的安装" class="headerlink" title="SONiC的安装"></a>SONiC的安装</h2><p>SONiC的安装是某种程度上是生成镜像的一个逆向过程。sonic-asic.bin是一个shell脚本，可以在shell下直接执行一下看看会发生什么事情。SONiC安装的本质其实就是bash ./sonic-asic.bin的执行过程。</p>
<p>SONiC可以在ONIE和SONiC环境下完成安装，这里面会调用两个脚本sharch_body.sh和install.sh。SONiC的安装时会有一些打印，参照打印与shell脚本可以发现里面做了什么,关注一下<code>/boot</code>目录。在此处简单说明一下：</p>
<ul>
<li>在sharch_body.sh中<ul>
<li>对image文件进行hash校验</li>
<li>为install.sh准备运行环境并执行install.sh</li>
</ul>
</li>
<li>在install.sh中<ul>
<li>确定安装环境（ONIE、SONiC、build）</li>
<li>调用machine.conf，准备platform相关环境变量，配置console，默认是ttyS0和9600。参数设置不匹配将导致SONiC bring up失败。新安装的onie，需要在onie下修改eeprom以及machine.conf(这个可以在onie编译的时候指定)。需要关注修改三个字段：onie_switch_asic、onie_machine、onie_platform。</li>
<li>安排安装os的分区（uefi+gpt）</li>
<li>解压fs.zip(boot+platform+docker+fs.squashfs)至分区，onie和SONiC安装会有一些细微差别。这里将创建boot和platform文件夹（在sonic的/host/image*下面，不是根目录），将驱动放到对应文件夹下，在rc.local中会释放出来。</li>
<li>配置grub，安装完成 </li>
<li>重启之后会按照安装时设置的grud启动新的操作系统</li>
</ul>
</li>
</ul>
<h2 id="SONiC的bring-up"><a href="#SONiC的bring-up" class="headerlink" title="SONiC的bring up"></a>SONiC的bring up</h2><p>SONiC基于SAI可以： 一个镜像适配相同ASIC厂家的不同设备型号，每一个款设备都有自己的差异性配置文件，如端口，led，波特率等。SONiC是如何正确加载对应设备型号的配置文件的？这里留个问题可以自己查查。</p>
<p>SONiC是Linux, 所以遵循Linux的启动过程。</p>
<ol>
<li><p>bootloader + onie阶段<br>我们可以在onie下安装sonic，grub将cmdline参数传递给kernel，kernel启动，加载驱动</p>
</li>
<li><p>kernel启动之后systemd初始化阶段这里面可以细分</p>
<ul>
<li>systemd相关，使用<code>systemctl list-dependencies graphical.target</code>查看当前加载的服务 </li>
<li>rc.local，这里面有一些启动后执行的动作，自己瞅瞅吧</li>
</ul>
</li>
</ol>
<p>需要关注一下SONiC的文件系统</p>
<ul>
<li>fdisk -l     查看有哪些分区,以及分区大小。那么如何调整分区大小？改那个配置文件？</li>
<li>df 查看下那些文件夹挂载在物理硬盘分区上</li>
<li>cat /proc/cmdline    查看内核启动参数</li>
<li>blkid            查看分区对应的PARTUUID</li>
</ul>
<h2 id="SONiC的上层应用"><a href="#SONiC的上层应用" class="headerlink" title="SONiC的上层应用"></a>SONiC的上层应用</h2><p>SONiC的服务跑在docker中，如PMON、syncd、frr等。关于这些服务是如何启动的？可以参见《SONIC中docker运行服务的单分析》，源码中注意下<code>docker_image_ctl.j2</code>文件，这是docker的启动管理模板。</p>
<p>SONiC核心的功能就是交换路由，所以交换路由协议在里面是很重要的，与传统交换机相比，SONiC中的服务运行在docker中，使用redis集中式进行数据管理，其它并没有什么本质区别。</p>
<p>后续考虑以vxlan为切入点，深入了解学习SONiC的系统架构，对于vxlan，参见<a href="https://rancho333.gitee.io/2021/02/03/vxlan%E5%AD%A6%E4%B9%A0/">vxlan学习</a>。</p>
<p>如何配置管理SONiC呢？传统的交换机会做一个命令行程序，指定用户登录后执行该程序，可以称之为CLI，在里面可以进入shell，也可以从shell退回CLI。社区版SONiC登录之后运行bash，用python做了一套简单的命令行，可以进行配置管理，这玩意解析速度极慢，使用体验极差。除此之外，还可以通过修改<code>config_db.json</code>然后重新加载或者直接使用<code>redis</code>命令行进行配置。当然SONiC支持SDN，可以通过openflow方式集中式管理配置。阿里在SONiC上面做了一套传统CLI，称之为<code>lambda-cli</code>，比社区版SONiC的命令行好用多了。</p>
<h2 id="TestBed自动化测试"><a href="#TestBed自动化测试" class="headerlink" title="TestBed自动化测试"></a>TestBed自动化测试</h2><p>TBD</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>树莓派做串口服务器</title>
    <url>/2021/02/02/%E6%A0%91%E8%8E%93%E6%B4%BE%E5%81%9A%E4%B8%B2%E5%8F%A3%E6%9C%8D%E5%8A%A1%E5%99%A8/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>交换机设备放在实验室中，部分位置只有网口而没有串口服务器，用PC做串口服务器太浪费，下面介绍用树莓派做串口服务器。</p>
<span id="more"></span>
<h1 id="拓扑说明"><a href="#拓扑说明" class="headerlink" title="拓扑说明"></a>拓扑说明</h1><p>通过SSh远程到树莓派上，树莓派通过USB转串口与交换机串口相连。Linux上通过minicom连接串口。</p>
<h1 id="Linux环境准备"><a href="#Linux环境准备" class="headerlink" title="Linux环境准备"></a>Linux环境准备</h1><h2 id="minicom安装"><a href="#minicom安装" class="headerlink" title="minicom安装"></a>minicom安装</h2><p>通过以下命令安装minicom。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">apt install  lrzsz</span><br><span class="line">apt install minicom</span><br></pre></td></tr></table></figure>

<h2 id="串口参数设置"><a href="#串口参数设置" class="headerlink" title="串口参数设置"></a>串口参数设置</h2><p><code>minicom -s</code>进行参数设置。<br><img src="https://rancho333.gitee.io/pictures/minicom_s.png"></p>
<p>按如下参数进行设置.<br><img src="https://rancho333.gitee.io/pictures/serial_port.png"><br>可以在插拔usb转串口线在<code>/dev</code>查看串口设备。波特率以设备波特率为准。</p>
<p>设置完成后记得保存设置。</p>
<h2 id="设备登录"><a href="#设备登录" class="headerlink" title="设备登录"></a>设备登录</h2><p>在shell下输入<code>minicom</code>即可登录设备。<br>minicom的控制命令。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Ctrl-A x        退出minicom</span><br><span class="line">Ctrl-A z        显示快捷键帮助信息</span><br></pre></td></tr></table></figure>

]]></content>
  </entry>
  <entry>
    <title>计算机存储体系</title>
    <url>/2020/03/08/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%AD%98%E5%82%A8%E4%BD%93%E7%B3%BB/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>在没有接触过嵌入式之前，对于计算机存储的认知仅限于知道硬盘和内存，然后硬盘掉电可以保存数据，内存掉电丢失数据。后来逐渐听到更多的专业名词，什么ROM，RAM，SRAM，DRAM，FLASH,，NandFlash，NorFlash等等了。以前将自己的定位总是局限在协议工程师，对于和硬件和驱动相关的东西有些抵触，随着工作的深入，也时常会用到一些I2C,gpio之类的东东。本着沉下来，归零，再出发的心态，这篇文章用来梳理一下自己对于计算机存储体系的认知。</p>
<span id="more"></span>

<h1 id="总体架构"><a href="#总体架构" class="headerlink" title="总体架构"></a>总体架构</h1><p>下面这张图大家应该都很熟悉了<br><img src="https://rancho333.gitee.io/pictures/storage.png"><br>生活中的大部分物品，基本都满足“好的不一定是最贵的，但是最贵的一定是好的”，在计算机存储体系中，基本满足了上面这句话。塔尖上的那一小撮是最贵的，最快的，存储空间最小的。在实际生产中需要做到价格与性能（或者说实际需求）的平衡。下面从上到下梳理一下吧。</p>
<h2 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h2><p>恩，之前软考《网络工程师》的时候接触过一点点.哦，文章有点跑题了，但是还是想记录一下。CPU执行指令分为：取指令，分析指令，执行指令三部曲，这里面会用到一系列的寄存器，有分别属于控制器和运算器，列举几个常见的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">控制器</span><br><span class="line">    程序计数器PC：存放下一条指令的地址</span><br><span class="line">    指令寄存器IR:存放正在运行的指令</span><br></pre></td></tr></table></figure>
<p>指令包括操作码和地址码（操作数所在的地址）</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">运算器：</span><br><span class="line">    累加寄存器AC</span><br><span class="line">    数据缓冲寄存器</span><br><span class="line">    状态条件寄存器</span><br></pre></td></tr></table></figure>
<p>具体见下图：<br><img src="https://rancho333.gitee.io/pictures/register.png"><br>寄存器是CPU的内部组成单元，是CPU运算是取指令和数据最快的地方。当然不仅仅是CPU了，比如交换芯片及很多其它的ASIC都是用寄存器来实现某些功能的，你会发现芯片SDK提供的API最底层就是读写某些寄存器来实现具体功能。</p>
<h2 id="cache与主存"><a href="#cache与主存" class="headerlink" title="cache与主存"></a>cache与主存</h2><p>cache与主存都是RAM（Random-Access Memory, 随机访问存储器），cache使用的是静态SRAM，主存使用的是DRAM。这两种器件掉电数据都会丢失。</p>
<p>SRAM只要存储器保持通电，里面存储的数据就可以保持不变。<br>DRAM需要周期性的充电刷新，主存也就是我们PC中的内存条了。</p>
<h2 id="ROM与flash"><a href="#ROM与flash" class="headerlink" title="ROM与flash"></a>ROM与flash</h2><p>以前一直纳闷为啥只读存储还能改里面的数据。<br>ROM一般用来存放bootloader(一般叫做固件，firmware)，这里面的内容在程序运行期间是无法更改的，掉电数据依然存在。<br>早期ROM在工厂里用特殊方法烧录进去，一旦烧录进去，用户只能验证写入的资料是否正确，不能再做任何修改。<br>后来人们发明了PROM（Programmable ROM， 可编程ROM），工厂制作的PROM内部没有数据，用户可以使用专用的编程期间烧写资料进去，但只能写一次，一旦写入也无法修改。<br>再后来发明了EPROM（Erasable Programmable ROM, 可擦写可编程ROM），芯片可以重复擦除和写入，但是需要使用紫外线照射芯片，比较麻烦。<br>再后来发明了EEPROM（Electrically Erasable Programmable ROM，电可擦除可编程ROM）,用专门的烧录器和烧录软件就可以直接烧录了，很方便。现在用的ROM大部分是这种。</p>
<p>至于flash，咱们常见的u盘，固态硬盘灯都是基于flash中的NandFlash。flash分为NorFlash和NandFlash两种类型。<br>Nor的读取速度比Nand快一些，Nand的写入速度比Nor快很多，Nand的成本低，哈，这是很重要的。<br>Nand的读写操作是以块为单位的，Nor是以字节为单位。<br>NorFlash一般用来替代ROM用来存放BootLoader，容量较小，支持芯片内执行（XIP, eXecute In Place），Nand就是用来做大容量数据存储的啦！</p>
<p>顺带提一下eMMC，这玩意没见过。eMMC相当于NandFlash+主控IC ，对外的接口协议与SD、TF卡一样，主要是针对手机或平板电脑等产品的内嵌式存储器标准规格。eMMC的一个明显优势是在封装中集成了一个控制器。eMMC由一个嵌入式存储解决方案组成，带有MMC（多媒体卡）接口、快闪存储器设备（Nand Flash）及主控制器，所有都在一个小型的BGA 封装。</p>
<h1 id="结束语"><a href="#结束语" class="headerlink" title="结束语"></a>结束语</h1><p>其实就是RAM的分类，ROM的分类，以及Flash的分类有点迷！搞清楚特性，对应上用途！</p>
<p>参考资料：<br><a href="https://blog.csdn.net/iva_brother/article/details/80463578">计算机存储器结构体系详解</a><br><a href="https://baijiahao.baidu.com/s?id=1610041455262486965&wfr=spider&for=pc">NorFlash、NandFlash、eMMC闪存的比较与区别</a><br><a href="https://blog.csdn.net/qq_38880380/article/details/78884522">NAND flash和NOR flash的区别详解</a></p>
]]></content>
      <tags>
        <tag>存储</tag>
        <tag>flash</tag>
      </tags>
  </entry>
  <entry>
    <title>通过Hexo与Github.io搭建个人博客</title>
    <url>/2019/07/14/%E9%80%9A%E8%BF%87Hexo%E4%B8%8EGithub-io%E6%90%AD%E5%BB%BA%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/</url>
    <content><![CDATA[<h2 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h2><p>我信奉好记性不如记下来，上学时在笔记本上记笔记，后来在csdn上写点东西(有广告，不舒服)，后来笔记都记在有道云笔记上。最后发现利用github.io可以很方便的搭建个人博客。下面记录的是Blog搭建的过程(完成blog的上传)以及源码的备份，后面的文章记录一些优化与使用技巧。</p>
<span id="more"></span>

<h2 id="环境准备"><a href="#环境准备" class="headerlink" title="环境准备"></a>环境准备</h2><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Github账号</span><br><span class="line">Linux服务器</span><br><span class="line">  git</span><br><span class="line">  node.js(6.9版本以上)</span><br></pre></td></tr></table></figure>
<p>Github账号的注册在这里不做赘述，然后创建一个名为yourname.github.io的仓库（仓库名格式一定要符合）。我用的Linux是ubuntu16.04 server版(家用)与ubuntu18.04(aws云服务器,一年免费，可以用来科学上网)。hexo依赖于git与node.js<br>安装git  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">sudo apt-get install git-core</span><br></pre></td></tr></table></figure>

<p>安装node.js,具体的node.js与hexo的对应版本参见hexo官网，我们这里使用的是hexo3.9，对应的node.js版本应该不高于12,否则会有一些奇奇怪怪的错误。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">curl -sL https:&#x2F;&#x2F;deb.nodesource.com&#x2F;setup_15.x | sudo -E bash -</span><br><span class="line">sudo apt-get install -y nodejs</span><br></pre></td></tr></table></figure>

<p>依赖程序安装完成之后，就可以使用npm安装Hexo.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">npm install -g hexo-cli</span><br></pre></td></tr></table></figure>
<p>之后进行Hexo的初始化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">hexo init &lt;folder&gt;</span><br><span class="line">cd &lt;folder&gt;</span><br></pre></td></tr></table></figure>
<p>完成之后，指定文件夹的目录如下：<br><img src="https://rancho333.gitee.io/pictures/hexo_tree.png"><br>这里面不包含pbulic文件夹，会在执行第一次<code>hexo g</code>命令后生成，并且在执行<code>hexo d</code>命令后会生成<code>.deploy_git</code>文件夹，这两个文件夹中的内容是相同的，是最终部署到github.io中的文件。<br>然后执行<code>npm install</code>产生node_modules文件夹，至此，服务端的基本初始化完成。<br>修改<code>_config.yml</code>配置文件如下：  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">deploy:</span><br><span class="line">  type: git </span><br><span class="line">  repository: git@github.com:yourname&#x2F;yourname.github.io.git</span><br><span class="line">  branch: master</span><br></pre></td></tr></table></figure>
<p>部署到github.io即完成，执行<code>hexo g -d</code>。这时候访问：<code>https://yourname.github.io/</code>即可访问Blog。  </p>
<h2 id="Hexo常用命令"><a href="#Hexo常用命令" class="headerlink" title="Hexo常用命令"></a>Hexo常用命令</h2><table>
<thead>
<tr>
<th align="center">command</th>
<th align="center">description</th>
</tr>
</thead>
<tbody><tr>
<td align="center">hexo init [folder]</td>
<td align="center">新建一个网站</td>
</tr>
<tr>
<td align="center">hexo new <code>&lt;title&gt;</code></td>
<td align="center">新建文章，如标题包含空格用引号括起来</td>
</tr>
<tr>
<td align="center">hexo generate</td>
<td align="center">生成静态文件，简写hexo g</td>
</tr>
<tr>
<td align="center">hexo deploy</td>
<td align="center">部署网站，简写hexo d</td>
</tr>
<tr>
<td align="center">hexo clean</td>
<td align="center">清除缓存文件</td>
</tr>
<tr>
<td align="center">hexo version</td>
<td align="center">查看Hexo版本</td>
</tr>
<tr>
<td align="center">hexo –config custom.yml</td>
<td align="center">自定义配置文件路径，执行后不再使用_config.yml</td>
</tr>
</tbody></table>
<p>注意，每个主题下面也有一个_config.yml文件(作用域是该主题)，主目录下的是全局配置(作用域是整个网站)。  </p>
<h2 id="源码备份"><a href="#源码备份" class="headerlink" title="源码备份"></a>源码备份</h2><p>hexo d只是将生成的静态网页部署到github.io上，这样存放源码的服务器到期或者多台PC开发时便会产生不便，下面说明将源码部署到github.io上。<br>创建README.md文件</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">echo &quot;# shiningdan.github.io&quot; &gt;&gt; README.md</span><br></pre></td></tr></table></figure>
<p>初始化git仓库(在hexo init folder的folder目录下执行)，hexo d操作的仓库是.deployer_git.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git init </span><br><span class="line">git add README.md </span><br><span class="line">git commit -m &quot;first commit&quot;</span><br></pre></td></tr></table></figure>
<p>和github.io建立映射<br><code>git remote add origin https://github.com/yourname/yourname.github.io.git </code><br>master分支作为deploy的分支，创建hexo分支用来备份源码  </p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git branch hexo  </span><br><span class="line">git push origin hexo  </span><br><span class="line">git checkout hexo  </span><br></pre></td></tr></table></figure>
<p>将github.io中的默认分支修改为hexo(这样下载时就是下源码)，因为user page的发布版必须位于master分支下<br>后续开发在hexo分支下执行，执行<code>hexo g -d</code>生成网站并部署到github的master分支上，执行<code>git add、git commit、git push origin hexo</code>提交源码  </p>
<h3 id="重新部署"><a href="#重新部署" class="headerlink" title="重新部署"></a>重新部署</h3><ol>
<li>下载源码<code>git clone https://github.com/yourname/yourname.github.io.git</code></li>
<li>安装依赖<code>npm install -g hexo-cli、npm install、npm install hexo-deployer-git</code>,注意不需要执行<code>hexo init</code>  </li>
</ol>
<h2 id="迁移至gitee，工作环境打包"><a href="#迁移至gitee，工作环境打包" class="headerlink" title="迁移至gitee，工作环境打包"></a>迁移至gitee，工作环境打包</h2><p>2021年两会期间，github的访问可靠性大打折扣，项目中使用的SONiC编译也无法正常完成，鉴于当下的网络环境，现将blog的page放到<a href="https://rancho333.gitee.io/">gitee</a>上去。</p>
<p>除此之外，虽然之前将hexo的源码也备份到了远程仓库，但是一旦主机环境发生改变，得重新安装对应的依赖，这也带来一定的不稳定隐患，现在将开发环境打包到docker，发布到<a href="https://hub.docker.com/repository/docker/rancho123/ubuntu">docker hub</a>中, 后续个人的工作环境会持续集成进去。一些Linux通用配置（vim, bash）则存放到<a href="https://gitee.com/Rancho333/vim_cfg">gitee</a>上。</p>
<p><strong>参考资料：</strong><br><a href="https://hexo.io/zh-cn/docs/">HEXO官方文档</a></p>
]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>ARP协议简述及应用</title>
    <url>/2020/12/25/ARP%E5%8D%8F%E8%AE%AE%E7%AE%80%E8%BF%B0%E5%8F%8A%E5%BA%94%E7%94%A8/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>这篇文章分为两个部分ARP协议简介以及ARP协议的实际应用。</p>
<span id="more"></span>
<h1 id="ARP协议简介"><a href="#ARP协议简介" class="headerlink" title="ARP协议简介"></a>ARP协议简介</h1><h2 id="ARP的作用"><a href="#ARP的作用" class="headerlink" title="ARP的作用"></a>ARP的作用</h2><p>ARP(Address Resolution Protocol，地址解析协议)是将IP地址解析为以太网MAC地址的协议。与之相对的，将MAC地址解析为IP地址的协议称为RARP。</p>
<p>在局域网中，当终端设备需要将数据发送给另一个终端设备时，它必须知道对方网络的IP地址。但是仅仅有IP地址是不够的，因为IP数据必须封装成帧才能通过物理网络发送，因此发送端还必须有接收端的MAC地址，所以需要一个从IP地址到物理地址的映射。ARP就是实现这个功能的协议。</p>
<h2 id="ARP报文的结构"><a href="#ARP报文的结构" class="headerlink" title="ARP报文的结构"></a>ARP报文的结构</h2><p><img src="https://rancho333.gitee.io/pictures/arp_protocol.png"> </p>
<p>对于各个字段的解释如下</p>
<table>
<thead>
<tr>
<th align="left">字段</th>
<th align="left">长度（bit）</th>
<th align="left">含义</th>
</tr>
</thead>
<tbody><tr>
<td align="left">Ethernet Address of destination</td>
<td align="left">48</td>
<td align="left">目的以太网地址。发送ARP请求时，为广播MAC地址，0xFF.FF.FF.FF.FF.FF</td>
</tr>
<tr>
<td align="left">Ethernet Address of sneder</td>
<td align="left">48</td>
<td align="left">源以太网地址</td>
</tr>
<tr>
<td align="left">Frame Type</td>
<td align="left">16</td>
<td align="left">表示报文类型。对于ARP请求或应答，该字段为0x0806</td>
</tr>
<tr>
<td align="left">Hardware Type</td>
<td align="left">16</td>
<td align="left">表示硬件地址的类型。对于以太网，该字段为1</td>
</tr>
<tr>
<td align="left">Protocol Type</td>
<td align="left">16</td>
<td align="left">表示发送方要映射的协议地址类型。对于IP地址，该值为0x0800</td>
</tr>
<tr>
<td align="left">Hardware Length</td>
<td align="left">8</td>
<td align="left">表示硬件地址的长度，单位是字节。对于ARP请求或应答来说，该值为6</td>
</tr>
<tr>
<td align="left">Protocol Length</td>
<td align="left">8</td>
<td align="left">表示协议地址的长度，单位是字节。对于ARP请求或应答来说，该值为4</td>
</tr>
<tr>
<td align="left">OP</td>
<td align="left">16</td>
<td align="left">表示操作类型。1 表示ARP请求，2 表示ARP应答，3表示RARP请求，4表示RARP应答</td>
</tr>
<tr>
<td align="left">Ethernet Address of sneder</td>
<td align="left">48</td>
<td align="left">发送方以太网地址。这个字段和ARP报文首部的源以太网地址字段是重复信息</td>
</tr>
<tr>
<td align="left">IP Address of sender</td>
<td align="left">32</td>
<td align="left">发送方IP地址</td>
</tr>
<tr>
<td align="left">Ethernet Address of destination</td>
<td align="left">48</td>
<td align="left">接收方以太网地址，发送ARP请求时，该处填充全0</td>
</tr>
<tr>
<td align="left">IP Address of destination</td>
<td align="left">32</td>
<td align="left">接收方IP地址</td>
</tr>
</tbody></table>
<p>在Linux上可以通过tcpdump工具抓取ARP包</p>
<p><img src="https://rancho333.gitee.io/pictures/arp_data_raw.png"><br>使用wireshark工具可以更为方便的查看报文中的各个字段：</p>
<p><img src="https://rancho333.gitee.io/pictures/arp_data.png"> </p>
<h2 id="ARP地址解析过程"><a href="#ARP地址解析过程" class="headerlink" title="ARP地址解析过程"></a>ARP地址解析过程</h2><p>假设主机A和B在同一个网段，主机A要向主机B发送信息，解析过程如下：</p>
<ul>
<li>主机A查看自己的ARP表，找到则直接使用</li>
<li>如果A在ARP表中没有找到B，则<ul>
<li>缓存IP数据报文</li>
<li>发送ARP请求报文，请求B的MAC地址</li>
</ul>
</li>
<li>主机B比较自己的IP地址与ARP请求报文中的IP地址，两者相同则：<ul>
<li>将A的IP与MAC地址缓存到自己的ARP表中</li>
<li>单播发送ARP应答报文给主机A，其中包含自己的MAC地址</li>
</ul>
</li>
<li>主机A收到ARP响应后，缓存B的MAC到ARP表中，之后发送IP数据报文</li>
</ul>
<p>当主机A和B不在同一网段时，主机A会向网关发送ARP请求。如果网关有主机B的ARP表项，则直接应答A；否则网关广播ARP请求，目标IP地址为主机B的IP地址，网关收到响应报文之后再应答B。</p>
<h2 id="ARP表"><a href="#ARP表" class="headerlink" title="ARP表"></a>ARP表</h2><p>ARP表分为动态ARP表和静态ARP表。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Address                  HWtype  HWaddress           Flags Mask            Iface</span><br><span class="line">10.204.113.138           ether   00:00:00:00:00:01   C                     ens160</span><br><span class="line">10.204.113.151                   (incomplete)                              ens160</span><br><span class="line">172.17.0.7               ether   02:42:ac:11:00:07   C                     docker0</span><br><span class="line">10.204.112.11            ether   00:e0:ec:47:33:1a   C                     ens160</span><br><span class="line">openbmc-develop.asia.ad  ether   00:e0:4c:06:00:95   C                     ens160</span><br><span class="line">10.204.112.44            ether   6c:b3:11:32:7f:12   C                     ens160</span><br><span class="line">172.17.0.2               ether   02:42:ac:11:00:02   C                     docker0</span><br><span class="line">sonic.asia.ad.celestica  ether   aa:ad:40:03:ba:19   C                     ens160</span><br></pre></td></tr></table></figure>

<h3 id="动态ARP表"><a href="#动态ARP表" class="headerlink" title="动态ARP表"></a>动态ARP表</h3><p>动态ARP表由ARP协议通过ARP报文自动生成与维护，可以被老化，可以被新的ARP报文更新，可以被静态ARP表项覆盖。当到达老化时间、接口down时会删除相应的动态ARP表项。</p>
<h3 id="静态ARP表项"><a href="#静态ARP表项" class="headerlink" title="静态ARP表项"></a>静态ARP表项</h3><p>静态ARP表项通过手工配置和维护，不会被老化，不会被动态ARP表项覆盖。</p>
<p>配置静态ARP表项可以增加通信的安全性。静态ARP表项可以限制和指定IP地址的设备通信时使用指定的MAC地址，此时攻击报文无法修改此表项的IP地址和MAC地址的映射关系，<br>从而保护了本设备和指定设备间的正常通信。</p>
<p>静态ARP表项分为短静态ARP表项和长静态ARP表项。</p>
<ul>
<li>长静态ARP表项必须配置IP地址、MAC地址、所在VLAN和出接口。长静态ARP表项可直接用于报文转发。</li>
<li>短静态ARP表项只需要配置IP地址和MAC地址。<ul>
<li>如果出接口是三层口，直接用于报文转发</li>
<li>如果出接口是VLAN虚接口，短静态ARP表项不能直接用于报文转发，当要发送IP数据包时，先发送ARP请求报文，如果收到的response中的<br>源IP和源MAC与所配置的相同，则将收到response的接口加入该静态ARP中，之后用于IP数据包转发。</li>
</ul>
</li>
</ul>
<p>当希望设备和指定用户只能使用某个固定的IP地址和MAC地址通信时，可以配置短静态ARP表项，当进一步希望这个用户只在某个VLAN内的某个特定接口上连接时就可以配置长静态ARP表项</p>
<h2 id="免费ARP"><a href="#免费ARP" class="headerlink" title="免费ARP"></a>免费ARP</h2><p>免费ARP是一种特殊的ARP报文，该报文中携带的发送端与目的端IP都是本机IP，发送端MAC是本机MAC，接收端MAC是全f。其本质是keep alive保活/心跳报文的应用。<br>免费ARP报文有以下功能:</p>
<ul>
<li>IP地址冲突检测。如果有冲突，冲突设备会给本机发送一个ARP应答，告知IP地址冲突</li>
<li>设备改变MAC地址，发送免费ARP更新其它设备中的ARP表项</li>
</ul>
<p>定时发送免费ARP的应用场景：</p>
<ul>
<li>防止仿冒网关的ARP攻击（ARP欺骗）<ul>
<li>如果攻击者仿冒网关发送免费ARP报文，可以将原本发送到网关的流量重定向到一个错误的MAC地址，导致用户无法正常访问网络。网关接口上使能免费ARP功能后，主机可以学习到正确的网关。</li>
</ul>
</li>
<li>防止ARP表项老化</li>
<li>防止VRRP虚拟IP地址冲突</li>
<li>及时更新模糊终结VLAN内设备的MAC地址表</li>
</ul>
<h1 id="ARP协议应用"><a href="#ARP协议应用" class="headerlink" title="ARP协议应用"></a>ARP协议应用</h1><p>ARP协议的状态机比较简单，但是应用起来是比较有意思的，一些基础网络问题也是值得思考的。</p>
<h2 id="二层通信与三层通信中ARP的应用"><a href="#二层通信与三层通信中ARP的应用" class="headerlink" title="二层通信与三层通信中ARP的应用"></a>二层通信与三层通信中ARP的应用</h2><p>二三层设备互通中arp是怎样工作的？</p>
<p><img src="https://rancho333.gitee.io/pictures/ping_arp.png"><br>如图所示，两个vlan通过interface vlan路由接口实现互通。下文说明中，交换机和终端设备均为初始状态，不含有arp表项。</p>
<h3 id="A和B之间的互通-二层"><a href="#A和B之间的互通-二层" class="headerlink" title="A和B之间的互通(二层)"></a>A和B之间的互通(二层)</h3><p>以A向B发起ping请求为例。</p>
<ol>
<li>A检查报文的目的IP地址发现和自己在同一个网段；</li>
<li>A—-&gt;B ARP请求报文，该报文在VLAN1内广播<ol>
<li>报文的dst mac是广播mac，src mac是A mac</li>
<li>报文的sender MAC是A mac, sender ip是A ip; target mac是全0，target ip是B ip</li>
</ol>
</li>
<li>B—-&gt;A  ARP回应报文<ol>
<li>报文的dst mac是A mac, src mac是B mac</li>
<li>报文的sender MAC是B mac(A请求的mac), sender ip是B ip; target mac是A mac，taaget ip是A ip</li>
</ol>
</li>
<li>A—-&gt;B  icmp request</li>
<li>B—-&gt;A  icmp reply</li>
</ol>
<h3 id="A和C之间的互通-三层"><a href="#A和C之间的互通-三层" class="headerlink" title="A和C之间的互通(三层)"></a>A和C之间的互通(三层)</h3><p>以A向C发起ping请求为例。</p>
<ol>
<li>A检查报文的目的IP地址，发现和自己不在同一个网段</li>
<li>A—-&gt;switch(int vlan 1) ARP请求报文，该报文在vlan1内广播<ol>
<li>报文的dst mac是广播mac，src mac是A mac</li>
<li>报文的sender MAC是A mac, sender ip是A ip; target mac是全0，target ip是int vlan 1 ip</li>
</ol>
</li>
<li>网关—-&gt; A ARP回应报文<ol>
<li>报文的dst mac是A mac, src mac是int vlan 1 mac</li>
<li>报文的sender MAC是int vlan 1 mac(A请求的mac), sender ip是int vlan 1 ip; target mac是A mac，taaget ip是A ip</li>
</ol>
</li>
<li>A—-&gt;C icmp request<ol>
<li>报文dst mac是int vlan 1的mac，src mac是A的mac; dst ip是C ip，src ip是A ip</li>
</ol>
</li>
<li>switch收到报文后判断出是三层报文，检查报文的目的IP地址，发现是在自己的直连网段</li>
<li>switch(int vlan 2)—-&gt;C ARP请求报文，该报文在vlan2内广播</li>
<li>C—-&gt;switch(int vlan 2) ARP回应报文</li>
<li>switch(int vlan 2)—-&gt;C icmp request<ol>
<li>报文的dst mac是C的mac, src mac是int vlan 2的mac; dst ip是C ip, src ip是A ip</li>
</ol>
</li>
<li>C—-&gt;A icmp reply, 这以后的处理同前面icmp request的过程基本相同。</li>
</ol>
<p>对报文路由，会对报文的MAC头进行重新封装，而IP层以上的字段基本不变。通过说明报文dst/src MAC的变化，注意ARP在二三层通信中起的作用。后续设备中ARP表有了相应的条目之后，则不会给对方发送ARP请求报文。</p>
<h2 id="ARP代理"><a href="#ARP代理" class="headerlink" title="ARP代理"></a>ARP代理</h2><p>如果ARP请求是从一个网络的主机发往同一网段却不在同一物理网络上的另一台主机，那么连接它们的具有代理ARP功能的设备就可以回答该请求，这个过程称作代理ARP（Proxy ARP）<br>代理ARP功能屏蔽分离的物理网络这一事实，使用户使用起来，好像在同一物理网络上。<br>代理ARP分为普通代理ARP和本地代理ARP，二者的应用场景有所区别。</p>
<ul>
<li>普通代理ARP的应用场景：想要互通的主机分别连接到设备的不同的三层接口上，且这些主机不在同一个广播域中</li>
<li>本地代理ARP的应用环境为：想要互通的主机连接到设备的同一个三层接口在，且这些主机不在同一个广播域中</li>
</ul>
<h3 id="普通代理ARP"><a href="#普通代理ARP" class="headerlink" title="普通代理ARP"></a>普通代理ARP</h3><p>处于同一网段内的主机，当连接到设备的不同三层接口时，可以利用设备的代理ARP功能，通过三层转发实现互通。<br>拓扑如下图所示。设备Router通过两个三层接口Eth1/1和Eth1/2连接两个网络，两个三层接口的IP地址不在同一个网段，但是两个网络内的主机Host A和Host B的地址通过掩码的控制，既与相连设备的接口地址在同一网段，同时二者也处于同一个网段。<br><img src="https://rancho333.gitee.io/pictures/general_arp_agent.png"><br>这种组网场景下，当Host A需要与Host B通信时，由于dst ip与src ip在同一网段，因此Host A会直接对Host B进行ARP请求。但是，两台主机不在同一个广播域中，Host B无法收到Host A的ARP请求报文，当然也就无法应答。<br>通过在Router上启用代理ARP功能，可以解决此问题。启用代理ARP后,Router可以应答Host A的ARP请求。同时，Router相当于Host B的代理，把从其它主机发送过来的报文转发给它。<br>代理ARP的优点是，它可以只被应用在一个设备上（此时设备的作用相当于网关），不会影响到网络中其它设备的路由表。代理ARP功能可以在IP主机没有配置缺省网关或者IP主机没有任何路由能力的情况下使用。</p>
<h3 id="本地代理ARP"><a href="#本地代理ARP" class="headerlink" title="本地代理ARP"></a>本地代理ARP</h3><p>拓扑如图所示。Host A与Host B属于同一个VLAN 2,但他们分别连接到被二层隔离的端口Eth1/3和Eth1/1上，通过在Router上启用本地代理ARP功能，可以实现Host A和Host B的三层互通。<br><img src="https://rancho333.gitee.io/pictures/local_arp_agent.png"></p>
<p>本地代理ARP可以在下列三种情况下实现主机之间的三层互通：</p>
<ul>
<li>想要互通的主机分别连接到同一个VLAN中的不同的二层隔离端口下</li>
<li>使能Super VLAN功能后，想要互通的主机属于不同的Sub VLAN</li>
<li>使能Lsolate-user-vlan功能后，想要互通的主机属于不同的Secondary VLAN</li>
</ul>
<h2 id="ARP-Snooping"><a href="#ARP-Snooping" class="headerlink" title="ARP Snooping"></a>ARP Snooping</h2><p>ARP snooping功能是一个用于二层交换网络环境的特性，通过侦听ARP报文建立ARP Snooping表项，从而提供给ARP快速应答和MFF手动方式等使用。<br>设备上的一个VLAN使能ARP Snooping后，该VLAN内所有端口接收的ARP报文会被重定向到CPu。CPU对重定向上送的ARP报文进行分析，获取ARP报文的src ip, src mac, src vlan和入端口信息，建立记录用户信息的ARP Snooping表项。</p>
<h2 id="ARP快速应答"><a href="#ARP快速应答" class="headerlink" title="ARP快速应答"></a>ARP快速应答</h2><p>在无线产品组网中，AC与AP会建立隧道连接，Client通过AP连接到AC，通过AC，client可以与网关建立连接。当Client发起ARP广播请求时，需要通过AC向所有的AP复制ARP请求，这样会导致ARP广播占用隧道的大量资源，导致性能下降。为了减少ARP广播占用的隧道资源，可以在AC上启用ARP快速应答功能，减少ARP广播报文的影响。</p>
<p>ARP快速应答功能就是根据AC设备收集的用户信息（DHCP Snooping表项或者ARP Snooping表项），在指定的VLAN内，尽可能的对ARP请求进行应答，从而减少ARP广播报文。</p>
<h3 id="ARP快速应答工作机制"><a href="#ARP快速应答工作机制" class="headerlink" title="ARP快速应答工作机制"></a>ARP快速应答工作机制</h3><p>ARP快速应答的工作机制如下：</p>
<ol>
<li>设备接收到ARP请求报文时，如果请求报文的目的IP地址是设备的VLAN虚接口的IP地址，则由ARP特性进行处理</li>
<li>如果不是，则根据报文中的目的IP地址查找DHCP Snooping表项<ol>
<li>如果查找成功，但是查找到的表项的接口和收到请求报文的接口一致，并且接口是以太网接口，则不进行应答，否则立即进行应答</li>
<li>如果查找失败，则继续查找ARP Snooping表项。如果查找成功，但是查找到的表项的接口和收到请求报文的接口一致，并且接口是以太网接口，则不进行应答，否则立即进行应答。</li>
<li>如果两个表项均查找失败，则直接转发请求报文或将报文交于其它特性处理。</li>
</ol>
</li>
</ol>
<h2 id="ARP防御攻击"><a href="#ARP防御攻击" class="headerlink" title="ARP防御攻击"></a>ARP防御攻击</h2><p>ARP协议有简单、易用的优点，但是也因为没有任何安全机制而容易被攻击发起者利用。</p>
<ul>
<li>攻击者可以仿冒用户、仿冒网关发送伪造的ARP报文，使网关或主机的ARP表项不正确，从而对网络进行攻击</li>
<li>攻击者通过向设备发送大量目标IP地址不能解析的IP报文，使得设备试图反复地对目标IP地址进行解析，导致CPU负荷过重及网络流量过大</li>
<li>攻击者向设备发送大量的ARP报文，对设备的CPU形成冲击。<br>目前ARP攻击和ARP病毒已经成为局域网安全的一大威胁。下面简单说明一下ARP攻防原理。</li>
</ul>
<h3 id="ARP防止IP报文攻击功能简介"><a href="#ARP防止IP报文攻击功能简介" class="headerlink" title="ARP防止IP报文攻击功能简介"></a>ARP防止IP报文攻击功能简介</h3><p>如果网络中有主机通过向设备发送大量目标IP地址不能解析的IP报文来攻击设备，则会造成下面的危害：</p>
<ul>
<li>设备向目的网段发送大量的ARP请求报文，加重目的网段的负载</li>
<li>设备会试图反复地对目标IP地址进行解析，增加了CPU的负担</li>
</ul>
<p>为了避免这种IP报文攻击所带来的危害，设备提供了下列两个功能：</p>
<ul>
<li>如果发送攻击报文的源是固定的，可以采用ARP源抑制功能。开启该功能后，如果网络中某主机向设备某端口连续发送目标IP地址不能解析的IP报文，当每5秒内此主机发出IP报文出发ARP请求报文的流量超过设置的阈值，那么对于由此主机发出的IP报文，设备不允许其触发ARP请求，直至5秒后再处理，从而避免了恶意攻击所造成的危害。</li>
<li>如果发送攻击报文的源不固定，设备立即产生一个黑洞路由，使得设备在一段时间内将去往该地址的报文直接丢弃。等待黑洞路由老化时间过后，如有报文触发则再次发起解析，如果解析成功则进行转发，否则仍然产生一个黑洞路由将去往改地址的报文丢弃。这种方式能够有效的防止IP报文的攻击，减轻CPU的负担。</li>
</ul>
<h3 id="ARP报文限速功能"><a href="#ARP报文限速功能" class="headerlink" title="ARP报文限速功能"></a>ARP报文限速功能</h3><p>ARP报文限速功能是指对上送CPU的ARP报文进行限速，可以防止大量ARP报文对CPU进行冲击。例如，在配置了ARP Detection功能后，设备会将收到的ARP报文重定向到CPU进行检查，这样会引入新的问题：如果攻击者恶意构造大量ARP报文发往设备，会导致设备的CPU负担过重，从而造成其它功能无法正常运行甚至设备瘫痪，这个时候可以启用ARP报文限速功能来控制上送CPU的ARP报文的速率。</p>
<p>推荐用户在配置了ARP Detection、ARP Snooping、ARP快速应答、MFF，或者发现有ARP泛洪攻击的情况下，使用ARP报文限速功能。</p>
<h3 id="源MAC地址固定的ARP攻击检测功能"><a href="#源MAC地址固定的ARP攻击检测功能" class="headerlink" title="源MAC地址固定的ARP攻击检测功能"></a>源MAC地址固定的ARP攻击检测功能</h3><p>本特性根据ARP报文的源MAC地址进行统计，在5秒内，如果收到同一源MAC地址的ARP报文超过一定的阈值，则认为存在攻击，系统会将此MAC地址添加到攻击检测表项中。在该攻击检测表项老化之前，如果设置的检查模式为过滤模式，则会打印告警信息并将该源MAC地址发送的ARP报文过滤掉。如果设置为监控模式，则只打印告警信息，不会将源MAC地址发送的ARP报文过滤掉。<br>对于网关或一些重要的服务器，可能会发送大量的ARP报文，为了使这些ARP报文不被过滤掉，可以将这类设备的MAC地址配置成保护MAC，这样，即使该MAC存在攻击也不会被检测过滤。只对上送CPU的ARP报文进行统计。</p>
<h3 id="ARP报文源MAC一致性检查功能简介"><a href="#ARP报文源MAC一致性检查功能简介" class="headerlink" title="ARP报文源MAC一致性检查功能简介"></a>ARP报文源MAC一致性检查功能简介</h3><p>ARP报文源MAC一致性检查功能主要应用于网关设备上，防御以太网数据帧首部中的源MAC地址和ARP报文中sender mac地址不同的ARP攻击。</p>
<p>在配置被特性后，网关设备在进行ARP学习前将对ARP报文进行检查。如果以太网数据帧首部中的源MAC地址和ARP报文中sender mac地址不同，则认为是攻击报文，将其丢弃，否则，继续进行ARP学习。</p>
<h3 id="ARP主动确认功能"><a href="#ARP主动确认功能" class="headerlink" title="ARP主动确认功能"></a>ARP主动确认功能</h3><p>ARP的主动确认功能主要应用于网关设备上，防止攻击者仿冒用户欺骗网关设备。</p>
<p>启用ARP主动确认功能后，设备在新建或更新ARP表项前需进行主动确认，防止产生错误的ARP表项。</p>
<h2 id="MLAG结合VARP实现VRRP"><a href="#MLAG结合VARP实现VRRP" class="headerlink" title="MLAG结合VARP实现VRRP"></a>MLAG结合VARP实现VRRP</h2><p>VRRP(virtual router redundancy protocol，虚拟路由器冗余协议)将可以承担网关功能的一组路由器加入到备份组中，形成一台虚拟路由器，局域网内的终端设备只需将虚拟路由器配置为缺省网关即可。VRRP有两个版本，VRRPv2基于IPv4, VRRPv3基于IPv6。正统的VRRP实现起来可能有些复杂，通过MLAG结合VARP可以较为简单的实现VRRP的功能。拓扑如下。<br><img src="https://rancho333.gitee.io/pictures/varp_mlag_vrrp.png"></p>
<p>原理说明：device作为leaf switch, 下行接host，上行通过mlag连接到两台网关。策略配置之后，host发往网关的流量只会通过mlag中的一个端口发往switch A或switch B, 当mlag中一条线路down掉时，通过另一条线路通信，在switch A和switch B上运行VARP协议，通过配置相同的VIP和VMAC实现网关虚拟化。这里面有两个关键点。</p>
<ul>
<li>主机流量同一时间只会发往一台物理网关</li>
<li>物理网关上配置相同的VIP和VMAC实现网关虚拟化</li>
</ul>
<p>对于VARP说明，可以通过ip地址/mac地址确定唯一三层接口，但是三层接口可以被多个ip地址/mac地址定位到。对于虚拟网关，物理网关除了正常配置的ip与mac地址，还会配置一组相同的vip/vmac，主机将vip作为网关ip。对于物理网关：</p>
<ul>
<li>只有当主机请求vip时才回复vmac</li>
<li>主动发送arp或者转发三层报文时，src mac使用的都是自己真实的router mac</li>
</ul>
<p>对于主机而言，网关是虚拟的，所以使用虚拟网关ip进行通信<br>对于交换机而言，自己与外界通信需要使用自己真实的ip和mac, 这样对方才能根据真实的ip和mac定位到自己。</p>
<p>当MLAG交换机配置了VARP之后，host通过arp去请求VARP虚拟网关ip的mac地址，则MLAG-VARP交换机回应的自然是虚拟网关的mac;host发送icmp request给虚拟网关，虚拟网关使用真实的router-mac去回复。</p>
]]></content>
      <tags>
        <tag>通信协议</tag>
      </tags>
  </entry>
  <entry>
    <title>Systemd学习</title>
    <url>/2021/01/26/Systemd%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>Systemd是现代Linux的服务启动管理。Linux的第一个进程已经由<code>init</code>变成<code>systemd</code>了。</p>
<span id="more"></span>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">[rancho sonic-buildimage]$ ps -ef | grep root | grep init</span><br><span class="line">root         1     0  0  2020 ?        00:19:51 &#x2F;sbin&#x2F;init splash</span><br><span class="line">[rancho sonic-buildimage]$ file &#x2F;sbin&#x2F;init</span><br><span class="line">&#x2F;sbin&#x2F;init: symbolic link to &#x2F;lib&#x2F;systemd&#x2F;systemd</span><br></pre></td></tr></table></figure>
<p>init的两个缺点:</p>
<ol>
<li>启动时间长。init是串行启动。</li>
<li>启动脚本复杂。init进程只是执行启动脚本，不管其它事情。所以脚本里面要处理各种情况，如依赖关系等，这使得脚本变得复杂且长。</li>
</ol>
<h1 id="Systemd概述"><a href="#Systemd概述" class="headerlink" title="Systemd概述"></a>Systemd概述</h1><p>Linux一直没有一个统一的管理平台，所以各种资料与学习都很零散，而且是一个分散的管理系统。Systemd是一个趋势，不然这么多发行版(Arch Linux、Debian系、Red Hat系)也不会去集成它了。</p>
<p>Systemd的设计目标是：为系统的启动和管理提供一套完整的解决方案。</p>
<p>Systemd的优点是功能强大，使用方便。缺点是体系庞大，非常复杂，与操作系统其它部分强耦合。<br><img src="https://rancho333.gitee.io/pictures/arch_of_systemd.png"></p>
<h1 id="Systemd命令族"><a href="#Systemd命令族" class="headerlink" title="Systemd命令族"></a>Systemd命令族</h1><p>Systemd是一组命令的集合，涉及到系统管理的各个方面。</p>
<h2 id="systemctl"><a href="#systemctl" class="headerlink" title="systemctl"></a>systemctl</h2><p><code>systemctl</code>是Systemd的主命令，用于系统管理。systemctl接受服务（.service），挂载点（.mount）,套接口（.socket）和设备（.device）作为单元。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl --version                 #查看systemd的版本</span><br><span class="line">systemctl reboot                    #重启系统</span><br><span class="line">systemctl poweroff                  #掉电</span><br><span class="line">systemctl halt                      #CPU停止工作</span><br><span class="line">systemctl suspend                   #暂停系统</span><br><span class="line"></span><br><span class="line">systemctl list-unit-files           #列出所有可用单元</span><br><span class="line">            [--type&#x3D;service]        #所有服务</span><br><span class="line">            [--type&#x3D;mount]          #所有系统挂载点</span><br><span class="line">            [--type&#x3D;socket]         #所有可用系统套接口</span><br><span class="line">systemctl list-units                #列出所有运行中的单元</span><br><span class="line">systemctl --failed                  #列出所有失败的单元</span><br><span class="line"></span><br><span class="line">systemctl status                    #显示系统状态</span><br><span class="line">            [XX.service]            #检查某个服务状态</span><br><span class="line">systemctl start XX.service          </span><br><span class="line">systemctl restart XX.service</span><br><span class="line">systemctl stop XX.service</span><br><span class="line">systemctl reload XX.service         #启动、重启、停止、重载服务</span><br><span class="line"></span><br><span class="line">systemctl is-active XX.service      #检查某个单元是否正在运行</span><br><span class="line">systemctl is-enabled XX.service     #检查某个单元是否启用</span><br><span class="line">systemctl is-failed XX.service      #检查某个单元是否启动失败</span><br><span class="line"></span><br><span class="line">systemctl enable XX.service         #在启动时启用服务</span><br><span class="line">systemctl disable XX.service        #在启动时禁止服务</span><br><span class="line">systemctl kill XX.service           #杀死服务</span><br><span class="line">systemctl show XX                   #检查某个服务的所有配置细节</span><br><span class="line"></span><br><span class="line">systemctl mask XX.service           #屏蔽服务</span><br><span class="line">systemctl unmask XX.service         #显示服务</span><br><span class="line"></span><br><span class="line">systemctl list-dependencies XX.service      #获取某个服务的依赖性列表</span><br><span class="line"></span><br><span class="line">systemctl get-default               #查看启动时的默认target</span><br><span class="line"></span><br><span class="line">systemctl daemon-reload             # 重新加载配置文件</span><br><span class="line">systemctl restart foobar            # 重启相关服务</span><br></pre></td></tr></table></figure>

<h2 id="systemd-analyze"><a href="#systemd-analyze" class="headerlink" title="systemd-analyze"></a>systemd-analyze</h2><p>服务分析工具。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemd-analyze                     #查看启动耗时</span><br><span class="line">systemd-analyze plot                #生成更直观的图表</span><br><span class="line">systemd-analyze blame               #查看各个进程耗费时间</span><br><span class="line">systemd-analyze critical-chain      #分析启动时的关键链</span><br><span class="line">systemd-analyze critical-chain XX.service   #分析某个服务的关键链</span><br></pre></td></tr></table></figure>

<h2 id="不常用命令"><a href="#不常用命令" class="headerlink" title="不常用命令"></a>不常用命令</h2><p>systemd的有些命令功能会和某些命令重合，还有一些不常见的命令，如：hostnamectl、localectl、timedatectl、loginctl。</p>
<h1 id="Unit"><a href="#Unit" class="headerlink" title="Unit"></a>Unit</h1><p>Systemd可以管理所有的系统资源，不同的资源统称为unit(单元)。<br>unit一共分成12种.   </p>
<ul>
<li>service : 系统服务</li>
<li>target : 多个unit构成的一个组</li>
<li>device : 硬件设备</li>
<li>mount : 文件系统挂载点</li>
<li>automount : 自动挂载点</li>
<li>path ： 文件或路径</li>
<li>scope ： 不是由systemd启动的外部进程</li>
<li>slice ： 进程组</li>
<li>snapshot : systemd快照，可以切回某个快照</li>
<li>socket : 进程间通信的socket</li>
<li>swap : swap文件</li>
<li>timer : 定时器</li>
</ul>
<h2 id="unit配置文件"><a href="#unit配置文件" class="headerlink" title="unit配置文件"></a>unit配置文件</h2><p>每一个unit都有一个配置文件，告诉systemd怎么启动这个unit。<br>systemd默认从<code>/etc/systemd/system</code>读取配置文件。这里面部分文件是符号链接，指向<code>/lib/systemd/system</code>或者<code>/usr/lib/systemd/system</code>。</p>
<p><code>systemctl enable</code>的本质就是在上面两个目录的文件之间建立符号链接关系。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl enable XX.service</span><br><span class="line">等同于</span><br><span class="line">ln -s &#x2F;lib&#x2F;systemd&#x2F;system&#x2F;XX.service &#x2F;etc&#x2F;systemd&#x2F;system&#x2F;XX.service</span><br></pre></td></tr></table></figure>
<p><img src="https://rancho333.gitee.io/pictures/systemd_enable.png"></p>
<p>如果配置文件里面设置了开机启动，<code>systemctl enable</code>命令相当于激活开机启动。</p>
<p>配置文件的后缀名就是该unit的种类，systemd默认后缀名是<code>.service</code>，所以<code>bluetooth</code>等效于<code>bluetooth.service</code>。</p>
<p><code>systemctl list-unit-files</code>会显示每个unit的状态，一共有四种：</p>
<ul>
<li>enabled：已建立启动连接</li>
<li>disabled：未建立启动链接</li>
<li>static: 该配置文件没有[install]部分，无法通过enable命令进行安装。只能做为其它unit的依赖(After字段或Requires字段)或者手动开启。相反的，基于这个特性，它无法通过disable关闭，一般用在必须启动的unit上。如写一个rc-local.service，实现开机后自动实现某些功能。</li>
<li>masked：该配置文件被禁止建立启动链接</li>
</ul>
<h2 id="配置文件的格式"><a href="#配置文件的格式" class="headerlink" title="配置文件的格式"></a>配置文件的格式</h2><p>配置文件示例如下：<br><img src="https://rancho333.gitee.io/pictures/systemd_config_file.png"></p>
<p>配置文件分为Unit、Service、Install等区块，每个区块中都是key-value形式的配置。</p>
<p><code>[Unit]</code>是配置文件的第一个区块，用来定义Unit的元数据，以及配置与其他Unit的关系，主要字段如下：</p>
<ul>
<li>Description: 简短描述</li>
<li>Documentation: 文档地址</li>
<li>Requires: 当前 Unit 依赖的其他 Unit，如果它们没有运行，当前 Unit 会启动失败</li>
<li>Wants：与当前 Unit 配合的其他 Unit，如果它们没有运行，当前 Unit 不会启动失败</li>
<li>BindsTo：与Requires类似，它指定的 Unit 如果退出，会导致当前 Unit 停止运行</li>
<li>Before：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之后启动</li>
<li>After：如果该字段指定的 Unit 也要启动，那么必须在当前 Unit 之前启动</li>
<li>Conflicts：这里指定的 Unit 不能与当前 Unit 同时运行</li>
<li>Condition…：当前 Unit 运行必须满足的条件，否则不会运行</li>
<li>Assert…：当前 Unit 运行必须满足的条件，否则会报启动失败</li>
</ul>
<p><code>[Service]</code>区块用来Service配置，只有Service类型的Unit才会有这个区块，它的主要字段如下：</p>
<ul>
<li>Type：定义启动时的进程行为。它有以下几种值<ul>
<li>Type=simple：默认值，执行ExecStart指定的命令，启动主进程</li>
<li>Type=forking：以 fork 方式从父进程创建子进程，创建后父进程会立即退出</li>
<li>Type=oneshot：一次性进程，Systemd 会等当前服务退出，再继续往下执行</li>
<li>Type=dbus：当前服务通过D-Bus启动</li>
<li>Type=notify：当前服务启动完毕，会通知Systemd，再继续往下执行</li>
<li>Type=idle：若有其他任务执行完毕，当前服务才会运行</li>
</ul>
</li>
<li>ExecStart：启动当前服务的命令</li>
<li>ExecStartPre：启动当前服务之前执行的命令</li>
<li>ExecStartPost：启动当前服务之后执行的命令</li>
<li>ExecReload：重启当前服务时执行的命令</li>
<li>ExecStop：停止当前服务时执行的命令</li>
<li>ExecStopPost：停止当其服务之后执行的命令</li>
<li>RestartSec：自动重启当前服务间隔的秒数</li>
<li>Restart：定义何种情况 Systemd 会自动重启当前服务，可能的值包括always（总是重启）、on-success、on-failure、on-abnormal、on-abort、on-watchdog</li>
<li>TimeoutSec：定义 Systemd 停止当前服务之前等待的秒数</li>
<li>Environment：指定环境变量</li>
</ul>
<p><code>[Install]</code>通常是配置文件的最后一个区块，用来定义如何启动，以及是否开机启动，它的主要字段如下：</p>
<ul>
<li>WantedBy：它的值是一个或多个 Target，当前 Unit 激活时（enable）符号链接会放入/etc/systemd/system目录下面以 Target 名 + .wants后缀构成的子目录中</li>
<li>RequiredBy：它的值是一个或多个 Target，当前 Unit 激活时，符号链接会放入/etc/systemd/system目录下面以 Target 名 + .required后缀构成的子目录中</li>
<li>Alias：当前 Unit 可用于启动的别名</li>
<li>Also：当前 Unit 激活（enable）时，会被同时激活的其他 Unit</li>
</ul>
<p>Unit配置文件的完整key-value清单，参见<a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html">官方文档</a>。</p>
<h1 id="Target"><a href="#Target" class="headerlink" title="Target"></a>Target</h1><p>计算机启动的时候，需要启动大量的Unit。如果每一次启动，都要一一写明本次启动需要那些Unit，显然非常不方便。Systemd的解决方案就是Target。</p>
<p>Target就是一个Unit组，包含许多相关的Unit。启动某个Target的时候，Systemd就会启动里面所有的Unit。从这个意义上说，Target这个概念类似于“状态点”，启动某个Target就好比启动到某种状态。</p>
<p>传统的Init启动模式中，有Runlevle的概念，和Target的作用很类似。不同的是，Runlevel是互斥的，但是多个Target是可以同时启动的。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">systemctl get-default           #查看启动时的默认 Target</span><br><span class="line">systemctl list-dependencies multi-user.target   #查看一个 Target 包含的所有 Unit</span><br></pre></td></tr></table></figure>

<p>它与Init的主要差别如下：</p>
<ol>
<li>默认的 RunLevel（在/etc/inittab文件设置）现在被默认的 Target 取代，位置是/etc/systemd/system/default.target，通常符号链接到graphical.target（图形界面）或者multi-user.target（多用户命令行）。</li>
<li>启动脚本的位置，以前是/etc/init.d目录，符号链接到不同的 RunLevel 目录 （比如/etc/rc3.d、/etc/rc5.d等），现在则存放在/lib/systemd/system和/etc/systemd/system目录。</li>
<li>配置文件的位置，以前init进程的配置文件是/etc/inittab，各种服务的配置文件存放在/etc/sysconfig目录。现在的配置文件主要存放在/lib/systemd目录，在/etc/systemd目录里面的修改可以覆盖原始设置。</li>
</ol>
<h1 id="日志管理"><a href="#日志管理" class="headerlink" title="日志管理"></a>日志管理</h1><p>Systemd统一管理Unit的启动日志，通过<code>journalctl</code>命令可以查看所有日志，日志的配置文件是<code>/etc/systemd/journald.conf</code>。它的功能很强大，用法也很多。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">journalctl                      # 查看所有日志（默认情况下 ，只保存本次启动的日志）</span><br><span class="line"></span><br><span class="line">journalctl -k                   # 查看内核日志（不显示应用日志）</span><br><span class="line"></span><br><span class="line">journalctl -b                    # 查看系统本次启动的日志</span><br><span class="line">journalctl -b -0</span><br><span class="line"></span><br><span class="line"># 查看指定时间的日志</span><br><span class="line">journalctl --since&#x3D;&quot;2012-10-30 18:17:16&quot;</span><br><span class="line">journalctl --since &quot;20 min ago&quot;</span><br><span class="line">journalctl --since yesterday</span><br><span class="line">journalctl --since &quot;2015-01-10&quot; --until &quot;2015-01-11 03:00&quot;</span><br><span class="line">journalctl --since 09:00 --until &quot;1 hour ago&quot;</span><br><span class="line"></span><br><span class="line">journalctl -n                   # 显示尾部的最新10行日志</span><br><span class="line">journalctl -n 20                # 显示尾部指定行数的日志</span><br><span class="line"></span><br><span class="line">journalctl -f                   # 实时滚动显示最新日志</span><br><span class="line"></span><br><span class="line">journalctl &#x2F;usr&#x2F;lib&#x2F;systemd&#x2F;systemd    # 查看指定服务的日志</span><br><span class="line"></span><br><span class="line">journalctl _PID&#x3D;1               # 查看指定进程的日志</span><br><span class="line"></span><br><span class="line">journalctl &#x2F;usr&#x2F;bin&#x2F;bash        # 查看某个路径的脚本的日志</span><br><span class="line"></span><br><span class="line">journalctl _UID&#x3D;33 --since today    # 查看指定用户的日志</span><br><span class="line"></span><br><span class="line"># 查看某个 Unit 的日志</span><br><span class="line">journalctl -u nginx.service</span><br><span class="line">journalctl -u nginx.service --since today</span><br><span class="line"></span><br><span class="line"># 查看指定优先级（及其以上级别）的日志，共有8级</span><br><span class="line"># 0: emerg</span><br><span class="line"># 1: alert</span><br><span class="line"># 2: crit</span><br><span class="line"># 3: err</span><br><span class="line"># 4: warning</span><br><span class="line"># 5: notice</span><br><span class="line"># 6: info</span><br><span class="line"># 7: debug</span><br><span class="line">journalctl -p err -b</span><br><span class="line"></span><br><span class="line">journalctl --disk-usage                  # 显示日志占据的硬盘空间</span><br><span class="line"></span><br><span class="line">journalctl --vacuum-size&#x3D;1G            # 指定日志文件占据的最大空间</span><br><span class="line"></span><br><span class="line">journalctl --vacuum-time&#x3D;1years             # 指定日志文件保存多久</span><br></pre></td></tr></table></figure>

<h1 id="几个问题"><a href="#几个问题" class="headerlink" title="几个问题"></a>几个问题</h1><p>列举几个在systemd使用过程中可能遇到的问题。</p>
<h2 id="开机启动与启动服务"><a href="#开机启动与启动服务" class="headerlink" title="开机启动与启动服务"></a>开机启动与启动服务</h2><p><code>systemctl enable</code>设置服务开机启动，该服务需要等到下一次开机才会启动。<code>systemctl start</code>表明立即启动该服务。</p>
<h2 id="Unit区块中的启动顺序与依赖关系"><a href="#Unit区块中的启动顺序与依赖关系" class="headerlink" title="Unit区块中的启动顺序与依赖关系"></a>Unit区块中的启动顺序与依赖关系</h2><p>启动顺序由<code>Before</code>和<code>After</code>字段表示。Before表明应该在value表示的服务<em>之前</em>启动，After表示应该在value表示的服务<em>之后</em>启动。这两个字段只涉及到启动顺序而不设计依赖关系。</p>
<p>举例来说，SONiC中的bgp服务需要用redis数据库存储数据。如果在配置文件中只定义在redis之后启动，而没有定义依赖关系。设备启动后，由于某些原因，redis挂掉了，这之后bgp就会无法建立数据库连接。</p>
<p>设置依赖关系，需要使用<code>Wants</code>和<code>Requires</code>字段。Wants字段表明两者之间存在<em>弱依赖</em>关系，即如果value表明的服务启动失败或者停止运行，不影响主服务的继续执行。Requires字段则表明两者之间存在<em>强依赖</em>关系，即如果value表明的服务启动失败或者异常退出，那么主服务也必须退出。注意这两个字段只涉及依赖关系，与启动顺序无关，默认情况下不是同时启动的。</p>
<p>依赖于某一服务才能正常运行，可以同时定义Requires和After字段，如下所示。<br><img src="https://rancho333.gitee.io/pictures/requires_after.png"></p>
<h2 id="Services区块的小问题"><a href="#Services区块的小问题" class="headerlink" title="Services区块的小问题"></a>Services区块的小问题</h2><p>Services区块定义如何启动当前服务。</p>
<p>在所有的启动设置之前加上一个连词号(-),表示<em>抑制错误</em>，即错误发生的时候，不影响其它命令的执行。比如，<code>EnvironmentFile=-/etc/sysconfig/sshd</code>（注意等号后面的那个连词号），就表示即使<code>/etc/sysconfig/sshd</code>文件不存在，也不会抛出错误。</p>
<p><code>KillMode</code>字段定义了Systemd如何停止服务，value可以设置的值如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">control-group（默认值）：当前控制组里面的所有子进程，都会被杀掉</span><br><span class="line">process：只杀主进程</span><br><span class="line">mixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号</span><br><span class="line">none：没有进程会被杀掉，只是执行服务的 stop 命令。</span><br></pre></td></tr></table></figure>

<p><code>Restart</code>字段定义了服务退出后，systemd重启该服务的方式，value可以设置的值如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">no（默认值）：退出后不会重启</span><br><span class="line">on-success：只有正常退出时（退出状态码为0），才会重启</span><br><span class="line">on-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启</span><br><span class="line">on-abnormal：只有被信号终止和超时，才会重启</span><br><span class="line">on-abort：只有在收到没有捕捉到的信号终止时，才会重启</span><br><span class="line">on-watchdog：超时退出，才会重启</span><br><span class="line">always：不管是什么退出原因，总是重启</span><br></pre></td></tr></table></figure>
<p>SONiC中很多服务Restart都设置为always，如swss服务。<code>RestartSec</code>字段表示systemd重启服务之前，需要等待的秒数。</p>
<h2 id="Install区块的小问题"><a href="#Install区块的小问题" class="headerlink" title="Install区块的小问题"></a>Install区块的小问题</h2><p>Install区块定义如何安装这个配置文件，即怎样做到开机启动。</p>
<p><code>WanteBy</code>字段表示该服务所在的Target。systemd默认启动的Target可以通过<code>systemctl get-default</code>查看到。服务必须加到这个Target或这个Target的子Target中才能开机启动。</p>
<p>常用的Target有两个，一个是<code>multi-user.target</code>，表示多用户命令行状态；另一个是<code>graphical.target</code>，表示图形用户状态，它依赖于<code>multi-user.target</code>，SONiC使用的是后者。官方文档有一张非常清晰的<a href="https://www.freedesktop.org/software/systemd/man/bootup.html#System%20Manager%20Bootup">Target依赖关系图</a></p>
<h2 id="Target的配置文件"><a href="#Target的配置文件" class="headerlink" title="Target的配置文件"></a>Target的配置文件</h2><p>在<code>/lib/systemd/system</code>下可以找到Target的配置文件,以<code>graphical.target</code>为例：<br><img src="https://rancho333.gitee.io/pictures/graphical_target.png"><br>其中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">Requires字段：要求basic.target一起运行。</span><br><span class="line">Conflicts字段：冲突字段。如果rescue.service或rescue.target正在运行，multi-user.target就不能运行，反之亦然。</span><br><span class="line">After：表示multi-user.target在basic.target 、 rescue.service、 rescue.target之后启动，如果它们有启动的话。</span><br><span class="line">AllowIsolate：允许使用systemctl isolate命令切换到multi-user.target。</span><br></pre></td></tr></table></figure>

<h1 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h1><p>一般而言，配置文件存放在<code>/lib/systemd/system</code>和<code>/usr/lib/systemd/system</code>目录下，通过<code>systemctl enable</code>在<code>/etc/systemd/system</code>创建符号链接指向前者，Systemd会执行etc下的文件，前提是文件中的Install配对了Target。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="http://www.ruanyifeng.com/blog/2016/03/systemd-tutorial-commands.html">Systemd入门教程：命令篇</a><br><a href="https://linux.cn/article-5926-1.html">systemctl 命令完全指南</a></p>
]]></content>
      <tags>
        <tag>Linux</tag>
        <tag>Systemd</tag>
      </tags>
  </entry>
  <entry>
    <title>sonic-testbed</title>
    <url>/2020/12/18/sonic-testbed/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>最初，SONiC的所有测试用例都是用ansible playbook写的。2019年开始使用pytest， 2020年9月份之后，只有用pytest写的测试用例才被采纳。<br>但是ansible依然很重要，pytest-ansible插件连接pytest与ansible。pytest通过ansible进行多设备协同工作。</p>
<span id="more"></span>
<h2 id="物理拓扑"><a href="#物理拓扑" class="headerlink" title="物理拓扑"></a>物理拓扑</h2><p><img src="https://rancho333.gitee.io/pictures/physical-topology.png"></p>
<ol>
<li>DUT和leaf fanout的端口一一互联</li>
<li>leaf fanout与DUT相连的端口进行VLAN隔离</li>
<li>root fanout连接leaf fanout与testbed server</li>
<li>root fanout的端口工作在vlan trunk模式下</li>
<li>任一testbed server可以发送带有vlan tag的包到达DUT端口（root fanout的trunk口需要使能该vlan tag）</li>
</ol>
<h3 id="Fanout-switch"><a href="#Fanout-switch" class="headerlink" title="Fanout switch"></a>Fanout switch</h3><p><em>Fanout switch是使能了vlan trunking的物理交换机</em></p>
<ul>
<li>Et33是一个vlan trunking端口，并且和linux host的eth0连接</li>
<li>Et1-Et32是vlan access端口，并且与DUT连接</li>
<li>使能LACP/LLDP</li>
<li>关闭STP功能</li>
</ul>
<h3 id="Testbed-server"><a href="#Testbed-server" class="headerlink" title="Testbed server"></a>Testbed server</h3><p><img src="https://rancho333.gitee.io/pictures/testbed-server.png"></p>
<h4 id="网络连接"><a href="#网络连接" class="headerlink" title="网络连接"></a>网络连接</h4><ul>
<li>testbed server有两个网络接口<ul>
<li>trunk端口连接root fanout</li>
<li>management port管理服务器以及服务器上的VMs和PTF容器</li>
</ul>
</li>
</ul>
<h3 id="VMs"><a href="#VMs" class="headerlink" title="VMs"></a>VMs</h3><p>VMs使用的是Arista的vEOS。它们用来设置测试协议，例如BGP、LACP、LLDP等。它们通过<code>testbed-cli.sh start-vms</code>进行创建。每一个VM使用2G内存并且拥有10个网络接口。<br>    * 8个前面板端口。这些端口用来连接到openvswitch网桥，连接到vlan interfaces.vlan interface通过物理接口连接到fanout。<br>    * 一个后背板端口。所有VMs通过这个背板口互联。<br>    * 一个管理网口。用来管理VMs.</p>
<h3 id="PTF"><a href="#PTF" class="headerlink" title="PTF"></a>PTF</h3><p>PTF容器通过发送和接收数据包来验证DUT的数据面。<br>PTF with direct port<br><img src="https://rancho333.gitee.io/pictures/testbed-direct.png"></p>
<p>DUT的前面板口直连到一个PTF容器的端口。一般的PTF容器的eth0连接到DUT的Ethernet0，eth1连接到Ethernet4。这一般在PTF拓扑中用来连接DUT端口和PTF容器端口。</p>
<p><img src="https://rancho333.gitee.io/pictures/testbed-injected.png"></p>
<p>DUT的前面板口和一个VM的接口直连。但是我们在这个连接上有个tap。从vlan interface中收到的包被发送给VMs和PTF容器。从VM和PTF容器中发出的包被送到vlan interface。这允许我们可以同时从PTF host往DUT注入包和维持VM与DUT之间的BGP会话。</p>
<h3 id="SONiC-Tested-with-keysight-IxNetwork-as-Traffic-Generator"><a href="#SONiC-Tested-with-keysight-IxNetwork-as-Traffic-Generator" class="headerlink" title="SONiC Tested with keysight IxNetwork as Traffic Generator"></a>SONiC Tested with keysight IxNetwork as Traffic Generator</h3><p>TO BE DONE！！</p>
<h2 id="Testbed设置"><a href="#Testbed设置" class="headerlink" title="Testbed设置"></a>Testbed设置</h2><p>下面讲述testbed的设置步骤以及拓扑的部署。</p>
<h3 id="准备testbed服务器"><a href="#准备testbed服务器" class="headerlink" title="准备testbed服务器"></a>准备testbed服务器</h3><ul>
<li>系统要求：ubuntu 18.04 amd64</li>
<li>设置管理口，使用如下示例：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@server-1:~# cat &#x2F;etc&#x2F;network&#x2F;interfaces</span><br><span class="line"># The management network interface</span><br><span class="line">auto ma0</span><br><span class="line">iface ma0 inet manual</span><br><span class="line"></span><br><span class="line"># Server, VM and PTF management interface</span><br><span class="line">auto br1</span><br><span class="line">iface br1 inet static</span><br><span class="line">    bridge_ports ma0</span><br><span class="line">    bridge_stp off</span><br><span class="line">    bridge_maxwait 0</span><br><span class="line">    bridge_fd 0</span><br><span class="line">    address 10.250.0.245</span><br><span class="line">    netmask 255.255.255.0</span><br><span class="line">    network 10.250.0.0</span><br><span class="line">    broadcast 10.250.0.255</span><br><span class="line">    gateway 10.250.0.1</span><br><span class="line">    dns-nameservers 10.250.0.1 10.250.0.2</span><br><span class="line">    # dns-* options are implemented by the resolvconf package, if installed</span><br></pre></td></tr></table></figure></li>
<li>安装python2.7（Ansible需要）</li>
<li>添加Docker的官方GPG key：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">$ curl -fsSL https:&#x2F;&#x2F;download.docker.com&#x2F;linux&#x2F;ubuntu&#x2F;gpg | sudo apt-key add -</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="为docker-pth设置docker仓库"><a href="#为docker-pth设置docker仓库" class="headerlink" title="为docker-pth设置docker仓库"></a>为<code>docker-pth</code>设置docker仓库</h3><ol>
<li>build <code>docker-pth</code>镜像<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone --recursive https:&#x2F;&#x2F;github.com&#x2F;Azure&#x2F;sonic-buildimage.git</span><br><span class="line">cd sonic-buildimage</span><br><span class="line">make configure PLATFORM&#x3D;generic</span><br><span class="line">make target&#x2F;docker-ptf.gz</span><br></pre></td></tr></table></figure></li>
<li>设置自己的docker仓库并将<code>docker-ptf</code>上传</li>
</ol>
<h3 id="创建并且运行docker-sonic-mgmt"><a href="#创建并且运行docker-sonic-mgmt" class="headerlink" title="创建并且运行docker-sonic-mgmt"></a>创建并且运行<code>docker-sonic-mgmt</code></h3><p>管理testbed和运行测试用例需要很多依赖。将所有的依赖部署到<code>docker-sonic-mgmt</code>中，这样就可以很方便的使用<code>ansible-playbook</code>，<code>pytest</code>，<code>spytest</code>。</p>
<ol>
<li><p>构建<code>docker-sonic-mgmt</code>镜像</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone --recursive https:&#x2F;&#x2F;github.com&#x2F;Azure&#x2F;sonic-buildimage.git</span><br><span class="line">cd sonic-buildimage</span><br><span class="line">make configure PLATFORM&#x3D;generic</span><br><span class="line">make target&#x2F;docker-sonic-mgmt.gz</span><br></pre></td></tr></table></figure>
<p>或者从<a href="https://sonic-jenkins.westus2.cloudapp.azure.com/job/bldenv/job/docker-sonic-mgmt/lastSuccessfulBuild/artifact/sonic-buildimage/target/docker-sonic-mgmt.gz">这里</a>下载事先编译好的镜像。</p>
</li>
<li><p>克隆<code>sonic-mgmt</code>库到testbed server的工作目录</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">git clone https:&#x2F;&#x2F;github.com&#x2F;Azure&#x2F;sonic-mgmt</span><br></pre></td></tr></table></figure></li>
<li><p>创建<code>docker-sonic-mgmt</code>容器，注意需要将上面克隆的<code>sonic-mgmt</code>挂载到容器中去:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker load &lt; docker-sonic-mgmt.gz</span><br><span class="line">docker run -v $PWD:&#x2F;data -it docker-sonic-mgmt bash</span><br><span class="line">cd ~&#x2F;sonic-mgmt</span><br></pre></td></tr></table></figure></li>
</ol>
<p><em>注意：之后的所有操作都是在<code>docker-sonic-mgmt</code>容器中操作</em></p>
<h3 id="准备Testbed配置"><a href="#准备Testbed配置" class="headerlink" title="准备Testbed配置"></a>准备Testbed配置</h3><p>进入到容器之后，我们需要修改testbed的配置文件使之与实验拓扑映射起来。</p>
<ul>
<li><p>Testbed Server</p>
<ul>
<li>在<code>ansible/veos</code>中更新server的管理IP</li>
<li>在<code>ansible/group_vars/vm_host/creds.yml</code>中更新server的凭证</li>
<li>在<code>ansible/host_vars/STA-ACS-SERV-01.yml</code>中更新server的网络配置（for VMs和PTF management）<ul>
<li><code>external_port</code>：server的trunk口名称（连接到fanout switch）</li>
<li><code>mgmt_gw</code>：VM管理端口的网关IP</li>
<li><code>mgmt_prefixlen</code>: 管理网口子网掩码</li>
</ul>
</li>
<li>检查ansible可以与这个host连接<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible -m ping -i veos vm_host_1 </span><br></pre></td></tr></table></figure></li>
</ul>
</li>
<li><p>VMs</p>
<ul>
<li>从Arista下载<a href="https://www.arista.com/en/support/software-download">vEOS</a></li>
<li>将镜像文件拷贝到<code>ansible/veos</code><ul>
<li><code>Aboot-veos-serial-8.0.0.iso</code></li>
<li><code>vEOS-lab-4.20.15M.vmdk</code></li>
</ul>
</li>
<li>将VM的IP地址更新到<code>ansible/veos</code>. 这个IP地址应该和定义的管理IP在同一个子网中</li>
<li>在<code>ansible/group_vars/eos/creds.yml</code>中更新VM的凭证</li>
</ul>
</li>
<li><p>PTF容器</p>
<ul>
<li>在<code>vars/docker_registry.yml</code>中更新docker仓库信息</li>
</ul>
</li>
</ul>
<h3 id="设置VMs"><a href="#设置VMs" class="headerlink" title="设置VMs"></a>设置VMs</h3><ol>
<li>开启VMs：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;testbed-cli.sh start-vms server_1 password.txt</span><br></pre></td></tr></table></figure>
<code>password.txt</code>是ansible的密码文件，如果不使用直接创建一个空文件即可。</li>
</ol>
<ol start="2">
<li>检查所有的VMs是否启动并且在运行中<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ansible -m ping -i veos server_1</span><br></pre></td></tr></table></figure></li>
</ol>
<h3 id="部署Fanout交换机的Vlan"><a href="#部署Fanout交换机的Vlan" class="headerlink" title="部署Fanout交换机的Vlan"></a>部署Fanout交换机的Vlan</h3><p>在部署Fanout和运行测试用例之前需要明确环境中的所有物理连接。<br>在<code>roles/fanout</code>下的playbook只是用来部署Arista的Vlan配置。如果使用其它类型的交换机，请手动配置Vlan，或者部署一个2层交换机。</p>
<h3 id="部署拓扑"><a href="#部署拓扑" class="headerlink" title="部署拓扑"></a>部署拓扑</h3><ul>
<li>使用自己的数据更新<code>testbed.csv</code>。至少需要更新PTF管理接口的配置。</li>
<li>部署拓扑请运行：<code>/testbed-cli.sh add-topo vms-t1 ~/.password</code></li>
<li>移除拓扑请运行: <code>./testbed-cli.sh remove-topo vms-t1 ~/.password</code></li>
</ul>
<p>注意：<code>testbed-cli.sh</code>的最后一步试图在root fanout中重新部署vlan范围（与拓扑中规定的相匹配）。Arista的正常工作，其它型号的需要手动修改？</p>
<h2 id="Docker容器设置"><a href="#Docker容器设置" class="headerlink" title="Docker容器设置"></a>Docker容器设置</h2><p>使用<code>setup-container.sh</code>脚本去自动创建和配置sonic-mgmt的docker容器。使用普通用户user创建即可。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;setuo-container.sh -n container_name -i image_id -d directory</span><br><span class="line">image_id是在sonic-buildimage中创建的docker-sonic-mgmt.tar</span><br><span class="line">directory是主机与docker进行mount的文件夹</span><br></pre></td></tr></table></figure>
<p>创建完dokcer容器之后，可以进入容器中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -u &lt;user&gt; -it &lt;container name&gt; bash</span><br></pre></td></tr></table></figure>

<h2 id="KVM-testbed设置"><a href="#KVM-testbed设置" class="headerlink" title="KVM testbed设置"></a>KVM testbed设置</h2><p>可以给testbed创建虚拟的交换机，在上面部署T0拓扑，运行一个快速测试去验证是否符合预期。<br>即物理设备都虚拟化在服务器上，对内存资源要求比较高，我们现在使用物理设备连接，暂不研究这块内容。<br>这里面有vEOS与cEOS的介绍，分别是基于KVM和docker的技术。</p>
<h2 id="cEOS"><a href="#cEOS" class="headerlink" title="cEOS"></a>cEOS</h2><p>如何使用cEOS作为DUT的邻居设备。<br>cEOS是容器化的EOS。所有的软件在容器中运行。与vEOS相比，cEOS内存暂用更少。</p>
<h3 id="网络设置"><a href="#网络设置" class="headerlink" title="网络设置"></a>网络设置</h3><p>首先创建一个基容器<code>net_$&#123;testbed_name&#125;_$&#123;vm_name&#125;</code>，在基容器中创建6个以太口。然后在基容器基础上启动cEOS<code>ceos_$&#123;testbed_name&#125;_$&#123;vm_name&#125;</code>容器。这6个网口分别用来：</p>
<ul>
<li>一个管理网口</li>
<li>4个前面板端口用来连接DUT</li>
<li>一个背板口连接PTF容器<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">+------------+                      +----+</span><br><span class="line">|  cEOS  Ma0 +--------- VM0100-m ---+ br |</span><br><span class="line">|            |                      +----+</span><br><span class="line">|            |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|        Et1 +----------VM0100-t0---+  br-VM0100-0 |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|            |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|        Et2 +----------VM0100-t1---+  br-VM0100-1 |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|            |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|        Et3 +----------VM0100-t2---+  br-VM0100-2 |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|            |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|        Et4 +----------VM0100-t3---+  br-VM0100-3 |</span><br><span class="line">|            |                      +--------------+</span><br><span class="line">|            |</span><br><span class="line">|            |                       +--------------+</span><br><span class="line">|        Et5 +----------VM0100-back--+  br-b-vms6-1 |</span><br><span class="line">|            |                       +--------------+</span><br><span class="line">+------------+</span><br></pre></td></tr></table></figure></li>
</ul>
<h3 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h3><p>cEOS容器中的<code>/mnt/flash</code>挂载到主机的<code>/data/ceos/ceos_$&#123;testbed_name&#125;_$&#123;vm_name&#125;</code>。</p>
<h3 id="登录"><a href="#登录" class="headerlink" title="登录"></a>登录</h3><p>两种方式登录到cEOS容器。</p>
<ol>
<li><p>docker exec</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">docker exec -it ceos_vms6-1_VM0100 Cli</span><br></pre></td></tr></table></figure></li>
<li><p>ssh</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">lgh@jenkins-worker-15:~$ ssh admin@10.250.0.51</span><br><span class="line">Password: </span><br><span class="line">ARISTA01T1&gt;show int status</span><br><span class="line">Port       Name      Status       Vlan     Duplex Speed  Type            Flags Encapsulation</span><br><span class="line">Et1                  connected    in Po1   full   unconf EbraTestPhyPort                    </span><br><span class="line">Et2                  connected    1        full   unconf EbraTestPhyPort                    </span><br><span class="line">Et3                  connected    1        full   unconf EbraTestPhyPort                    </span><br><span class="line">Et4                  connected    1        full   unconf EbraTestPhyPort                    </span><br><span class="line">Et5        backplane connected    routed   full   unconf EbraTestPhyPort                    </span><br><span class="line">Ma0                  connected    routed   full   10G    10&#x2F;100&#x2F;1000                        </span><br><span class="line">Po1                  connected    routed   full   unconf N&#x2F;A                                </span><br><span class="line"></span><br><span class="line">ARISTA01T1&gt;</span><br></pre></td></tr></table></figure></li>
</ol>
<h2 id="testbed路由设计"><a href="#testbed路由设计" class="headerlink" title="testbed路由设计"></a>testbed路由设计</h2><p>下面说明testbed中的BGP路由设计。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">              +------+</span><br><span class="line">              +  VM  +---------+</span><br><span class="line">              +------+         |</span><br><span class="line">                               |</span><br><span class="line">              +------+         |</span><br><span class="line">              +  VM  +---------+</span><br><span class="line">              +------+         |</span><br><span class="line">+-------+                  +---+---+     </span><br><span class="line">|  PTF  +------------------+  DUT  |</span><br><span class="line">+-------+                  +---+---+</span><br><span class="line">              +------+         |</span><br><span class="line">              +  VM  +---------+</span><br><span class="line">              +------+         |</span><br><span class="line">                               |</span><br><span class="line">              +------+         |</span><br><span class="line">              +  VM  +---------+</span><br><span class="line">              +------+</span><br></pre></td></tr></table></figure>
<p>在这个拓扑中，VMs（vEOS）充当DUT的BGP邻居。VMs生成并且宣告BGP路由给DUT.这种方式有几个问题：</p>
<ul>
<li>在vEOS很难生成任意路由，例如，写一个复杂的路由表，过滤生成需要的路由</li>
<li>消耗很多内存在vENOS中</li>
<li>特定的NOS规则。如果我们打算从VN切换到SONiC，我们需要重写所有的路由表。<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">              +------+</span><br><span class="line">    +---------+  VM  +---------+</span><br><span class="line">    |         +------+         |</span><br><span class="line">    |                          |</span><br><span class="line">    |         +------+         |</span><br><span class="line">    +---------+  VM  +---------+</span><br><span class="line">    |         +------+         |</span><br><span class="line">+---+---+                  +---+---+     </span><br><span class="line">|  PTF  |                  |  DUT  |</span><br><span class="line">+---+---+                  +---+---+</span><br><span class="line">    |         +------+         |</span><br><span class="line">    +---------+  VM  +---------+</span><br><span class="line">    |         +------+         |</span><br><span class="line">    |                          |</span><br><span class="line">    |         +------+         |</span><br><span class="line">    +---------+  VM  +---------+</span><br><span class="line">              +------+</span><br></pre></td></tr></table></figure>
新的方法是将VM作为一个透传设备，我们在PTF容器上运行exabgp,exabgp通告如有信息给VM，VM再将路由信息通告给DUT。这种方式有几个好处：</li>
<li>VM模板变得简单很多。只有基础的端口，lag，BGP配置</li>
<li>VM的内存开销变小</li>
<li>exbgp可以生成复杂路由条目</li>
<li>容易支持不同的NOS作为邻居设备，例如SONiC vm</li>
</ul>
<h2 id="拓扑"><a href="#拓扑" class="headerlink" title="拓扑"></a>拓扑</h2><ol>
<li>配置testbed的拓扑定义在一个文件中：<code>testbed.csv</code></li>
<li>一个脚本去操作所有的testbed:<code>testbed-cli.sh</code></li>
<li>灵活的拓扑允许将VM_SET和PTF容器作为一个实体看待</li>
<li>所有的VM管理网口ip定义在：<code>veos</code></li>
<li>PTF容器在所有拓扑中被使用</li>
<li>自动构建fanout switch的配置（需要被重构）</li>
<li>请看示例模块如果你想设置任意的testbed的拓扑</li>
</ol>
<h3 id="testbed拓扑配置"><a href="#testbed拓扑配置" class="headerlink" title="testbed拓扑配置"></a>testbed拓扑配置</h3><ul>
<li><code>testbed.csv</code>文件由以下组成：<ul>
<li>物理拓扑；VMs和PTF容器的端口如何与DUT连接</li>
<li>VMs的配置模板</li>
</ul>
</li>
<li>拓扑在<code>vars/topo_*.yml</code>文件中</li>
<li>当前的拓扑有：<ul>
<li>t1:32个VMs + 用来端口注入的PTF容器</li>
<li>t1-lag：24个VMs + 用来端口注入的PTF容器。其中8个VMs在每一LAG中有两个端口</li>
<li>ptf32: 拥有32个个端口的PTF容器与DUT端口直连</li>
<li>ptf64: 和ptf32相同，但是拥有64个端口</li>
<li>t0：4个VMs + PTF容器（4个用来端口注入，28个用来直连DUT）</li>
</ul>
</li>
</ul>
<h3 id="当前的拓扑"><a href="#当前的拓扑" class="headerlink" title="当前的拓扑"></a>当前的拓扑</h3><h4 id="t1"><a href="#t1" class="headerlink" title="t1"></a>t1</h4><p><img src="https://rancho333.gitee.io/pictures/testbed-t1.png"></p>
<ul>
<li>需要32个VMs</li>
<li>所有的DUT端口直连VMs</li>
<li>PTF容器只有注入端口</li>
</ul>
<h4 id="t1-lag"><a href="#t1-lag" class="headerlink" title="t1-lag"></a>t1-lag</h4><p><img src="https://rancho333.gitee.io/pictures/testbed-t1-lag.png"></p>
<ul>
<li>需要24个VMs</li>
<li>所有的DUT端口直连VMs</li>
<li>PTF容器只有注入端口</li>
</ul>
<h4 id="ptf32"><a href="#ptf32" class="headerlink" title="ptf32"></a>ptf32</h4><p><img src="https://rancho333.gitee.io/pictures/testbed-ptf32.png"></p>
<ul>
<li>不需要VMs</li>
<li>所有的DUT端口直连PTF容器</li>
<li>PTF容器没有注入端口</li>
</ul>
<h4 id="ptf64"><a href="#ptf64" class="headerlink" title="ptf64"></a>ptf64</h4><p><img src="https://rancho333.gitee.io/pictures/testbed-ptf64.png"><br>和ptf32一样</p>
<h4 id="t0"><a href="#t0" class="headerlink" title="t0"></a>t0</h4><p><img src="https://rancho333.gitee.io/pictures/testbed-t0.png"></p>
<ul>
<li>需要4个VMs</li>
<li>4个DUT端口连接到VMs</li>
<li>PTF容器有4个注入端口与28个直连端口</li>
</ul>
<h2 id="testbed配置"><a href="#testbed配置" class="headerlink" title="testbed配置"></a>testbed配置</h2><h3 id="testbed清单"><a href="#testbed清单" class="headerlink" title="testbed清单"></a>testbed清单</h3><ul>
<li><code>ansible/lab</code>：包含实验的所有DUTs， fanout switch, testbed server拓扑</li>
<li><code>ansible/veos</code>：所有的server和VMs</li>
</ul>
<h3 id=""><a href="#" class="headerlink" title=""></a></h3><h2 id="Sonic-Mgmt-testbed设置"><a href="#Sonic-Mgmt-testbed设置" class="headerlink" title="Sonic-Mgmt testbed设置"></a>Sonic-Mgmt testbed设置</h2><p>从github上将sonic testbed设置到自己的环境中将会是一个冗长的过程。在将测试用例跑起来之前有十多个文件需要更新。<br>然而，这个过程可以通过testbed.yaml和TestbedProcessing.py自动完成。testbed.yaml是一个配置文件（编译所有需要运行testcase的数据到一个文件中）。TestbedProcess.py的工作原理是：从配置文件拉取信息，然后将信息推送到它们属于的文件中去。这篇指南将会勾勒并简易化testbed的设置。</p>
<h3 id="目标"><a href="#目标" class="headerlink" title="目标"></a>目标</h3><p>通过使用testbed.yaml和TestbedProcessing.py来完成testbed的设置。这篇指南结束后，应该完成sonic-mgmt testbed的设置并且将testcases跑起来。</p>
<h3 id="预迁移设置"><a href="#预迁移设置" class="headerlink" title="预迁移设置"></a>预迁移设置</h3><p> sonic-mgmt启动并运行测试用例需要下述的设备：</p>
<ul>
<li>Linux服务器</li>
<li>root fanout</li>
<li>leaf fanout</li>
<li>DUT (device under test)<br>testbed的信息和拓扑可以从overview中获取到。</li>
</ul>
<h3 id="修改-Testbed-yaml配置文件"><a href="#修改-Testbed-yaml配置文件" class="headerlink" title="修改 Testbed.yaml配置文件"></a>修改 Testbed.yaml配置文件</h3><p>在testbed.yaml中有7个主要的部分需要编辑：</p>
<ol>
<li>device_groups</li>
<li>devices</li>
<li>host_vars</li>
<li>veos_groups</li>
<li>veos</li>
<li>testbed</li>
<li>topology<br>每一部分文件的作用都需要按顺序的写好。具体信息在Sonic-Mgmt testbed Configuration中有描述</li>
</ol>
<p>对于testbed.yaml文件（在ansible下面有个testbed-new.yaml文件）：</p>
<h4 id="（可选）testbed-config部分："><a href="#（可选）testbed-config部分：" class="headerlink" title="（可选）testbed_config部分："></a>（可选）testbed_config部分：</h4><ul>
<li>name - 给testbed配置文件选择一个名字</li>
<li>alias - 给testbed配置文件选择一个别名</li>
</ul>
<h5 id="device-groups部分"><a href="#device-groups部分" class="headerlink" title="device_groups部分"></a>device_groups部分</h5><p>用法：lab</p>
<p>device_group部分生成lab文件，是用来设置testbed的的必须清单文件。配置文件的格式是yaml格式，脚本会将之转换成INI格式。device_group部分包含实验室中所有DUTs, fanout switchs，testbed server拓扑。组子节点从下面的device部分介绍。在大多数情况下可以不用管这一部分。</p>
<h4 id="devices部分"><a href="#devices部分" class="headerlink" title="devices部分"></a>devices部分</h4><p>用法：files/sonic_lab_devices, group_vars/fanout/secrets, group_vars/lab/secrets, lab</p>
<p>device部分是包含所有设备和主机的字典。这部分不包含PTF容器的信息。关于PTF容器的信息，查看testbed.csv文件。<br>对每一个你添加的设备，添加下面的信息：</p>
<table>
<thead>
<tr>
<th>Hostname</th>
<th>ansible_host</th>
<th>ansible_ssh_user</th>
<th>ansible_ssh_pass</th>
<th>HwSKU</th>
<th>device_type</th>
</tr>
</thead>
<tbody><tr>
<td>str-msn2700-01</td>
<td>[IP Address]</td>
<td>[username]</td>
<td>[password]</td>
<td>DevSonic</td>
<td>DevSonic</td>
</tr>
<tr>
<td>str-7260-10</td>
<td>[IP Address]</td>
<td>[username]</td>
<td>[password]</td>
<td>Arista-7260QX-64</td>
<td>FanoutRoot</td>
</tr>
<tr>
<td>str-7260-10</td>
<td>[IP Address]</td>
<td>[username]</td>
<td>[password]</td>
<td>Arista-7260QX-64</td>
<td>FanoutLeaf</td>
</tr>
<tr>
<td>str-acs-serv-01</td>
<td>[IP Address]</td>
<td>[username]</td>
<td>[password]</td>
<td>TestServ</td>
<td>Server</td>
</tr>
</tbody></table>
<ul>
<li>hostname - 设备名称</li>
<li>ansible_host - 设备的管理IP</li>
<li>ansible_ssh_user - 设备登录名称</li>
<li>ansible_ssh_pass - 设备登录密码</li>
<li>hesku - 这是用来查阅验证的值（在/group_vars/all/labinfo.json）。没有这部分，就爱那个会失败。确保这部分在labinfo.json中有准确的数据。</li>
<li>device_type - 设备类型。如果只有4种设备，可以将提供标签留白不填写。</li>
</ul>
<p>lab server部分需要不同的字段输入：ansible_become_pass, sonicadmin_user(用户名), sonicadmin_password, sonic_inital_password. 这些字段是可选的，因为它们是直接从group_var/lab/secrets.yml中获取的变量。所以为了便利，这部分的配置文件作为一个拷贝。</p>
<h4 id="host-vars部分"><a href="#host-vars部分" class="headerlink" title="host_vars部分"></a>host_vars部分</h4><p>用法：所有的host_val数据</p>
<p>host的参数在此处设置。在这篇指南中，我们在此处定义server（str-acs-serv-01）：<br>对于每一个你添加的host，定义或确认如下数据：</p>
<ul>
<li>mgmt_bridge</li>
<li>mgmt_prefixlen (这个应该和mgmt_subnet_mask_length匹配)</li>
<li>mgmt_gw</li>
<li>external_about</li>
</ul>
<h4 id="veos-groups部分"><a href="#veos-groups部分" class="headerlink" title="veos_groups部分"></a>veos_groups部分</h4><p>用法：veos</p>
<h4 id="veos部分"><a href="#veos部分" class="headerlink" title="veos部分"></a>veos部分</h4><p>用法：group_vars/eos/cred, main.yml, group_vars/vm_host/creds</p>
<h4 id="testbed部分"><a href="#testbed部分" class="headerlink" title="testbed部分"></a>testbed部分</h4><p>用法： testbed.csv</p>
<h4 id="拓扑部分"><a href="#拓扑部分" class="headerlink" title="拓扑部分"></a>拓扑部分</h4><p>用法： files/sonic_lab_links.csv</p>
<h4 id="docker-registry部分"><a href="#docker-registry部分" class="headerlink" title="docker_registry部分"></a>docker_registry部分</h4><p>用法： /vars/docker_registry.yml</p>
<h3 id="testbed运行脚本"><a href="#testbed运行脚本" class="headerlink" title="testbed运行脚本"></a>testbed运行脚本</h3><p>当testbed.yaml文件配置好后，将TestbedProcess.py和testbed.yaml文件放在sonic-mgmt/ansible下面。</p>
<p>运行TestbedProcessing.py脚本：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">python TestbedProcessing.py -i testbed.yaml</span><br><span class="line">options:</span><br><span class="line">-i &#x3D; 解析testbed.yaml文件</span><br><span class="line">-basedir &#x3D; 项目的根目录</span><br><span class="line">-backup &#x3D; 文件的备份文件夹</span><br></pre></td></tr></table></figure>

<h4 id="VMS命令"><a href="#VMS命令" class="headerlink" title="VMS命令"></a>VMS命令</h4><p>开启VMS（使用vms_1）:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;testbed-cli.sh start-vms vms_1 password.txt</span><br></pre></td></tr></table></figure>
<p>停止VMS（使用vms_1）:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;testbed-cli.sh stop-vms vms_1 password.txt</span><br></pre></td></tr></table></figure>

<h3 id="部署（PTF32）拓扑容器"><a href="#部署（PTF32）拓扑容器" class="headerlink" title="部署（PTF32）拓扑容器"></a>部署（PTF32）拓扑容器</h3><p>在这篇指南中，将会使用testbed-cli.sh添加ptf32-1作为示例</p>
<p>移除拓扑 ptf32-1:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;testbed-cli.sh remove-topo ptf32-1 password.txt</span><br></pre></td></tr></table></figure>

<p>添加拓扑 ptf32-1:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;testbed-cli.sh add-topo ptf32-1 password.txt</span><br></pre></td></tr></table></figure>
<p>可以使用”docker ps”或者”dokcer container ls”命令去检查是否添加或移除。</p>
<h3 id="运行第一个测试用例（Neighbour）"><a href="#运行第一个测试用例（Neighbour）" class="headerlink" title="运行第一个测试用例（Neighbour）"></a>运行第一个测试用例（Neighbour）</h3><p>当VMs和ptf32-1拓扑成功添加后，第一个测试用例“neighbour”就可以运行起来了。testbed的名字和测试用例的名字需要通过变量声明出来。请检查一下，之后，playbook就可以运行了。<br>运行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">export TESTBED_NAME&#x3D;ptf32-1</span><br><span class="line">export TESTCASE_NAME&#x3D;neighbour</span><br><span class="line">echo $TESTBED_NAME</span><br><span class="line">echo $TESTCASE_NAME</span><br><span class="line">ansible-playbook -i lab -l sonic-ag9032 test_sonic.ynl -e testbed_name&#x3D;$TESTBED_NAME -e testcase_name&#x3D;$TESTCASE_NAME</span><br></pre></td></tr></table></figure>

<h2 id="排错"><a href="#排错" class="headerlink" title="排错"></a>排错</h2><p>问题：Testbed命令行提示没有password文件<br>解决方式：创建一个空的password文件去绕过这个问题</p>
<p>问题：即使在我运行完stop-vms命令后IPs不可达<br>解决方式：如果运行了stop-vms命令后这个问题依然存在，运行如下命令：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">virsh</span><br><span class="line">list</span><br><span class="line">destory VM_Name (删除占用这个IP的VM)</span><br><span class="line">exit(退出virsh)，在永久删除这个IPs前请确保没有其它VM使用这个IPs</span><br></pre></td></tr></table></figure>

<p>问题：任务设置失败。SSH Error：data could not be sent to the remote host<br>解决方式：导致这个现象的问题可能有很多。<br>    1. 确保这台主机可以通过SSH到达<br>    2. group_vars/all/lab_info.json文件中包含了正确的凭证吗？<br>    3. 设备在files/sonic_lab_devices.cav中有正确的hwsku吗？<br>    4. 确保lab文件中在IPs后面没有”/“，INI文件无法识别<br>    5. 重新检查testbed.yaml配置文件，是否获取了IPs和正确的凭证</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>vxlan学习</title>
    <url>/2021/02/03/vxlan%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>vxlan是overlay层的应用，vlan是underlay层的应用。这篇文档是vxlan的学习文档，在学习vxlan之前，会简单介绍下vlan，之后进入vxlan学习。学习完成后，应该搞明白以下的几个问题：</p>
<span id="more"></span>
<ul>
<li>什么是vxlan</li>
<li>vxlan解决了什么问题，应用场景是什么</li>
<li>vxlan报文的封装格式是什么样的</li>
<li>什么是VTEP和VNI</li>
<li>哪些VTEP之间需要建立vxlan隧道<ul>
<li>什么是<code>同一大二层域</code></li>
</ul>
</li>
<li>vxlan隧道是如何建立的<ul>
<li>如何确定报文属于那个BD，哪些报文进入vxlan隧道</li>
<li>如何确定报文走那条隧道</li>
</ul>
</li>
<li>什么是vxlan二层网关和三层网关</li>
<li>什么是vxlan集中式网关与分布式网关<ul>
<li>集中式网关中同子网互通流程是怎样的</li>
<li>集中式网关中不同子网互通流程是怎样的</li>
</ul>
</li>
<li>什么是BGP EVPN<ul>
<li>分布式网关中报文的转发流程是怎样的</li>
</ul>
</li>
</ul>
<h1 id="vlan介绍"><a href="#vlan介绍" class="headerlink" title="vlan介绍"></a>vlan介绍</h1><p>VLAN(virtual local area network)即虚拟局域网，是将一个物理的LAN在逻辑上划分多个广播域的通信技术。根据IEEE 802.1Q协议规定，在以太网数据帧的目的MAC地址和源MAC地址字段之后、协议字段之前加入4个字节的VLAN tag，用以标识VLAN信息，VLAN数据帧格式如下图所示。</p>
<p><img src="https://rancho333.gitee.io/pictures/vlan_frame.png"></p>
<p>对于交换机而言，其内部处理的数据帧都带有VLAN tag，现网中交换机连接的设备只会接收Untagged帧。交换机需要有识别Untagged帧并在收发时给帧添加、剥离VLAN标签的能力，交换机间的接口需要有同时识别和发送多个vlan数据帧的能力。</p>
<p>根据接口对象和收发数据帧处理的不同，下面介绍4中链路类型，用以适应不同的连接和组网：</p>
<ul>
<li>Access接口：一般用于交换机与用户终端相连。Access接口大部分情况只能收发Untagged帧，且只能为Untagged帧添加唯一的VLAN tag。</li>
<li>Trunk接口：一般用于交换机之间相连。允许多个VLAN的帧带tag通过，但只允许一个VLAN的帧(默认vlan)从该类型接口上发出时不带tag。</li>
<li>Hybridd接口：Access和Trunk的混合。</li>
<li>使用QinQ(802.1Q-in-802.1Q)协议，一般用于私网与公网之间的连接，也被称为Dot1q-tunnel接口，它可以给vlan加上双层Tag，最多支持4094*4094个VLAN。</li>
</ul>
<p>下面介绍一下vlan划分的方式及使用场景：</p>
<table>
<thead>
<tr>
<th align="left">划分方式</th>
<th align="left">简介</th>
<th align="left">适用场景</th>
</tr>
</thead>
<tbody><tr>
<td align="left">基于接口</td>
<td align="left">根据交换机的接口来划分vlan</td>
<td align="left">使用与任何大小但是位置比较固定的网络</td>
</tr>
<tr>
<td align="left">基于MAC地址</td>
<td align="left">根据数据帧的源MAC地址来划分VLAN</td>
<td align="left">适用于位置经常移动但网卡不经常更换的小型网络</td>
</tr>
<tr>
<td align="left">基于子网</td>
<td align="left">根据数据帧中的源IP地址和子网掩码来划分VLAN</td>
<td align="left">适用于安全需求不高、对移动性和简易管理需求比较高的场景</td>
</tr>
<tr>
<td align="left">基于网络层协议</td>
<td align="left">根据数据帧所属的协议(族)类型及封装格式</td>
<td align="left">适用于需要同时运行多协议的网络</td>
</tr>
<tr>
<td align="left">基于匹配策略</td>
<td align="left">根据配置的策略划分VLAN,能实现上述的多种组合</td>
<td align="left">使用与需求比较复杂的环境</td>
</tr>
</tbody></table>
<p>两个概念，vlan的透传和终结，vlan的透传就是某个vlan不仅在一台交换机上有效，它还要通过某种方式延伸到别的以太网交换机上，在别的设备上照样有效，vlan的透传可以使用802.1Q协议，trunk链路上使用。vlan的终结意思相对，某个vlan的有效域不能再延伸到别的设备，或者不能通过某条链路延伸到别的设备，可以使用pvlan技术实现，主要在vlan数据出端口到终端设备，或者上三层转发时剥离。这两者的本质就是保留vlan tag和去除vlan tag。</p>
<h1 id="vxlan学习"><a href="#vxlan学习" class="headerlink" title="vxlan学习"></a>vxlan学习</h1><h2 id="什么是vxlan"><a href="#什么是vxlan" class="headerlink" title="什么是vxlan"></a>什么是vxlan</h2><p>vxlan(virtual extensible local area network)虚拟扩展局域网，是有IETF定义的NVO3(network virtualization over layer 3)标准技术之一。vxlan的本质是一种隧道技术，将L2的以太帧封装到UDP报文中在L3网络中传输。虽然从名字上看，vxlan是vlan的一种扩展协议，但是vxlan构建虚拟隧道的本领已经和vlan迥然不同了。vxlan报文格式如下图所示。</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_tag.png"></p>
<p>如上图所示，VTEP对VM发送的原始以太帧（original L2 frame）进行了如下的封装：</p>
<table>
<thead>
<tr>
<th align="left">封装</th>
<th align="left">说明</th>
</tr>
</thead>
<tbody><tr>
<td align="left">vxaln header</td>
<td align="left">增加vxlan头(8字节),其中24bits的VNI用来标识vxlan</td>
</tr>
<tr>
<td align="left">udp header</td>
<td align="left">vxlan头和原始以太帧一起作为UDP的数据。UDP中，目的端口号(vxlan port)固定为4789</td>
</tr>
<tr>
<td align="left">outer ip header</td>
<td align="left">src ip为源VM所属VTEP的IP地址，目的IP地址为目的VM所属VTEP的IP地址</td>
</tr>
<tr>
<td align="left">outer mac header</td>
<td align="left">src mac为源VM所属VTEP的mac地址，目的mac地址为到达VTEP的路径的下一跳设备的mac地址</td>
</tr>
</tbody></table>
<h2 id="vxlan的应用场景"><a href="#vxlan的应用场景" class="headerlink" title="vxlan的应用场景"></a>vxlan的应用场景</h2><p>vxlan的主要应用场景是数据中心。vxlan可以满足数据中心的三个关键需求：</p>
<ol>
<li>数据中心服务器侧虚拟化后出现了虚拟机动态迁移，要求提供一个无障碍接入的网络</li>
<li>数据中心规模庞大，租户数量激增，要求网络提供隔离海量租户的能力</li>
<li>针对虚拟机规模受网络规格限制的解决方案。对接入交换机，MAC地址规格需求极大降低，但是对核心网关要求极高。两个vxlan可以具有相同的MAC地址，但在一个vxlan内不能有重复的mac地址</li>
</ol>
<p>对于虚拟机动态迁移，不仅虚拟机的IP地址不变，而且虚拟机的运行状态也必须保持原状（如TCP会话状态），所以虚拟机动态迁移只能在一个二层域中进行。vxlan可以将整个数据中心基础网络虚拟化成一台巨大的“二层交换机”，所有的服务器都连结在这台二层交换机上。underlay网路具体如何转发，服务器完全无需关心。将虚拟机从“二层交换机”的一个端口换到另一个端口，完全无需变更IP地址。<br>使用这种理念的技术协议，除了vxlan外，还有NVGRE、STT等。</p>
<p>传统网络中，vlan数量只有4000个左右，vxlan理论上可以支持16M的vxlan段，从而满足大规模不同网络之间的标识、隔离需求。</p>
<h2 id="vxlan的隧道是如何建立的"><a href="#vxlan的隧道是如何建立的" class="headerlink" title="vxlan的隧道是如何建立的"></a>vxlan的隧道是如何建立的</h2><h3 id="vxlan中的VTEP和VNI"><a href="#vxlan中的VTEP和VNI" class="headerlink" title="vxlan中的VTEP和VNI"></a>vxlan中的VTEP和VNI</h3><p>下面了解一下vxlan网络模型以及一些常见的概念，如下图所示，两台服务器之间通过vxlan的网络进行通信。</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_network_module.png"></p>
<p>如上图所示，vxlan报文在vtep两端有一个封装和解封装的操作。</p>
<p>VTEP(vxlan tunnel endpoints, vxlan隧道端点)是vxlan网络的边缘设备，是vxlan隧道的起点个终点，vxlan对用户原始数据帧的封装和解封装均在VTEP上进行。VTEP既可以是一台独立的网络设备，也可以是服务器中的虚拟交换机。</p>
<p>VNI(vxlan network identifier, vxlan网络标识符)是一种类似VLAN ID的用户标识，一个VNI代表了一个租户，属于不同的VNI虚拟机之间不能直接进行二层通信。在分布式网关的部署场景下，VNI可以分为二层VNI和三层VNI：</p>
<ul>
<li>二层VNI是普通VNI，以1:1方式映射到广播域BD，实现vxlan报文同子网的转发</li>
<li>三层VNI和VPN实例进行关联，用于vxlan报文跨子网的转发，参见EVPN相关</li>
</ul>
<h3 id="那些VTEP之间需要建立vxlan隧道"><a href="#那些VTEP之间需要建立vxlan隧道" class="headerlink" title="那些VTEP之间需要建立vxlan隧道"></a>那些VTEP之间需要建立vxlan隧道</h3><p>连接在不同的VTEP上的VM之间如果有“大二层”互通的需求，这两个VTEP之间就需要建立vxlan隧道。换言之，同一个大二层域内的VTEP之间都需要建立VTEP隧道。</p>
<p><code>同一个大二层域</code>类似于传统网络中VLAN(虚拟局域网)的概念，在vxlan中它有另一个名字，叫做Bridge-Domain，简称BD。vlan是通过vlan id来标识的，BD则是通过VNI来标识的，BD与VNI是1:1的映射关系。以华为CloudEngine系列交换机而言，可以如下配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">bridge-domain 10        #表示创建一个大二层广播域，编号是10</span><br><span class="line">  vxlan vni 5000        #表示在BD下，指定与之关联的VNI是5000</span><br></pre></td></tr></table></figure>
<p>有了映射之后，进入VTEP的报文就可以根据自己所属的BD来确定报文封装时添加的VNI。那么怎么确定报文属于那个BD呢？</p>
<p>VTEP只是交换机承担的一个角色，只是交换机功能的一部分。并非所有进入交换机的报文都会走Vxlan隧道（也可能报文就是走普通二三层转发流程）。</p>
<p>在vlan的接口对报文处理的流程是：</p>
<ol>
<li>根据配置来检查哪些报文时允许通过的</li>
<li>判断对检查通过的报文做怎样的处理</li>
</ol>
<p>在vxlan网络中，VTEP上的接口承担类似的任务，这个接口是个叫做<code>二层子接口</code>的逻辑接口。二层子接口对报文的处理流程是：</p>
<ol>
<li>根据配置来检查哪些报文需要进入vxlan隧道</li>
<li>判断对检查通过的报文做怎样的处理</li>
</ol>
<p>在二层子接口上，可以根据需要定义不同的流封装类型（类似传统网络中不同的接口类型），一般有dot1q、untag、qinq和default四种类型：</p>
<ul>
<li>dot1q:对于带一层vlan tag的报文，该类型的接口只接受与指定vlan tag匹配的报文；对于带有两层vlan tag的报文，该类型接口只接收外层vlan tag与指定VLAN tag匹配的报文</li>
<li>untag：只接收不带vlan tag的报文</li>
<li>qinq：只接收带有指定两层vlan tag的报文</li>
<li>default: 允许接口接收所有的报文，不区分报文中是否带有vlan tag。不论是对原始报文进行vxlan封装还是解封装，该类型接口都不会对原始报文进行任何vlan tag处理，包括添加、替换和剥离。</li>
</ul>
<p>vxlan隧道两端二层子接口的配置并不一定是完全相等的。正因为这样，才可能实现属于同一网段但是不同vlan的两个vm通过vxlan隧道进行通信。</p>
<p>除二层子接口外，还可以将vlan作为业务接入点。将vlan绑定到BD后，加入该vlan的接口即为vxlan业务接入点，进入接口的报文由vxlan隧道处理。</p>
<p>只要将二层子接口加入指定的BD，然后根据二层子接口上的配置，设备就可以确定报文属于那个BD啦！</p>
<h3 id="vxlan隧道是怎么建立的"><a href="#vxlan隧道是怎么建立的" class="headerlink" title="vxlan隧道是怎么建立的"></a>vxlan隧道是怎么建立的</h3><p>两种方式，手动或自动。</p>
<h4 id="手动建立"><a href="#手动建立" class="headerlink" title="手动建立"></a>手动建立</h4><p>这种方式需要用户手动指定vxlan隧道源IP为本端VTEP的IP、目的IP为对端VTEP的IP，也就是人为在本端VTEP和对端VTEP之间建立静态VXLAN隧道。</p>
<p>以华为CloudEngine系列交换机为例，在NVE(network virtualization edge)接口下完成配置，配置举例如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">interface Nve1          #创建逻辑接口NVE 1</span><br><span class="line">    source 1.1.1.1          #配置源VTEP的IP地址（推荐使用Loopback接口的IP地址）</span><br><span class="line">    vni 5000 head-end peer-list 2.2.2.2</span><br><span class="line">    vni 5000 head-end peer-list 2.2.2.3</span><br></pre></td></tr></table></figure>
<p>两条vni命令表示VNI 5000的对端VTEP有两个。根据这两条配置，VTEP上会生成如下所示的一张表：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&lt;HUAWEI&gt; display vxlan vni 5000 verbose</span><br><span class="line">BD ID : 10</span><br><span class="line">State : up</span><br><span class="line">NVE : 288</span><br><span class="line">Source Address : 1.1.1.1</span><br><span class="line">Source IPv6 Address : -</span><br><span class="line">UDP Port : 4789</span><br><span class="line">BUM Mode : head-end</span><br><span class="line">Group Address : -</span><br><span class="line">Peer List : 2.2.2.2 2.2.2.3</span><br><span class="line">IPv6 Peer List : -</span><br></pre></td></tr></table></figure>
<p>根据这张表的Peer List，本端VTEP就可以知道属于同一BD的对端VTEP有哪些，这也决定了同一大二层广播域的范围。当VTEP收到BUM(broadcast&amp;unknown-unicast&amp;multicast)报文时，会将报文复制并发送给peer list中所列的所有对端VTEP（类似广播报文在VLAn内广播）。因此，这张表也被称为”头端复制列表”。当VTEP收到一致单播报文时，会根据VTEP上的MAC表来确定报文要从那条vxlan隧道走。而此时Peer List中所列出的对端，则充当了MAC表中”出接口”的角色。</p>
<h4 id="自动建立"><a href="#自动建立" class="headerlink" title="自动建立"></a>自动建立</h4><p>自动建立则需要借助EVPN(Ethernet VPN)协议。</p>
<h4 id="如何确定报文走那条隧道"><a href="#如何确定报文走那条隧道" class="headerlink" title="如何确定报文走那条隧道"></a>如何确定报文走那条隧道</h4><p>参见<code>vxlan网络中报文时如何转发的</code>章节。</p>
<h2 id="vxlan网关有哪些种类"><a href="#vxlan网关有哪些种类" class="headerlink" title="vxlan网关有哪些种类"></a>vxlan网关有哪些种类</h2><h3 id="vxlan二层网关与三层网关"><a href="#vxlan二层网关与三层网关" class="headerlink" title="vxlan二层网关与三层网关"></a>vxlan二层网关与三层网关</h3><p>和vlan类似，不同VNI之间的主机，以及vxlan网络和非vxlan网络中的主机不能直接相互通信，为了满足这些通信需求，vxlan引入了vxlan网关的概念。vxlan网关分为二层网关和三层网关：</p>
<ul>
<li>二层网关：用于终端接入vxlan网络，也可用于同一vxlan网络的子网通信</li>
<li>三层网关：用于vxlan网络中跨子网通信以及访问外部网络</li>
</ul>
<p>具体说明下。<br>vxlan三层网关。用于终结vxlan网络，将vxlan报文转换成传统三层报文发送至IP网络，适用于vxlan网络内服务器与远端之间的三层互访；同时也作不同vxlan网络互通，如下图所示.当服务器访问外部网络时，vxlan三层网关剥离对应vxlan报文封装，送入IP网络；当外部终端访问vxlan内的服务器时，vxlan根据目的IP地址所属vxlan及所属的VTEP，加上对应的vxlan报文头封装进入vxlan网络。vxlan之间的互访流量与此类似，vxlan网关剥离vxlan报文头，并基于目的IP地址所属vxlan及所属的VTEP，重新封装后送入另外的vxlan网络。<br><img src="https://rancho333.gitee.io/pictures/vxlan_l3_gateway.png"></p>
<p>vxlan二层网关。用于终结vxlan网络。将vxlan报文转换成对应的传统二层网络送到传统以太网路，适用于vxlan网络内服务器与远端终端或远端服务器的二层互联。如在不同网络中做虚拟机迁移时，当业务需要传统网络中服务器与vxlan网络中服务器在同一个二层中，此时需要使用vxlan二层网关打通vxlan网络和二层网络。如下图所示。vxlan10网络中的服务器要和IP网络中vlan100的业务二层互通，此时就需要通过vxlan的二层网关进行互联。vxlan10的报文进入IP网络的流量，剥离vxlan报文头，根据vxlan的标签查询对应的vlan网络，并据此在二层报文中加入vlan的802.1Q报文送入IP网络；相反vlan100的业务流量进入vxlan也需要根据vlan获知对应的vxlan的vni，根据目的mac地址获知远端vtep的IP地址，基于以上信息进行vxlan封装后送入对应的vxlan网络。</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_l2_gateway.png"></p>
<h3 id="vxlan集中式网关与分布式网关"><a href="#vxlan集中式网关与分布式网关" class="headerlink" title="vxlan集中式网关与分布式网关"></a>vxlan集中式网关与分布式网关</h3><p>集中式网关指将三层网关集中部署在一台设备上,如下图所示，所有跨子网的流量都经过这个三层网关转发，实现流量的集中管理。</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_gateway.png"></p>
<p>集中式网关的优点和缺点如下：</p>
<ul>
<li>优点：对跨子网流量进行集中管理，网关部署和管理比较简单</li>
<li>缺点：<ul>
<li>转发路径不是最优</li>
<li>ARP表项规格瓶颈。通过三层网关转发的终端的ARP表项都需要在三层网关上生成。</li>
</ul>
</li>
</ul>
<p>vxlan分布式网关是指在典型的”spine-leaf”组网结构下，将leaf节点作为vxlan隧道断点VTEP，每个leaf节点都可作为vxlan三层网关(同时也是vxlan二层网关)，spine节点不感知vxlan隧道，只作为vxlan报文的转发节点。如下图所示</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_gateway_2.png"></p>
<p>部署分布式网关时：</p>
<ul>
<li>spine节点：关注于高速IP转发，强调的是设备的高速转发能力</li>
<li>leaf节点：<ul>
<li>作为vxlan网络的二层网关，与物理服务器或vm对接，用于解决终端租户接入vxlan虚拟网络的问题</li>
<li>作为vxlan网络的三层网关，进行vxlan报文封装与解封装，实现跨子网的终端租户通信，以及外部网络的访问</li>
</ul>
</li>
</ul>
<p>vxlan分布式网关具有如下特点：</p>
<ul>
<li>同一个leaf节点既可以做vxlan二层网关，也可以做vxlan三层网关</li>
<li>leaf节点只需要学习自身连接服务器的ARP表项，而不必像集中三层网关一样，需要学习所有服务器的ARP表项，解决了集中式三层网关带来的ARP表项瓶颈问题，网络规模扩展能力强</li>
</ul>
<h2 id="vxlan网络中报文时如何转发的"><a href="#vxlan网络中报文时如何转发的" class="headerlink" title="vxlan网络中报文时如何转发的"></a>vxlan网络中报文时如何转发的</h2><p>这里介绍集中式vxlan中相同子网内、不同子网间是如何进行通信的。对于分布式vxlan网络，在EVPN中介绍。<br>对于二三层转发通信细节不是很清楚的同学，建议学习下二层与三层ping中arp与icmp报文的交互细节。</p>
<h3 id="集中式vxlan中同子网互通流程"><a href="#集中式vxlan中同子网互通流程" class="headerlink" title="集中式vxlan中同子网互通流程"></a>集中式vxlan中同子网互通流程</h3><p><img src="https://rancho333.gitee.io/pictures/vxlan_l2_ct.png"></p>
<p>如上图所示，VM_A、VM_B、VM_C属于相同网段，且同属VNI 5000。C要与A进行通信，对于首次通信，需要通过ARP获取对方MAC。在vlan子网通信中，arp报文在vlan内广播。在vxlan相同子网中，ARP请求报文转发流程见下图</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_l2_arp_request.png"></p>
<p>A向C进行MAC请求的过程如下：</p>
<ol>
<li>A发送ARP请求报文请求C的MAC</li>
<li>VTEP_1收到ARP请求后<ol>
<li>根据二层子接口上的配置判断报文需要进入vxlan隧道，确定报文所属BD，VNI</li>
<li>VTEP_1学习A的MAC、VNI和报文入接口的对应关系，记录到MAC地址表中</li>
<li>VTEP_1根据头端复制列表对报文进行复制，并分别进行封装，其中：<ol>
<li>外层源IP为本地VTEP_1的IP地址，外层目的IP地址为对端VTEP(VTEP_2、VTEP_3)的IP地址</li>
<li>外层源MAC地址为本地VTEP的mac地址，外层目的mac地址为去往目的IP网络的下一跳设备mac地址</li>
<li>封装完成之后就是在underlay网络中将vxlan报文传送到对端VTEP</li>
</ol>
</li>
</ol>
</li>
<li>VTEP_2和VTEP_3收到报文后，对报文进行解封装，得到A发送的原始报文<ol>
<li>VTEP_2和VTEP_3学习A的MAC地址、VNI和远端VTEP_1IP地址的对应关系，并记录在本地MAC表中</li>
<li>VTEP_2和VTEP_3根据二层子接口上的配置进行相应的处理并在对应的二层域内广播</li>
</ol>
</li>
<li>B和C收到arp报文后，按照arp报文处理方式进行丢弃或应答。这里C向A发送ARP应答。</li>
</ol>
<p>ARP应答报文转发流程见下图</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_l2_arp_reply.png"></p>
<p>C向A发送ARP 应答报文的过程如下：</p>
<ol>
<li>A向C发送ARP应答报文</li>
<li>VTEP_3收到ARP应答报文后<ol>
<li>确定报文所属的BD、VNI</li>
<li>VTEP_3学习C的MAC、VNI和报文入接口的对应关系，记录到MAC地址表中</li>
<li>VTEP_3对报文进行封装，其中：<ol>
<li>外层源IP为本地VTEP_3的IP地址，外层目的IP地址为对端VTEP_1的IP地址</li>
<li>外层源MAC地址为本地VTEP的mac地址，外层目的mac地址为去往目的IP网络的下一跳设备mac地址</li>
<li>封装完成之后就是在underlay网络中将vxlan报文传送到对端VTEP</li>
</ol>
</li>
</ol>
</li>
<li>VTEP_1收到报文后，对报文进行解封装，得到C发送的原始报文<ol>
<li>VTEP_1学习C的MAC地址、VNI和远端VTEP_3IP地址的对应关系，并记录在本地MAC表中</li>
<li>VTE_1将解封后的报文发送给A</li>
</ol>
</li>
</ol>
<p>至此，A和C均已学习到了对方的MAC地址。</p>
<h3 id="集中式vxlan不同子网互通流程"><a href="#集中式vxlan不同子网互通流程" class="headerlink" title="集中式vxlan不同子网互通流程"></a>集中式vxlan不同子网互通流程</h3><p><img src="https://rancho333.gitee.io/pictures/vxlan_l3_ct.png"></p>
<p>A、B分属不同网段，且分别属于VNI 5000和VNI 6000。A、B对应的三层网关分别是VTEP_3上的BDIF 10和BDIF 20的IP地址。VTEP_3上存在到两个网段的路由。</p>
<p>BDIF接口的功能与VLAN IF接口类似，是基于BD创建的三层逻辑接口，用以实现不同子网之间的通信，或vxlan网络与非vxlan网络之间的通信。</p>
<p>对于首次通信，类比与underlay网络中跨网段通信。A请求网关BDIF 10 MAC，然后将数据包发送给网关BDIF 10，BDIF 10将数据包路由至BDIF 20，BDIF 20请求B的MAC，然后将数据包发送给B。具体流程如下：</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_l3_arp.png"></p>
<p>数据报文转发流程如下：</p>
<ol>
<li>A将数据报文发送给网关。报文的源MAC是A MAC，目的MAC是网管BDIF 10的MAC；报文的源IP是A的IP，目的IP是B的IP</li>
<li>VTEP_1收到数据报文之后，识别报文所属的VNI，并根据MAC表项对报文进行封装<ol>
<li>外层源IP地址为本地VTEP的IP，外层目的IP地址为对端VTEP的IP</li>
<li>外层源MAC地址为本地VTEP的MAC地址，外层目的MAC地址为下一跳设备的IP地址</li>
<li>封装之后再underlay网络中传送至目的VTEP</li>
</ol>
</li>
<li>VTEP_3收到报文之后，对报文进行解封装。得到A发送的原始报文，VTEP_3会报文会做如下处理：<ol>
<li>VTEP_3发现该报文的目的MAC为本机BDIF 10接口的MAC，而目的IP为B的IP，所以会根据路由表查找B的下一跳</li>
<li>发现下一跳的出接口为BDIF 20。VETP_3查询ARP表项，将原始报文的源MAC修改为BDIF 20接口的MAC，将目的MAC修改为B的MAC</li>
<li>报文到BDIF 20后，识别需要进入vxlan隧道，所以根据MAC表对报文进行封装。<ol>
<li>外层源IP为本地VTEP的IP，外层目的IP地址为对端VTEP的IP</li>
<li>外层源MAC地址为本地VTEP的MAC，外层目的MAC为去往目的IP网络的下一跳设备的MAC地址</li>
<li>封装之后再underlay网络中传送至目的VTEP</li>
</ol>
</li>
</ol>
</li>
<li>VETP_2收到报文之后，对报文进行解封装，将overlay报文发送给B</li>
</ol>
<p>vxlan网络与非vxlan网络之间的互通，也需要借助三层网关，但是不同在于：报文在vxlan网络侧会进行封装，而在非vxlan网络侧不需要进行封装。报文从vxlan侧进入网关并解封后，就按照普通单播报文的发送方式进行转发。</p>
<h2 id="overlay网络的三种构建模式"><a href="#overlay网络的三种构建模式" class="headerlink" title="overlay网络的三种构建模式"></a>overlay网络的三种构建模式</h2><p>在数据中心，部分业务不适合进行虚拟化(如小机服务器，高性能数据库服务器),这些服务器会直接与物理交换机互联；对于服务器(虚拟机)，接入的可以是虚拟交换机(OpenvSwitch),也可以是物理交换机，因此存在如下图所示的三种接入模型。</p>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_network_module_2.png"></p>
<p>以上，在network overlay方案中，所有终端均采用物理交换机作为VTEP节点；host overlay方案中，所有终端均采用虚拟交换机作为VTEP节点；hybird overlay方案中，既有物理交换机接入，又有虚拟交换机接入，且软件VTEP和硬件VTEP之间可以基于标准协议互通。</p>
<h2 id="vxlan与SDN"><a href="#vxlan与SDN" class="headerlink" title="vxlan与SDN"></a>vxlan与SDN</h2><p>vxlan只定义了转发平面的流程，对于控制平面还没有规范，一般采取三种方式：</p>
<ol>
<li>组播。由物理网络的组播协议形成组播表项，通过手工方式将不同的vxlan与组播组一一绑定。vxlan的报文通过绑定的组播组在组播对应的范围内进行泛洪</li>
<li>自定义协议。通过自定义的邻居发现协议学习overlay网络的拓扑结构并建立隧道管理机制，比如现在广泛应用的BGP-EVPN</li>
<li>SDN控制器。通过SDN控制器集中控制vxlan的转发，经由openflow协议下发表项是目前业界的主流方式</li>
</ol>
<h1 id="EVPN学习"><a href="#EVPN学习" class="headerlink" title="EVPN学习"></a>EVPN学习</h1><h2 id="EVPN的作用"><a href="#EVPN的作用" class="headerlink" title="EVPN的作用"></a>EVPN的作用</h2><p>最初的vxlan方案(RFC7348)中没有定义控制平面，是手工配置隧道，然后通过流量泛洪的方式进行主机地址的学习。这会导致网络中存在很多泛洪流量、网络扩展起来很难。</p>
]]></content>
      <tags>
        <tag>通信协议</tag>
        <tag>vxlan</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC中Vxlan-decap测试用例简析</title>
    <url>/2021/04/28/SONiC%E4%B8%ADVxlan-decap%E6%B5%8B%E8%AF%95%E7%94%A8%E4%BE%8B%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<h2 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h2><p>本文简要分析SONiC testbed中Vxlan decap测试用例的实现，作为对<a href="https://rancho333.gitee.io/2021/02/03/vxlan%E5%AD%A6%E4%B9%A0/">vxlan学习</a>的补充。</p>
<span id="more"></span>

<h2 id="背景简述"><a href="#背景简述" class="headerlink" title="背景简述"></a>背景简述</h2><p>Vxlan技术的本质是通过overlay实现一个vm无感知的大二层网络，一般用于数据中心，好处是vm迁移时可以保持IP不变（再辅以一些技术手段可以保持业务不中断）,换种方式说，vm可以在任意物理主机上实现和网关的二层互通。</p>
<h2 id="测试用例简析"><a href="#测试用例简析" class="headerlink" title="测试用例简析"></a>测试用例简析</h2><p>在<code>sonic-mgmt/tests/vxlan</code>下共有5个测试文件：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">test_vnet_route_leak.py</span><br><span class="line">test_vnet_vxlan.py</span><br><span class="line">test_vxlan_decap.py</span><br><span class="line">vnet_constants.py</span><br><span class="line">vnet_utils.py</span><br></pre></td></tr></table></figure>
<p>本次只是简要分析下<code>test_vxlan_decap.py</code>测试内容。</p>
<h2 id="测试内容"><a href="#测试内容" class="headerlink" title="测试内容"></a>测试内容</h2><p>测试dut在数据面对vxlan报文的解封装。对每一vlan会运行三个case。</p>
<ol>
<li>Vxlan： 给portchannel接口发送封装的vxlan报文，应该在对应的vlan接口上看到payload报文。</li>
<li>RegularLAGtoVLAN: 发送常规报文给portchannel接口，应该在对应的vlan接口上看到该报文。</li>
<li>RegularVLANtoLAG: 发送常规报文给vlan成员接口，应该在portchannel接口上看到该报文。</li>
</ol>
<p><img src="https://rancho333.gitee.io/pictures/vxlan_tests.png"></p>
<h2 id="测试参数"><a href="#测试参数" class="headerlink" title="测试参数"></a>测试参数</h2><p>共有6个测试参数。</p>
<ol>
<li><code>config_file</code>是运行test所需要的所有必要信息。该文件由ansible构造生成。该参数不可缺省。</li>
<li><code>vxlan_enabled</code>是一个布尔参数。当设置为true时，vxlan测试失败整个测试失败。该参数默认为false。</li>
<li><code>count</code>是一个整数。表示发包数，默认为1.</li>
<li><code>dut_host</code>是dut的ip地址</li>
<li><code>sonic_admin_user</code>是dut的登录名</li>
<li><code>sonic_admin_password</code>是登录密码</li>
</ol>
<h2 id="测试方法"><a href="#测试方法" class="headerlink" title="测试方法"></a>测试方法</h2><p>testbed设置好之后，运行:</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">.&#x2F;run_tests.sh -d cel-seastone-01 -n cel_slx_t0 -c vxlan&#x2F;test_vxlan_decap.py -t t0,any</span><br></pre></td></tr></table></figure>

<h2 id="测试结果"><a href="#测试结果" class="headerlink" title="测试结果"></a>测试结果</h2><p>测试失败</p>
<p>log记录下来供后续参考。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">E               &quot;delta&quot;: &quot;0:01:30.984956&quot;, E               &quot;end&quot;: &quot;2021-04-28 09:12:57.714679&quot;, E               &quot;failed&quot;: true, E               &quot;invocation&quot;: &#123;E                   &quot;module_args&quot;: &#123;E                       &quot;_raw_params&quot;: &quot;ptf --test-dir ptftests vxlan-decap.Vxlan --platform-dir ptftests --qlen&#x3D;10000 --platform remote -t &#39;vxlan_enabled&#x3D;False;count&#x3D;10;config_file&#x3D;&#39;\&quot;&#39;\&quot;&#39;&#x2F;tmp&#x2F;vxlan_decap.json&#39;\&quot;&#39;\&quot;&#39;;sonic_admin_user&#x3D;u&#39;\&quot;&#39;\&quot;&#39;admin&#39;\&quot;&#39;\&quot;&#39;;sonic_admin_password&#x3D;u&#39;\&quot;&#39;\&quot;&#39;password&#39;\&quot;&#39;\&quot;&#39;;dut_hostname&#x3D;u&#39;\&quot;&#39;\&quot;&#39;10.251.0.100&#39;\&quot;&#39;\&quot;&#39;;sonic_admin_alt_password&#x3D;u&#39;\&quot;&#39;\&quot;&#39;YourPaSsWoRd&#39;\&quot;&#39;\&quot;&#39;&#39; --relax --debug info --log-file &#x2F;tmp&#x2F;vxlan-decap.Vxlan.Removed.2021-04-28-09:11:26.log&quot;, E                       &quot;_uses_shell&quot;: true, E                       &quot;argv&quot;: null, E                       &quot;chdir&quot;: &quot;&#x2F;root&quot;, E                       &quot;creates&quot;: null, E                       &quot;executable&quot;: null, E                       &quot;removes&quot;: null, E                       &quot;stdin&quot;: null, E                       &quot;stdin_add_newline&quot;: true, E                       &quot;strip_empty_ends&quot;: true, E                       &quot;warn&quot;: trueE                   &#125;E               &#125;, E               &quot;msg&quot;: &quot;non-zero return code&quot;, E               &quot;rc&quot;: 1, E               &quot;start&quot;: &quot;2021-04-28 09:11:26.729723&quot;, E               &quot;stderr&quot;: &quot;WARNING: No route found for IPv6 destination :: (no default route?)\n&#x2F;usr&#x2F;local&#x2F;lib&#x2F;python2.7&#x2F;dist-packages&#x2F;paramiko&#x2F;transport.py:33: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in a future release.\n  from cryptography.hazmat.backends import default_backend\nvxlan-decap.Vxlan ... FAIL\n\n&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;\nFAIL: vxlan-decap.Vxlan\n----------------------------------------------------------------------\nTraceback (most recent call last):\n  File \&quot;ptftests&#x2F;vxlan-decap.py\&quot;, line 397, in runTest\n    self.warmup()\n  File \&quot;ptftests&#x2F;vxlan-decap.py\&quot;, line 334, in warmup\n    raise AssertionError(\&quot;Warmup failed\&quot;)\nAssertionError: Warmup failed\n\n----------------------------------------------------------------------\nRan 1 test in 89.524s\n\nFAILED (failures&#x3D;1)&quot;, E               &quot;stderr_lines&quot;: [E                   &quot;WARNING: No route found for IPv6 destination :: (no default route?)&quot;, E                   &quot;&#x2F;usr&#x2F;local&#x2F;lib&#x2F;python2.7&#x2F;dist-packages&#x2F;paramiko&#x2F;transport.py:33: CryptographyDeprecationWarning: Python 2 is no longer supported by the Python core team. Support for it is now deprecated in cryptography, and will be removed in a future release.&quot;, E                   &quot;  from cryptography.hazmat.backends import default_backend&quot;, E                   &quot;vxlan-decap.Vxlan ... FAIL&quot;, E                   &quot;&quot;, E                   &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;, E                   &quot;FAIL: vxlan-decap.Vxlan&quot;, E                   &quot;----------------------------------------------------------------------&quot;, E                   &quot;Traceback (most recent call last):&quot;, E                   &quot;  File \&quot;ptftests&#x2F;vxlan-decap.py\&quot;, line 397, in runTest&quot;, E                   &quot;    self.warmup()&quot;, E                   &quot;  File \&quot;ptftests&#x2F;vxlan-decap.py\&quot;, line 334, in warmup&quot;, E                   &quot;    raise AssertionError(\&quot;Warmup failed\&quot;)&quot;, E                   &quot;AssertionError: Warmup failed&quot;, E                   &quot;&quot;, E                   &quot;----------------------------------------------------------------------&quot;, E                   &quot;Ran 1 test in 89.524s&quot;, E                   &quot;&quot;, E                   &quot;FAILED (failures&#x3D;1)&quot;E               ], E               &quot;stdout&quot;: &quot;&quot;, E               &quot;stdout_lines&quot;: []E           &#125;</span><br></pre></td></tr></table></figure>

<p>可以找到是在<code>warmup</code>中出错了，具体怎么修改后续再跟吧！</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC中交换芯片启动流程简述</title>
    <url>/2021/07/21/SONiC%E4%B8%AD%E4%BA%A4%E6%8D%A2%E8%8A%AF%E7%89%87%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本文基于SONiC 202012分支进行交换芯片启动流程的分析。源码部分主要涉及<code>sonic-swss</code>和<code>sonic-sairedis</code>以及<code>ocp-sai</code>. 一句话说明所有流程：swss模块通知syncd模块进行ASIC初始化。</p>
<span id="more"></span>

<h2 id="模块主要功能说明"><a href="#模块主要功能说明" class="headerlink" title="模块主要功能说明"></a>模块主要功能说明</h2><p>docker swss中的模块主要可以分为三类:</p>
<ol>
<li>收集信息写往APP_DB，如portsyncd, intfsyncd（*syncd）</li>
<li>订阅APP_DB将数据写往ASIC_DB，如orchagent（是APP_DB的consumer，同时也是ASIC_DB的producer）</li>
<li>收集数据写往kernel， IntfMgrd和VlanMgrd</li>
</ol>
<p>docker syncd中主要是syncd模块，该模块订阅ASIC_DB,之后调用sai api操作sdk, 完成数据的下发。</p>
<h1 id="从swss开始"><a href="#从swss开始" class="headerlink" title="从swss开始"></a>从swss开始</h1><p>搞清楚ASIC的启动流程，实际上上就是弄清楚orchagent和syncd这两个进程的初始化和通信的过程。</p>
<p>在docker syncd的启动脚本中，我们可以看到其依赖关系。<br><img src="https://rancho333.github.io/pictures/syncd_service.png"></p>
<p>docker swss中orchagent负责通知syncd进行ASIC初始化， 对于orchagent主要理解下面两行代码：<br><img src="https://rancho333.github.io/pictures/orchagent_init.png"></p>
<p>这里简要说明一下<code>OCP SAI</code>的工作方式，对应的源码在<code>src/sonic-sairedis/SAI</code>, 这里面定义了sai的data以及functions，还有一些metadata操作方式，而数据的初始化以及函数的实现由芯片厂商实现，通过动态库的方式提供。syncd编译时会链接到libsai，这样我们在syncd中就可以调用sai api完成对SDK的控制。</p>
<p>与此类似的，在<code>sonic-sairedis</code>中提供一个libsairedis的动态库(源码在<code>src/sonic-sairedis/lib</code>)，这里面同样对ocp sai进行实现，不过实现的对象是redis，这样在orchagent中就可以调用sai api完成对redis的操作。</p>
<p>对于<code>initSaiApi</code>：<br><img src="https://rancho333.github.io/pictures/saiapi_init.png"></p>
<p>对于<code>sai_api_query</code>, 在<code>src/sonic-sairedis/SAI/inc/sai.h</code>中是对其的定义，在<code>src/sonic-sairedis/lib/src/sai_redis_interfacequery.cpp</code>中是对其的实现。借用<code>API</code>宏完成对其初始化。<br><img src="https://rancho333.github.io/pictures/saiapi_query.png"></p>
<p>注意<code>sai_apis_t</code>结构体是<code>src/sonic-sairedis/SAI/meta/parse.pl</code>perl脚本自动生成的，生成的文件名为<code>saimetadata.h</code>,结构体成员为各功能模块的结构体指针。</p>
<p>以<code>sai_switch_api</code>为例：<br><img src="https://rancho333.github.io/pictures/sai_switch_api.png"><br>到这里就完成了对OCP SAI的封装调用，而最后对redis的操作，201911之后的版本，实际的redis操作函数都使用宏来生成。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REDIS_GENERIC_QUAD</span><br><span class="line">REDIS_CREATE</span><br></pre></td></tr></table></figure>

<p>这部分操作的就是将<code>create_switch</code>的信息写到<code>ASIC_DB</code>, <code>syncd</code>进程收到发布的消息之后进行真正的SDK初始化操作。<br><img src="https://rancho333.github.io/pictures/syslog.png"></p>
<h2 id="create-switch分析"><a href="#create-switch分析" class="headerlink" title="create_switch分析"></a>create_switch分析</h2><p><code>redis_create_switch</code>函数由宏定义展开：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">REDIS_GENERIC_QUAD(OT,ot)        sai_redis.h</span><br><span class="line">REDIS_CREATE(OT,ot)              sai_redis.h</span><br></pre></td></tr></table></figure>
<p><img src="https://rancho333.github.io/pictures/define_redis_create.png"></p>
<p><code>redis_sai</code>的定义如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">std::shared_ptr&lt;SaiInterface&gt; redis_sai &#x3D; std::make_shared&lt;ClientServerSai&gt;();    sai_redis_interfacequery.cpp</span><br><span class="line"></span><br><span class="line">SaiInterface是父类， ClientServerSai是其子类</span><br><span class="line">                    RemoteSaiInterface同样是SaiInterface子类</span><br><span class="line">                        RedisRemoteSaiInterface又是RemoteSaiInterface的子类</span><br></pre></td></tr></table></figure>
<p><code>redis_sai</code>的指针类型是<code>SaiInterface</code>，根据C++的多态特性，<code>redis_sai-&gt;create</code>的最终实现在：<br><img src="https://rancho333.github.io/pictures/redis_sai_create.png"></p>
<h1 id="syncd初始化ASIC"><a href="#syncd初始化ASIC" class="headerlink" title="syncd初始化ASIC"></a>syncd初始化ASIC</h1><p>直接从初始化sai api开始(由于201911之后的版本syncd模块重构了，变得更加难看，下面的分析基于201911版本，基本流程都差不多)：<br><img src="https://rancho333.github.io/pictures/syncd_saiapi_init.png"></p>
<p>在mainloop里面进入<code>processEvent</code>流程，里面进入<code>initviewmode</code>:<br><img src="https://rancho333.github.io/pictures/initview_mode.png"></p>
<p>之后：<br><img src="https://rancho333.github.io/pictures/on_switch_create.png"></p>
<p>然后调用sai api完成交换芯片初始化指令的下发：<br><img src="https://rancho333.github.io/pictures/create_switch.png"></p>
<p>最后就是sai模块中厂商对应的实现：<br><img src="https://rancho333.github.io/pictures/brcm_sai.png"></p>
]]></content>
      <tags>
        <tag>SONiC</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC上层应用之SWSS</title>
    <url>/2021/08/19/SONiC%E4%B8%8A%E5%B1%82%E5%BA%94%E7%94%A8%E4%B9%8BSWSS/</url>
    <content><![CDATA[]]></content>
  </entry>
  <entry>
    <title>SONiC中coredump调试</title>
    <url>/2021/08/23/SONiC%E4%B8%ADcoredump%E8%B0%83%E8%AF%95/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>在进行<code>sonic-testbed</code>中的<code>process monitor</code>用例调试的时候，发现<code>swss</code>容器中的<code>orchagent</code>进程产生coredump导致测试失败。本文将简单介绍coredump以及如何编译debug版本SONiC进行coredump调试。</p>
<span id="more"></span>

<h1 id="SONiC中coredump的一些配置"><a href="#SONiC中coredump的一些配置" class="headerlink" title="SONiC中coredump的一些配置"></a>SONiC中coredump的一些配置</h1><p>由于SONiC中的服务基本上都是运行在docker中，所以需要使能docker产生coredump。需要做两件事：</p>
<ol>
<li>在host上配置<code>/proc/sys/kernel/core_pattern</code>, 配置core文件路径以及名称</li>
<li>在docker中配置core文件大小限制<code>ulimit -c unlimited</code></li>
</ol>
<p>下面是SONiC对core文件路径及名称的配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">root@cel-brixia2-01:&#x2F;home&#x2F;admin# cat &#x2F;proc&#x2F;sys&#x2F;kernel&#x2F;core_pattern </span><br><span class="line">|&#x2F;usr&#x2F;local&#x2F;bin&#x2F;coredump-compress %e %t %p %P</span><br><span class="line">root@cel-brixia2-01:&#x2F;home&#x2F;admin# </span><br><span class="line">root@cel-brixia2-01:&#x2F;home&#x2F;admin# cat &#x2F;usr&#x2F;local&#x2F;bin&#x2F;coredump-compress</span><br><span class="line">#!&#x2F;bin&#x2F;bash</span><br><span class="line"></span><br><span class="line"># Collect all parameters in order and build a file name prefix</span><br><span class="line">PREFIX&#x3D;&quot;&quot;</span><br><span class="line">while [[ $# &gt; 1 ]]; do</span><br><span class="line">    PREFIX&#x3D;$&#123;PREFIX&#125;$1.</span><br><span class="line">    shift</span><br><span class="line">done</span><br><span class="line"></span><br><span class="line">if [ $# &gt; 0 ]; then</span><br><span class="line">    ns&#x3D;&#96;xargs -0 -L1 -a &#x2F;proc&#x2F;$&#123;1&#125;&#x2F;environ | grep -e &quot;^NAMESPACE_ID&quot; | cut -f2 -d&#39;&#x3D;&#39;&#96;</span><br><span class="line">    if [ ! -z $&#123;ns&#125; ]; then</span><br><span class="line">        PREFIX&#x3D;$&#123;PREFIX&#125;$&#123;ns&#125;.</span><br><span class="line">    fi</span><br><span class="line">fi</span><br><span class="line"></span><br><span class="line">&#x2F;bin&#x2F;gzip -1 - &gt; &#x2F;var&#x2F;core&#x2F;$&#123;PREFIX&#125;core.gz</span><br></pre></td></tr></table></figure>
<p>即当产生core文件时，我们可以在<code>/var/core/</code>路径下找到.</p>
<h1 id="SONiC中core文件调试"><a href="#SONiC中core文件调试" class="headerlink" title="SONiC中core文件调试"></a>SONiC中core文件调试</h1><p>普通的SONiC版本中是不带<code>gdb</code>工具的，<code>elf</code>文件也都是<code>stripped</code>。在编译debug版本的时候，需要做两件事：</p>
<ol>
<li>在docker中安装gdb工具</li>
<li>对<code>elf</code> not stripped或者主动添加<code>symbols</code>信息</li>
</ol>
<p>SONiC的编译系统提供了很方便的方法供用户编译debug版本，以<code>swss</code>为例做步骤说明。</p>
<ol>
<li><p>修改<code>rules/config</code>中的字段如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">-# INSTALL_DEBUG_TOOLS &#x3D; y</span><br><span class="line">+INSTALL_DEBUG_TOOLS &#x3D; y</span><br><span class="line"></span><br><span class="line">-#SONIC_DEBUGGING_ON &#x3D; y</span><br><span class="line">-#SONIC_PROFILING_ON &#x3D; y</span><br><span class="line">+SONIC_DEBUGGING_ON &#x3D; y</span><br><span class="line">+SONIC_PROFILING_ON &#x3D; y</span><br></pre></td></tr></table></figure></li>
<li><p>使用<code>make list</code>找到需要对应的target，如</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">target&#x2F;docker-orchagent-dbg.gz</span><br></pre></td></tr></table></figure>
<p>之后<code>make target/docker-orchagent-dbg.gz</code>生成debug版本的容器，然后拷贝到设备上。</p>
</li>
<li><p>加载镜像，生成debug版的容器</p>
<ul>
<li>使用<code>docker load -i docker-orchagent-dbg.gz</code>载入编译好的debug版镜像</li>
<li>删除原来的容器<code>docker rm swss</code></li>
<li>修改<code>/usr/bin/swss.sh</code> 文件<code>--name=$DOCKERNAME docker-orchagent-dbg:latest</code>，指定使用debug版镜像生成容器</li>
<li><code>service swss stop</code> &amp;&amp; <code>service swss start</code> 生成新的容器</li>
</ul>
</li>
<li><p>对core文件进行调试<br>将<code>/var/core</code>下的core文件拷到docker中，可以参见<code>/usr/bin/swss.sh</code>中<code>create docker</code>时挂载的目录，一般host上的<code>/etc/sonic</code>会以只读的方式挂载到docker中。</p>
</li>
</ol>
<p>使用<code>gdb /usr/bin/orchagent core.file</code>进行调试的时候，我们会发现gdb是从<code>/usr/lib/debug/.build-id/</code>下面读取symbols信息的。SONiC采用模块化增量的方式进行编译，原有的<code>elf</code>文件依然是<code>stripped</code>状态，但是在debug版本中会将里面的symbols信息提取出来放到一个deb包中，如<code>swss-dbg_1.0.0_amd64.deb</code>。</p>
<ol start="5">
<li>这是针对某一具体的debug容器替换说明，如果对整个SONiC编译debug版本,修改完<code>rules/config</code>后，直接<code>make target/sonic-broadcom.bin</code>即可。</li>
</ol>
]]></content>
      <tags>
        <tag>SONiC</tag>
        <tag>coredump</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC中syncd调用SAI简析</title>
    <url>/2021/09/06/SONiC%E4%B8%ADsyncd%E8%B0%83%E7%94%A8SAI%E7%AE%80%E6%9E%90/</url>
    <content><![CDATA[<h1 id="写在前面"><a href="#写在前面" class="headerlink" title="写在前面"></a>写在前面</h1><p>本文以SONiC<code>202012</code>版本进行<code>syncd</code>模块初始化分析。sycnd与orchagent强相关，主要有5个动作，分别是<code>create</code>、<code>remove</code>、<code>set</code>、<code>get</code>以及<code>notify</code>。对于前三个动作，orchagent调用sairedis api写往ASIC_DB即返回成功，<code>get</code>动作会阻塞等待syncd的答复，当syncd接收到<code>notify</code>事件后会通过ASIC_DB通知到orchagent。本文暂分析syncd的初始化动作。 </p>
<p>本文可以总结成一句话：SONiC上层根据objecttype获取对应的info结构，从而调用里面的具体方法，完成sai的调用。</p>
<span id="more"></span>

<h1 id="syncd-main-cpp中初始化ASIC"><a href="#syncd-main-cpp中初始化ASIC" class="headerlink" title="syncd_main.cpp中初始化ASIC"></a>syncd_main.cpp中初始化ASIC</h1><p><code>syncd_main.cpp</code>是syncd进程的入口函数，里面主要做3件事情：</p>
<ol>
<li>初始或日志服务</li>
<li>获取warmreboot状态</li>
<li>实例化类<code>VendorSai</code>、<code>Syncd</code>以及运行<code>syncd-&gt;run</code>函数进入syncd主循环模块</li>
</ol>
<p>在<code>Syncd_main.cpp</code>中主要是三行代码：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto vendorSai &#x3D; std::make_shared&lt;VendorSai&gt;();             &#x2F;&#x2F;实例化VendorSai，作为参数传给syncd</span><br><span class="line">auto syncd &#x3D; std::make_shared&lt;Syncd&gt;(vendorSai, commandLineOptions, isWarmStart);   &#x2F;&#x2F;实例化Syncd</span><br><span class="line">syncd-&gt;run();                                               &#x2F;&#x2F; 执行run方法</span><br></pre></td></tr></table></figure>

<p>对于<code>VendorSai</code>实例化，它的构造函数并没有做什么特别的事。</p>
<p>对于<code>Syncd</code>实例化</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;Syncd.cpp</span><br><span class="line">&#x2F;&#x2F; 注册notify事件的回调函数，onFdbEvent，onPortStateChange，onSwitchShutdownRequest，onSwitchStateChange等</span><br><span class="line">m_sn.onFdbEvent &#x3D; std::bind(&amp;NotificationHandler::onFdbEvent, m_handler.get(), _1, _2);</span><br><span class="line">m_sn.onPortStateChange &#x3D; std::bind(&amp;NotificationHandler::onPortStateChange, m_handler.get(), _1, _2);</span><br><span class="line"></span><br><span class="line">vendorSai-&gt;initialize               &#x2F;&#x2F;初始化sai api，并将之放到 m_apis中</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;初始化关心的DB、channel, 在syncd::run中通过其获取各种事件然后进行处理</span><br><span class="line">m_selectableChannel &#x3D; std::make_shared&lt;RedisSelectableChannel&gt;(</span><br><span class="line">                m_dbAsic,</span><br><span class="line">                ASIC_STATE_TABLE,</span><br><span class="line">                REDIS_TABLE_GETRESPONSE,</span><br><span class="line">                TEMP_PREFIX,</span><br><span class="line">                modifyRedis);</span><br><span class="line">m_restartQuery &#x3D; std::make_shared&lt;swss::NotificationConsumer&gt;(m_dbAsic.get(), SYNCD_NOTIFICATION_CHANNEL_RESTARTQUERY);</span><br><span class="line">m_flexCounter &#x3D; std::make_shared&lt;swss::ConsumerTable&gt;(m_dbFlexCounter.get(), FLEX_COUNTER_TABLE);</span><br><span class="line">    m_flexCounterGroup &#x3D; std::make_shared&lt;swss::ConsumerTable&gt;(m_dbFlexCounter.get(), FLEX_COUNTER_GROUP_TABLE);</span><br></pre></td></tr></table></figure>
<p>对于方法<code>initialize</code></p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto status &#x3D; sai_api_initialize(flags, service_method_table);      &#x2F;&#x2F;初始化sai api</span><br><span class="line">int failed &#x3D; sai_metadata_apis_query(sai_api_query, &amp;m_apis);       &#x2F;&#x2F;将api放入数据结构 m_api中</span><br></pre></td></tr></table></figure>

<p><code>Syncd</code>的主逻辑在<code>run</code>方法中，循环处理各种到来的事件，首先是初始化switch，在<code>onSyncdStart</code>中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">HardReiniter hr(m_client, m_translator, m_vendorSai, m_handler); &#x2F;&#x2F; 构造函数只是完成参数初始化</span><br><span class="line">m_switches &#x3D; hr.hardReinit();</span><br></pre></td></tr></table></figure>
<p>然后调</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;HardReiniter.cpp</span><br><span class="line">   std::vector&lt;std::shared_ptr&lt;SingleReiniter&gt;&gt; vec;</span><br><span class="line"></span><br><span class="line">    &#x2F;&#x2F; perform hard reinit on all switches</span><br><span class="line"></span><br><span class="line">    for (auto&amp; kvp: m_switchMap)</span><br><span class="line">    &#123;</span><br><span class="line">        auto sr &#x3D; std::make_shared&lt;SingleReiniter&gt;(</span><br><span class="line">                m_client,</span><br><span class="line">                m_translator,</span><br><span class="line">                m_vendorSai,</span><br><span class="line">                m_handler,</span><br><span class="line">                m_switchVidToRid.at(kvp.first),</span><br><span class="line">                m_switchRidToVid.at(kvp.first),</span><br><span class="line">                kvp.second);</span><br><span class="line"></span><br><span class="line">        sr-&gt;hardReinit();</span><br><span class="line">&#x2F;&#x2F; 这里面有做多ASIC的考虑，我们当前只会用到单ASIC</span><br></pre></td></tr></table></figure>
<p>之后</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">processSwitches();</span><br><span class="line">status &#x3D; m_vendorSai-&gt;create(SAI_OBJECT_TYPE_SWITCH, &amp;m_switch_rid, 0, attr_count, attr_list);</span><br></pre></td></tr></table></figure>
<p>在VendorSai.cpp中</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto info &#x3D; sai_metadata_get_object_type_info(objectType);          &#x2F;&#x2F; 根据SAI_OBJECT_TYPE_SWITCH获取type_info</span><br><span class="line">auto status &#x3D; info-&gt;create(&amp;mk, switchId, attr_count, attr_list);   &#x2F;&#x2F; 根据type_info中的方法（sai提供）初始化ASIC</span><br></pre></td></tr></table></figure>

<p><code>sai_metadata_get_object_type_info</code>实际上就是一个数组，根据<code>objectType</code>获取相应的数据。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;saimetadatautils.c</span><br><span class="line">const sai_object_type_info_t* sai_metadata_get_object_type_info(</span><br><span class="line">        _In_ sai_object_type_t object_type)</span><br><span class="line">&#123;                                                                                                                                                                                              </span><br><span class="line">    if (sai_metadata_is_object_type_valid(object_type))</span><br><span class="line">    &#123;   </span><br><span class="line">        return sai_metadata_all_object_type_infos[object_type];</span><br><span class="line">    &#125;   </span><br><span class="line"> </span><br><span class="line">    return NULL;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>数组<code>type_info</code>的定义在：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;saimetadata.c</span><br><span class="line">const sai_object_type_info_t* const sai_metadata_all_object_type_infos[] &#x3D; &#123;</span><br><span class="line">    NULL,  </span><br><span class="line">    &amp;sai_metadata_object_type_info_SAI_OBJECT_TYPE_PORT,                                                                                                                                       </span><br><span class="line">    &amp;sai_metadata_object_type_info_SAI_OBJECT_TYPE_LAG,</span><br><span class="line">    &amp;sai_metadata_object_type_info_SAI_OBJECT_TYPE_VIRTUAL_ROUTER,</span><br><span class="line">    &amp;sai_metadata_object_type_info_SAI_OBJECT_TYPE_NEXT_HOP,</span><br><span class="line">    ……</span><br><span class="line">    &amp;sai_metadata_object_type_info_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    ……</span><br><span class="line">    &#125;;</span><br></pre></td></tr></table></figure>
<p>以<code>type_switch</code>为例，它的具体数据为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">const sai_object_type_info_t sai_metadata_object_type_info_SAI_OBJECT_TYPE_SWITCH &#x3D; &#123;</span><br><span class="line">    .objecttype           &#x3D; SAI_OBJECT_TYPE_SWITCH,                    </span><br><span class="line">    .objecttypename       &#x3D; &quot;SAI_OBJECT_TYPE_SWITCH&quot;,                  </span><br><span class="line">    .attridstart          &#x3D; SAI_SWITCH_ATTR_START,                     </span><br><span class="line">    .attridend            &#x3D; SAI_SWITCH_ATTR_END,                       </span><br><span class="line">    .enummetadata         &#x3D; &amp;sai_metadata_enum_sai_switch_attr_t,</span><br><span class="line">    .attrmetadata         &#x3D; sai_metadata_object_type_sai_switch_attr_t,</span><br><span class="line">    .attrmetadatalength   &#x3D; 195,                                       </span><br><span class="line">    .isnonobjectid        &#x3D; false,                                     </span><br><span class="line">    .isobjectid           &#x3D; !false,                                    </span><br><span class="line">    .structmembers        &#x3D; NULL,                                      </span><br><span class="line">    .structmemberscount   &#x3D; 0,                                         </span><br><span class="line">    .revgraphmembers      &#x3D; sai_metadata_SAI_OBJECT_TYPE_SWITCH_rev_graph_members,</span><br><span class="line">    .revgraphmemberscount &#x3D; 8,                                         </span><br><span class="line">    .create               &#x3D; sai_metadata_generic_create_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    .remove               &#x3D; sai_metadata_generic_remove_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    .set                  &#x3D; sai_metadata_generic_set_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    .get                  &#x3D; sai_metadata_generic_get_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    .getstats             &#x3D; sai_metadata_generic_get_stats_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    .getstatsext          &#x3D; sai_metadata_generic_get_stats_ext_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    .clearstats           &#x3D; sai_metadata_generic_clear_stats_SAI_OBJECT_TYPE_SWITCH,</span><br><span class="line">    .isexperimental       &#x3D; false,                                     </span><br><span class="line">    .statenum             &#x3D; &amp;sai_metadata_enum_sai_switch_stat_t,                                                                                                                           </span><br><span class="line">&#125;;                                                   </span><br></pre></td></tr></table></figure>
<p>由于在<code>VendorSai::create</code>中调用的是其<code>create</code>方法，我们看下其实现：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;saimetadata.c</span><br><span class="line">sai_status_t sai_metadata_generic_create_SAI_OBJECT_TYPE_SWITCH(</span><br><span class="line">    _Inout_ sai_object_meta_key_t *meta_key,</span><br><span class="line">    _In_ sai_object_id_t switch_id,</span><br><span class="line">    _In_ uint32_t attr_count,</span><br><span class="line">    _In_ const sai_attribute_t *attr_list)</span><br><span class="line">&#123;             </span><br><span class="line">    return sai_metadata_sai_switch_api-&gt;create_switch(&amp;meta_key-&gt;objectkey.key.object_id, attr_count, attr_list);</span><br><span class="line">&#125;  </span><br><span class="line">&#x2F;&#x2F;sai_metadata_sai_switch_api的数据类型是sai_switch_api_t</span><br><span class="line">sai_switch_api_t *sai_metadata_sai_switch_api &#x3D; NULL;</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 给sai_metadata_sai_switch_api赋值，获取的实际就是sai_switch_api_t的实现</span><br><span class="line">status &#x3D; api_query(SAI_API_SWITCH, (void**)&amp;sai_metadata_sai_switch_api);</span><br><span class="line">&#x2F;&#x2F; sai_metadata_generic_create_SAI_OBJECT_TYPE_SWITCH是将switch_api中的create方法单独拎出来，以前的SAI冒似都是获取apis，然后调用switch_api，最后调用create_switch</span><br><span class="line">apis-&gt;switch_api &#x3D; sai_metadata_sai_switch_api;</span><br></pre></td></tr></table></figure>

<p><code>sai_switch_api_t</code>结构体的定义在：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;saiswitch.c</span><br><span class="line">typedef struct _sai_switch_api_t</span><br><span class="line">&#123;                                                                                                                                                                                              </span><br><span class="line">    sai_create_switch_fn                   create_switch;</span><br><span class="line">    sai_remove_switch_fn                   remove_switch;</span><br><span class="line">    sai_set_switch_attribute_fn            set_switch_attribute;</span><br><span class="line">    sai_get_switch_attribute_fn            get_switch_attribute;</span><br><span class="line">    sai_get_switch_stats_fn                get_switch_stats;</span><br><span class="line">    sai_get_switch_stats_ext_fn            get_switch_stats_ext;</span><br><span class="line">    sai_clear_switch_stats_fn              clear_switch_stats;</span><br><span class="line">    sai_switch_mdio_read_fn                switch_mdio_read;</span><br><span class="line">    sai_switch_mdio_write_fn               switch_mdio_write;</span><br><span class="line">    sai_create_switch_tunnel_fn            create_switch_tunnel;</span><br><span class="line">    sai_remove_switch_tunnel_fn            remove_switch_tunnel;</span><br><span class="line">    sai_set_switch_tunnel_attribute_fn     set_switch_tunnel_attribute;</span><br><span class="line">    sai_get_switch_tunnel_attribute_fn     get_switch_tunnel_attribute;</span><br><span class="line"> </span><br><span class="line">&#125; sai_switch_api_t;</span><br></pre></td></tr></table></figure>
<p>该结构的成员函数的实现则是由各ASIC厂家实现，以<code>create_switch</code>为例，在broadcom sai中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;brcm_sai_switch.c</span><br><span class="line">const sai_switch_api_t switch_apis &#x3D; &#123;</span><br><span class="line">    brcm_sai_create_switch,</span><br><span class="line">    brcm_sai_remove_switch,</span><br><span class="line">    brcm_sai_set_switch_attribute,</span><br><span class="line">    brcm_sai_get_switch_attribute,</span><br><span class="line">&#125;;     </span><br><span class="line">&#x2F;&#x2F; brcm_sai_create_switch具体的实现则不过分纠结了，SDK干的活   </span><br></pre></td></tr></table></figure>
<p>这样下来，从<code>SAI_OBJECT_TYPE_SWITCH</code>获取<code>tyep_info</code>结构，再到create方法在<code>sai</code>层的定义，以及最后的厂商实现就都连起来了。</p>
<p>总结下来，<code>VendorSai::create</code>方法中：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">auto info &#x3D; sai_metadata_get_object_type_info(objectType);      &#x2F;&#x2F;根据objecttype获取info结构，包含了该type的所有方法及属性</span><br><span class="line">auto status &#x3D; info-&gt;create(&amp;mk, switchId, attr_count, attr_list);  &#x2F;&#x2F; 调用type的create方法完成sai的调用</span><br></pre></td></tr></table></figure>

<p><code>onSyncdStart</code>之后，创建线程处理notifiy事件。</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">m_processor-&gt;startNotificationsProcessingThread();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;将care的db放到select监控中，接下来的main loop中就是循环处理这四个select事件</span><br><span class="line">s-&gt;addSelectable(m_selectableChannel.get());</span><br><span class="line">s-&gt;addSelectable(m_restartQuery.get());</span><br><span class="line">s-&gt;addSelectable(m_flexCounter.get());</span><br><span class="line">s-&gt;addSelectable(m_flexCounterGroup.get());</span><br></pre></td></tr></table></figure>

<h1 id="对于某一具体功能的下发"><a href="#对于某一具体功能的下发" class="headerlink" title="对于某一具体功能的下发"></a>对于某一具体功能的下发</h1><p>此处以IP Tunnel的创建为例。在swss docker中执行<code>swssconfig ipinip.json</code>，在<code>orchagent</code>这边大致流程为：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;orchdaemon.cpp 中会调用每一功能模块中的doTask任务</span><br><span class="line">TunnelDecapOrch *tunnel_decap_orch &#x3D; new TunnelDecapOrch(m_applDb, APP_TUNNEL_DECAP_TABLE_NAME);</span><br><span class="line"> m_orchList &#x3D; &#123; …… gIntfsOrch, gNeighOrch, gRouteOrch, copp_orch, tunnel_decap_orch, qos_orch, ……&#125;;</span><br><span class="line">for (Orch *o : m_orchList)</span><br><span class="line">             o-&gt;doTask();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;tunneldecaporch.cpp</span><br><span class="line">if (addDecapTunnel(key, tunnel_type, ip_addresses, p_src_ip, dscp_mode, ecn_mode, encap_ecn_mode, ttl_mode))</span><br><span class="line">&#123;</span><br><span class="line">    SWSS_LOG_NOTICE(&quot;Tunnel(s) added to ASIC_DB.&quot;);</span><br><span class="line">&#125;</span><br><span class="line">status &#x3D; sai_tunnel_api-&gt;create_tunnel(&amp;tunnel_id, gSwitchId, (uint32_t)tunnel_attrs.size(), tunnel_attrs.data());</span><br><span class="line">&#x2F;&#x2F; 给每一ip创建一个decap tunnel entry</span><br><span class="line">if (!addDecapTunnelTermEntries(key, dst_ip, tunnel_id))</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 将tunnel_term写入到ASIC DB中</span><br><span class="line">sai_status_t status &#x3D; sai_tunnel_api-&gt;create_tunnel_term_table_entry(&amp;tunnel_term_table_entry_id, gSwitchId, (uint32_t)tunnel_table_entry_attrs.size(), tunnel_table_entry_attr    s.data());  </span><br><span class="line">SWSS_LOG_NOTICE(&quot;Created tunnel entry for ip: %s&quot;, ip.c_str());</span><br></pre></td></tr></table></figure>

<p><code>syncd</code>的mainloop中接收到通知，进行处理：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;syncd.cpp</span><br><span class="line">processEvent(*m_selectableChannel.get());</span><br><span class="line"></span><br><span class="line">processSingleEvent(kco);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; create，remove，set，get都是使用这一个API，大概这就是quard的意思吧</span><br><span class="line">return processQuadEvent(SAI_COMMON_API_CREATE, kco);</span><br></pre></td></tr></table></figure>

<p>我们创建的是IP tunnel的解封装规则，对应的sai objtype是<code>SAI_OBJECT_TYPE_TUNNEL_TERM_TABLE_ENTRY</code>.</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#x2F;&#x2F;syncd.cpp</span><br><span class="line">&#x2F;&#x2F; 获取参数列表</span><br><span class="line">auto&amp; values &#x3D; kfvFieldsValues(kco);</span><br><span class="line">sai_attribute_t *attr_list &#x3D; list.get_attr_list();</span><br><span class="line">uint32_t attr_count &#x3D; list.get_attr_count();</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 获取type对应的info数据，isnonobjectid是false</span><br><span class="line">auto info &#x3D; sai_metadata_get_object_type_info(metaKey.objecttype);</span><br><span class="line"></span><br><span class="line">status &#x3D; processOid(metaKey.objecttype, strObjectId, api, attr_count, attr_list);</span><br><span class="line"> </span><br><span class="line">return processOidCreate(objectType, strObjectId, attr_count, attr_list);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 调用vendorSai中的create方法</span><br><span class="line">sai_status_t status &#x3D; m_vendorSai-&gt;create(objectType, &amp;objectRid, switchRid, attr_count, attr_list);</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F;在VendorSai.cpp中是create方法的实现</span><br><span class="line">&#x2F;&#x2F; 根据objecttype获取info结构</span><br><span class="line">auto info &#x3D; sai_metadata_get_object_type_info(objectType);</span><br><span class="line">&#x2F;&#x2F; 调用infor中的create方法</span><br><span class="line">auto status &#x3D; info-&gt;create(&amp;mk, switchId, attr_count, attr_list);</span><br><span class="line">&#x2F;&#x2F;tunnel term的create方法在saimetadata.c中</span><br><span class="line">sai_metadata_generic_create_SAI_OBJECT_TYPE_TUNNEL_TERM_TABLE_ENTRY</span><br><span class="line"></span><br><span class="line">&#x2F;&#x2F; 最后是发送通知信息给swss</span><br><span class="line">sendApiResponse(api, status);</span><br></pre></td></tr></table></figure>

<h1 id="关于Tunnelmgrd"><a href="#关于Tunnelmgrd" class="headerlink" title="关于Tunnelmgrd"></a>关于Tunnelmgrd</h1><p><code>swss</code>中有一类进程以<code>*mgrd</code>结尾，它们干的活是将APP_DB中的数据同步到linux kernel，sonic中的一些配置是通过写APP_DB来完成的，<code>orchagent</code>完成<code>ASIC</code>的下发，<code>*mgrd</code>完成kernel的同步。</p>
<p>当然也有与之相反的配置流程，如路由的下发，<code>zebra</code>将路由信息下发到kernel，同时发送一份信息到<code>Fpmsyncd</code>，<code>Fpmsyncd</code>将其写到<code>APP_DB</code>,最后<code>orchagent</code>将其下发到<code>ASIC</code>.</p>
<p>上面两种方式的本质就是<code>kernel</code>和<code>ASIC</code>之间配置的同步。</p>
]]></content>
      <tags>
        <tag>SONiC</tag>
        <tag>syncd</tag>
      </tags>
  </entry>
  <entry>
    <title>NAT简述及仿真实验</title>
    <url>/2021/09/29/NAT%E7%AE%80%E8%BF%B0%E5%8F%8A%E4%BB%BF%E7%9C%9F%E5%AE%9E%E9%AA%8C/</url>
    <content><![CDATA[<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

<ul>
<li><a href="#%E5%85%B3%E4%BA%8Enat%E7%9A%84%E4%B8%80%E4%BA%9B%E5%9F%BA%E6%9C%AC%E9%97%AE%E9%A2%98">关于NAT的一些基本问题</a><ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AFnat">什么是NAT?</a></li>
<li><a href="#nat%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%96%B9%E5%BC%8F">NAT的工作方式</a></li>
<li><a href="#nat%E7%9A%84%E5%BC%8A%E7%AB%AF%E5%8F%8A%E5%A4%84%E7%90%86%E6%96%B9%E5%BC%8F">NAT的弊端及处理方式</a><ul>
<li><a href="#alg">ALG</a></li>
<li><a href="#icmp%E6%8A%A5%E6%96%87%E7%9A%84%E7%89%B9%E6%AE%8A%E5%A4%84%E7%90%86">ICMP报文的特殊处理</a></li>
<li><a href="#ip%E5%88%86%E7%89%87%E7%9A%84%E7%89%B9%E6%AE%8A%E5%A4%84%E7%90%86">IP分片的特殊处理</a><span id="more"></span></li>
</ul>
</li>
</ul>
</li>
<li><a href="#nat%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%9E%8B">NAT的基本工作模型</a><ul>
<li><a href="#%E4%BC%A0%E7%BB%9Fnat">传统NAT</a><ul>
<li><a href="#%E5%9F%BA%E6%9C%AC%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2basic-nat">基本地址转换(Basic NAT)</a></li>
<li><a href="#naptnetwork-address-port-translation">NAPT(network address port translation)</a></li>
<li><a href="#%E5%85%B3%E4%BA%8E%E9%9D%99%E6%80%81nat%E5%92%8C%E5%8A%A8%E6%80%81nat">关于静态NAT和动态NAT</a></li>
</ul>
</li>
<li><a href="#bi-directional-nat-or-two-way-nat">Bi-directional NAT or Two-Way NAT</a></li>
<li><a href="#twice-nat">Twice NAT</a></li>
</ul>
</li>
<li><a href="#nat%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BA%94%E7%94%A8%E6%96%B9%E6%A1%88">NAT的一些应用方案</a><ul>
<li><a href="#nat%E7%9A%84%E5%8F%8C%E7%83%AD%E6%9C%BA%E5%A4%87%E4%BB%BDnat%E5%A4%9A%E5%87%BA%E5%8F%A3%E7%AD%96%E7%95%A5">NAT的双热机备份/NAT多出口策略</a></li>
<li><a href="#nat%E7%A9%BF%E8%B6%8A%E6%8A%80%E6%9C%AF">NAT穿越技术</a></li>
<li><a href="#nat%E4%B8%8Evpn">NAT与VPN</a></li>
<li><a href="#nat%E4%B8%8E%E8%B7%AF%E7%94%B1%E7%9A%84%E5%85%B3%E7%B3%BB%E5%8F%8A%E4%B8%80%E4%BA%9B%E5%A4%84%E7%90%86%E7%BB%86%E8%8A%82">NAT与路由的关系及一些处理细节</a></li>
<li><a href="#sonic%E4%B8%ADnat%E7%9A%84%E5%AE%9E%E7%8E%B0">SONiC中NAT的实现</a></li>
<li><a href="#nat-ptv4v6%E5%9C%B0%E5%9D%80%E8%BD%AC%E6%8D%A2">NAT-PT(V4/V6地址转换)</a></li>
</ul>
</li>
<li><a href="#gns3%E4%B8%8Anat%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%AE%9E%E9%AA%8C">GNS3上NAT的基本实验</a><ul>
<li><a href="#%E9%9D%99%E6%80%81nat%E5%AE%9E%E9%AA%8C">静态NAT实验</a></li>
<li><a href="#%E5%8A%A8%E6%80%81nat%E5%AE%9E%E9%AA%8C">动态NAT实验</a></li>
<li><a href="#pat%E5%AE%9E%E9%AA%8C">PAT实验</a></li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li>
</ul>
<!-- END doctoc generated TOC please keep comment here to allow auto update -->

<h1 id="关于NAT的一些基本问题"><a href="#关于NAT的一些基本问题" class="headerlink" title="关于NAT的一些基本问题"></a>关于NAT的一些基本问题</h1><p>本文旨在对NAT有一个全局的了解，包括NAT技术的起因，技术的实现方式以及应用场景，技术存在的缺点以及解决方式，最后以几个基本的实验进行验证收尾，对于某些复杂的应用场景或技术细节，会简述而不深究，这些等到真实的应用中去打磨。</p>
<h2 id="什么是NAT"><a href="#什么是NAT" class="headerlink" title="什么是NAT?"></a>什么是NAT?</h2><p>NAT的名字很准确，Network Address Translator(网络地址转换)，就是替换私网IP报文头部的地址信息，从而提供公网可达性和上层协议的连接能力。按照rfc2663的说法，NAT是从一个IP地址范围映射到另一个范围的方法，很显然，这种说法更加概括<br>NAT的使用场景：</p>
<ul>
<li>私网到公网的翻译</li>
<li>重叠地址之间的翻译</li>
<li>保护内网IP设备</li>
</ul>
<p>关于私网，RFC1918规定了三个保留地址段落：10.0.0.0-10.255.255.255；172.16.0.0-172.31.255.255；192.168.0.0-192.168.255.255。</p>
<h2 id="NAT的工作方式"><a href="#NAT的工作方式" class="headerlink" title="NAT的工作方式"></a>NAT的工作方式</h2><p>NAT功能在网络出口路由器上使能，在报文离开私网进入公网时，将源IP替换为公网IP，报文从公网进入私网时，做相反的替换。NAT处理报文的几个关键特点：</p>
<ul>
<li>网络被分为私网和公网两个部分，NAT网关设置在私网到公网的路由出口位置，双向流量必须都经过NAT网关</li>
<li>NAT网关在两个访问方向上完成两次地址转换，出方向上做源信息替换，入方向上做目的地址替换</li>
<li><em>NAT网关的存在对通信双方是透明的</em>(这是NAT致力于达到的，但做的不好，因为有些上层协议会在内部携带IP地址信息)</li>
<li>NAT网关为了实现双向翻译，需要维护一张关联表，把会话信息记录下来</li>
</ul>
<h2 id="NAT的弊端及处理方式"><a href="#NAT的弊端及处理方式" class="headerlink" title="NAT的弊端及处理方式"></a>NAT的弊端及处理方式</h2><p>NAT缓解公网IP不够用的同时带来了一些不好的影响，需要通过另一些技术去解决。</p>
<ul>
<li>NAT无法做到透明传输，ALG技术来解决</li>
<li>NAT破环了IP协议架构端到端的通信模型，破坏了节点在通讯中的对等地位。NAT穿透技术进行解决</li>
<li>NAT使IP会话的时效变短，因为IP和端口资源有限，而通信的需求无限，NAT网关会对关联表进行老化操作(特别是UDP通信)，这可能会导致用户可感知的连接中断，通过上层协议设置连接保活机制来解决</li>
<li>使依赖IP进行主机跟踪的机制失效，如：基于用户行为的日志分析，基于IP的用户授权，服务器连接设置同一时间只接收同一IP的有限访问，总之NAT屏蔽了通信的一端，把简单的事情复杂化了</li>
<li>ICMP复用和解复用需要特殊处理，如果ICMP payload无法提供足够信息，解复用会失败</li>
<li>IP分片，因为只有第一个分片有传输层信息，NAT很难识别后续分片与关联表的对应关系，需要特殊处理</li>
</ul>
<h3 id="ALG"><a href="#ALG" class="headerlink" title="ALG"></a>ALG</h3><p>NAT工作在L3和L4，ALG(application level gateways)是用以解决NAT对应用层无感知的常用方式。NAT网关基于传输层端口信息来识别连接是否为已知的应用类型，在识别为已知应用时，会对其报文内容进行检查，当发现任何形式表达的IP地址和端口时，会把这些信息同步转换。</p>
<p>但是，应用层协议很多而且在不断变化，而设备中的ALG都是针对特定协议特定版本开发的，尽管Linux允许动态加载ALG特性，其管理维护成本依然很高。因此，ALG只能解决常用的用户需求，而且，有些报文从源端发出就已经加密，ALG也无能为力。</p>
<h3 id="ICMP报文的特殊处理"><a href="#ICMP报文的特殊处理" class="headerlink" title="ICMP报文的特殊处理"></a>ICMP报文的特殊处理</h3><p>NAT网关通常采用五元组进行NAT映射，即源地址、源端口、IP协议类型、目的地址、目的端口。ICMP报文直接承载在IP报文之上，没有L4信息。以ping为例，对于ICMP请求报文，TYPE+CODE字段作为源端口，identifier作为目的端口记录，反之亦然。windows上发出的ICMP报文identifier字段全部是0x0400，处理上有些差别。<br>这段话来自华三的《NAT专题》，在思科的c3600上实验时，发现其只使用identifier标识一个ICMP会话，即ICMP的src port和dst port都是identifier的值。这里表示理解，只要NAT设备能够区别出不同内部主机发的报文即可，具体实现厂家可能有所差异。</p>
<h3 id="IP分片的特殊处理"><a href="#IP分片的特殊处理" class="headerlink" title="IP分片的特殊处理"></a>IP分片的特殊处理</h3><p>当进行IP分片时，这些信息只有首片报文会携带(只有首片中有端口号，只有首片中有icmp的identifier)，后续分片报文依靠报文ID、分片标志位、分片偏移量依次关联到前一个分片。在PAT转换类型中，除了对IP地址进行处理，还会处理L4的端口号，ICMP报文头中的identifier字段信息。因此，除首片外的报文无法进行转换，需要特殊处理，有两种方式：</p>
<ul>
<li>先缓存，等所有报文到达后，进行虚拟重组，再进行NAT转换，将转换后的报文再顺序发出</li>
<li>在首片到达并转换后，保存转换首片使用的IP以及identifier信息，在后续分片到达后使用同样表项进行转换。</li>
</ul>
<h1 id="NAT的基本工作模型"><a href="#NAT的基本工作模型" class="headerlink" title="NAT的基本工作模型"></a>NAT的基本工作模型</h1><p>NAT是网络地址转换的总称，基于不同的应用场景它有不同的配置。大的分类上可以分为传统NAT和two-way NAT以及twice NAT。</p>
<h2 id="传统NAT"><a href="#传统NAT" class="headerlink" title="传统NAT"></a>传统NAT</h2><p>传统NAT只能由内网主机发起通信，是单向的。传统NAT有两种实现。</p>
<h3 id="基本地址转换-Basic-NAT"><a href="#基本地址转换-Basic-NAT" class="headerlink" title="基本地址转换(Basic NAT)"></a>基本地址转换(Basic NAT)</h3><p>NAT设备拥有多个公网ip，数量远少于内网主机的数量，当有内网主机访问外网时分配公网ip，访问结束时释放。NAT设备拥有公网IP地址的数目，应该根据网络高峰可能访问外网的内网主机数目的统计值来确定。</p>
<p>上面这段话是对rfc2663 4.1.1章节的一个翻译，结合实际的应用，Basic NAT就是只进行IP地址转换的NAT模式。</p>
<h3 id="NAPT-network-address-port-translation"><a href="#NAPT-network-address-port-translation" class="headerlink" title="NAPT(network address port translation)"></a>NAPT(network address port translation)</h3><p>一个外网地址可以同时分配给多个内网地址公用。该模式下，NAPT会转换源IP，源端口以及相关的ip，tcp/udp和icmp的header checksums.转换的id可以是 tcp/udp的端口号或者icmp的query ID。其转换的基本原理可形容为：<br>(iAddr;iPort) &lt;——&gt; (eAddr; ePort)<br>与此相关可称之为PAT(port address translation)模式，NAT使用最多的模式就是PAT模式。相反的不使用port进行地址转换称为NO-PAT(not port address translation)，而NAPT根据是否关心对端的信息可以分为下面两种：</p>
<ol>
<li><p>endpoint-independent mapping(不关心对端地址和端口的转换模式)<br>NAT设备通过建立三元组(源地址、源端口号、协议类型)表项来进行地址分配和报文过滤。即，只要来自相同源地址和源端口号的报文，不论其目的地址是否相同，通过NAPT映射后，其源地址和源端口号都被转换成同一个外部地址和端口号，并且NAT设备允许外部网络的主机通过该转换后的地址和端口来访问这些内部网络的主机。这种模式可以很好的支持位于不同NAT设备之后的主机进行互访。</p>
</li>
<li><p>address and port-dependent mapping(关心对端地址和端口转换模式)<br>NAT设备通过建立五元组(源地址、源端口号、协议类型、目的地址、目的端口号)进行地址分配和报文过滤。即，对于来自相同源地址和源端口号的报文，若其目的地址和目的端口号不同，通过NAPT映射后，会被转换成不同的外部地址和端口号，并且NAT设备只允许这些目的地址对应的外部网络的主机才可以访问对应的内部主机。这种模式安全性好，但是不便于位于不同NAT设备之后的主机间的互访。</p>
</li>
</ol>
<p>而通过对外部主机地址+端口的限制，又可以分为：</p>
<ul>
<li>全锥形：对于inbound,只要NAT表项中存在，不关心src ip</li>
<li>限制锥形：对于inbound, 关心src ip</li>
<li>端口限制锥形: 对于inbound, 关心src ip + src port</li>
<li>对称形: 对于outbound和inbound, 只有src ip, src port, dst ip, dst port完全一致才认为是一个会话，否则创建新的表项<br>这些都是本质是NAT的应用，更加细粒度的进行控制过滤，是NAT的一种工作方式, 可以称之为<em>policy NAT</em>。</li>
</ul>
<h3 id="关于静态NAT和动态NAT"><a href="#关于静态NAT和动态NAT" class="headerlink" title="关于静态NAT和动态NAT"></a>关于静态NAT和动态NAT</h3><p>这是另一种分类方式，静态NAT即内外网地址信息静态绑定，是一一映射，这种很少使用，可用来隐藏私网ip和重叠地址网络的通信。动态NAT则是使用外网地址池，有资源回收机制，这种用法也少，地主家也不能买这么多公网IP地址。</p>
<h2 id="Bi-directional-NAT-or-Two-Way-NAT"><a href="#Bi-directional-NAT-or-Two-Way-NAT" class="headerlink" title="Bi-directional NAT or Two-Way NAT"></a>Bi-directional NAT or Two-Way NAT</h2><p>外部网络能够有主动访问内网主机的机会，如给外网提供一台Web服务器，或是一台FTP服务器。实现双向NAT的关键在于DNS-ALG的引入，借助DNS-ALG,实现处于不同网络中的主机直接通过域名来相互访问。<br>静态NAT一般就是双向NAT.</p>
<h2 id="Twice-NAT"><a href="#Twice-NAT" class="headerlink" title="Twice NAT"></a>Twice NAT</h2><p>相对于traditional NAT和bi-directional NAT中NAT设备只会对报文的源或者目的进行修改，twice NAT则对报文的src/dst同时进行修改。例如当外网主机使用的外网的ip已经分配给别的组织地址，这时需要将dst也改掉。这种方式常用于支持内网用户主动访问与之地址重叠(overlap)的外网资源。</p>
<p>当内网主机A向外网主机B发起通信时，但是内网中有主机D使用的是和B一样的IP地址（如之前ISP分配的，现在收回了；如同一公司的异地组网），如果A直接和B进行通信，那么报文会转发给D。A 通过发送DNS请求B的ip，DNS-ALG接收到之后给其分配一个可路由的内网地址C，现在A向C通信，NAT设备收到之后，对于src ip,按传统NAT转换，对于dest ip，将地址C改为B的地址，发给外网，收到之后，反之亦然。<br>Twice NAT would not be allowed to advertise local networks to the external network or vice versa.</p>
<p>NAT可分为SNAT、DNAT和twice NAT, 对于inside——&gt;outside的流量，做SNAT，对于outside——&gt;inside的流量，做DNAT。</p>
<h1 id="NAT的一些应用方案"><a href="#NAT的一些应用方案" class="headerlink" title="NAT的一些应用方案"></a>NAT的一些应用方案</h1><h2 id="NAT的双热机备份-NAT多出口策略"><a href="#NAT的双热机备份-NAT多出口策略" class="headerlink" title="NAT的双热机备份/NAT多出口策略"></a>NAT的双热机备份/NAT多出口策略</h2><p>与出口网关一样，NAT存在单点故障的问题。进行双热机备份当然是很好的方式。双热机备份分为对称式和非对称式，对称式即进出流量只能走相同的设备，非对称式则没有这个要求，可以进行负载均衡。这里简单列举一下对称式的实现方式：</p>
<ul>
<li>利用VRRP实现流量切换</li>
<li>利用动态路由实现流量切换</li>
</ul>
<h2 id="NAT穿越技术"><a href="#NAT穿越技术" class="headerlink" title="NAT穿越技术"></a>NAT穿越技术</h2><p>这里只是插个眼，不做深入研究，NAT穿越技术有：</p>
<ul>
<li>ALG</li>
<li>探针技术STUN与TURN</li>
<li>中间件技术</li>
<li>中继代理技术</li>
<li>特定协议的自穿越技术</li>
</ul>
<h2 id="NAT与VPN"><a href="#NAT与VPN" class="headerlink" title="NAT与VPN"></a>NAT与VPN</h2><p>常见的VPN有：GRE、L2TP、IPsec、SSL VPN等。NAT在工作过程中会修改L3和L4的信息，在分析VPN与NAT共存时，首先需要分析该VPN隧道的封装方式，看有没有传输层端口，其次要分析VPN隧道的协商过程中是否使用报文的IP地址。具体分析在这里不展开了，说个结论：SSL VPN与L2TP VPN与NAT可以天然共存，IPsec VPN在部分模式下可与NAT共存，而GRE无法穿越NAT.</p>
<h2 id="NAT与路由的关系及一些处理细节"><a href="#NAT与路由的关系及一些处理细节" class="headerlink" title="NAT与路由的关系及一些处理细节"></a>NAT与路由的关系及一些处理细节</h2><p>对cisco的实现，参见下图：<br><img src="https://rancho333.github.io/pictures/cisco_nat_seq.png"><br>对于inside-&gt;outside的流量，NAT转化发生在routing之后；对于outside-&gt;inside的流量，NAT转换发生在路由之前.所以自cisco的实现中，NAT与路由的关系只取决于流量的方向，通过inside/outside修饰接口分割出两个区域，通过source/dest表明流量的方向。</p>
<p>Cisco会在特定的时间将“一条NAT映射策略”安装到系统的inside NAT表或者outside NAT表中，对于从网口进入的数据包，会根据网口是inside还是outside去匹配inside NAT表或者outside NAT表中的NAT规则，仅此而已。不管是inside NAT表还是outside NAT表，都各有两张，一张是SNAT表，另一张是DNAT表。对于每一个数据包，都要用源IP地址去查询SNAT表，用目标IP地址去查询DNAT表。这在下面的静态NAT实验中将有很好的体现。</p>
<p>对Linux的实现，参见下图：<br><img src="https://rancho333.github.io/pictures/linux_nat_seq.jpg"><br>Linux中并没有将NAT应用于接口的说法，NAT的配置是全局的。此时接口就是一个match，写match/target去匹配执行就好。SNAT位于post-routing域，DNAT位于pre-routing域。SNAT指的是内网发往外网的流量修改src ip, DNAT指的是外网发往内网的流量修改dest ip。Linux中的NAT是基于五元组的，也就是NAT结果和一个流(conntrack)关联在一起。</p>
<p>Linux的nat中，待转换的IP地址是一个match，因此不管是一对一的转换还是一对多的转换，原理都是一样的。Linux并不区分静态转换和动态转换。在内核中，永远都不会出现所谓的NAT映射表，iptables添加的NAT规则不会生成映射，数据包进入匹配nat成功，也不会生成映射，nat结果仅仅存在于conntrack中作为tuple的一部分体现。</p>
<p>Linux的nat查询对于第一个包是逐条匹配iptables nat表规则，对于后续的包，则转化为针对五元组的conntrack哈希查询。</p>
<p>借用一下SONiC中对NAT的配置：<br><img src="https://rancho333.github.io/pictures/sonic_nat_config.png"><br>命令行里面默认的NAT类型是dnat，这里不理解，等待后续使用去验证。这个NAT条目只有外网发到内网的流量才会触发呀？这不符合NAT使用最多的场景呀！</p>
<p>思科强调使用者得使用域，Linux强调技术本身的合理性.</p>
<h2 id="SONiC中NAT的实现"><a href="#SONiC中NAT的实现" class="headerlink" title="SONiC中NAT的实现"></a>SONiC中NAT的实现</h2><p><a href="https://github.com/Azure/SONiC/blob/master/doc/nat/nat_design_spec.md">SONiC中NAT</a>是SONiC对NAT的设计文档。鉴于TH4不支持NAT，SONiC的上NAT的实验后续再进行。</p>
<h2 id="NAT-PT-V4-V6地址转换"><a href="#NAT-PT-V4-V6地址转换" class="headerlink" title="NAT-PT(V4/V6地址转换)"></a>NAT-PT(V4/V6地址转换)</h2><p>IPv4与IPv6的过渡技术有双栈、隧道和翻译。其中翻译就是使用的NAT-PT技术。这里插个眼，后续有需要在深入。</p>
<h1 id="GNS3上NAT的基本实验"><a href="#GNS3上NAT的基本实验" class="headerlink" title="GNS3上NAT的基本实验"></a>GNS3上NAT的基本实验</h1><p>以上都是看的一些文档资料，实验看看效果才好，实验环境为GNS3+c3600，做三个基本场景的实验：</p>
<ul>
<li>静态NAT实验</li>
<li>动态NAT实验</li>
<li>PAT实验</li>
</ul>
<h2 id="静态NAT实验"><a href="#静态NAT实验" class="headerlink" title="静态NAT实验"></a>静态NAT实验</h2><p>基本命令为<code>ip nat inside static a b</code>, 系统会将a——&gt;b的源地址转换加入到inside的SNAT表中，同时将b——&gt;a的目的地址转换加入到outside的DNAT表中。针对后面所有的数据包，不管是内部发起的，还是外部发起的，都会根据接口使能的inside nat还是outside nat来查表匹配。<br>拓扑图如下：<br><img src="https://rancho333.github.io/pictures/topo_nat.png"><br>配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">R1:</span><br><span class="line">interface Ethernet0&#x2F;0</span><br><span class="line"> ip address 192.168.1.2 255.255.255.0</span><br><span class="line">router ospf 1</span><br><span class="line"> network 192.168.1.0 0.0.0.255 area 0</span><br><span class="line"></span><br><span class="line">R2:</span><br><span class="line">interface Ethernet0&#x2F;0</span><br><span class="line"> ip address 192.168.1.1 255.255.255.0</span><br><span class="line"> ip nat inside</span><br><span class="line">interface Ethernet0&#x2F;1</span><br><span class="line"> ip address 202.100.10.1 255.255.255.0</span><br><span class="line"> ip nat outside</span><br><span class="line">router ospf 1</span><br><span class="line"> network 192.168.1.0 0.0.0.255 area 0</span><br><span class="line"> network 202.100.10.0 0.0.0.255 area 0</span><br><span class="line">ip nat inside source static 192.168.1.2 202.100.10.3</span><br><span class="line"></span><br><span class="line">R3:</span><br><span class="line">interface Ethernet0&#x2F;1</span><br><span class="line"> ip address 202.100.10.2 255.255.255.0</span><br><span class="line">router ospf 1</span><br><span class="line"> network 202.100.10.0 0.0.0.255 area 0</span><br></pre></td></tr></table></figure>
<p>在R1上ping R3，分别在R2的左右两侧进行抓包，左侧为NAT之前的报文：<br><img src="https://rancho333.github.io/pictures/before_nat.png"><br>右侧为NAT之后的报文，发现src ip已经发生改变：<br><img src="https://rancho333.github.io/pictures/after_nat.png"></p>
<p>注意我们只配置了<code>ip nat inside source</code>, 即我们只在inside接口上使能了SNAT，但是对于R4返回的数据包，是在outside接口上做DNAT，我们并没有做这个配置，这是因为cisco自动进行了这种关联，在命令行中我们也会发现cisco在outside上只有<code>ip nat outside source</code>。从NAT转换表中我们也可以看出这种自动关联的动作。<br><img src="https://rancho333.github.io/pictures/inside_source.png"><br>在ping动作之前，表中其实只有第二行，第一行的icmp是ping之后流量触发时建立，发现多了outside global和outside local字段。</p>
<p><code>ip nat outside source</code>表示从outside发往inside的报文做SNAT。进一步的总结下，cisco NAT的四种类型：</p>
<ol>
<li>从inside到outside时做SNAT</li>
<li>从inside到outside时做DNAT</li>
<li>从outside到inside时做SNAT</li>
<li>从outside到inside时做DNAT<br>其中1,4是成对的，2,3是成对的。即配1了4会自动部署，配3了2会自动部署，验证一下2,3的成对关系：<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip nat outside source static 202.100.10.2 192.168.1.3</span><br></pre></td></tr></table></figure>
然后使用R3 ping R1，抓包结果为：<br><img src="https://rancho333.github.io/pictures/outside_ping.png"><br>可以看到R1给192.168.1.3回了icmp reply报文，但是R3并没有收到地址转换后的报文。</li>
</ol>
<p>NAT表项转换为：<br><img src="https://rancho333.github.io/pictures/outside_dest.png"><br>同样第一行为我们配置的，第二行为流量触发的，可以发现增加了<code>inside local</code>和<code>inside local</code></p>
<p>这里需要结合cisco中NAT与路由的关系来回答这个问题：<br>显然这里是步骤<code>2</code>出了问题，inside-&gt;outside流量是在路由之后完成的，即R1给R3的icmp reply报文是针对192.168.1.3做的路由，R3自然收不到报文<br>所以需要在R2上配置一条静态路由：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip route 192.168.1.3 255.255.255.255 202.100.10.2</span><br></pre></td></tr></table></figure>
<p>或者在outside上面配置source时添加add-route选项：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">ip nat outside source static 202.100.10.2 192.168.1.3 add-route # add-route会给prefix 192.168.1.3添加next-hop为202.100.10.2</span><br></pre></td></tr></table></figure>
<p><em>说明一下：这里的SNAT单纯表示替换source ip，DNAT单纯表示替换dest ip，SNAT和DNAT在Linux中与路由的关系在这里不适用</em></p>
<h2 id="动态NAT实验"><a href="#动态NAT实验" class="headerlink" title="动态NAT实验"></a>动态NAT实验</h2><p>对于动态NAT，配置完命令后系统不会添加任何NAT规则只有当某一个包匹配到了ACL，要引发NAT时，系统会动态的从pool中选取一个要转换的IP地址，加入到inside的SNAT表项中，同时针对反方向的目的地址转换规则将其加入到outside的DNAT表项中。<br>因此，cisco的动态NAT是单向的，因为反向的数据包进入时不会匹配到ACL，不会引发NAT规则，也就不会生成任何NAT表项。在此例中，如果R3先ping R1是不通的，必须先让R1 ping R3生成NAT表项后，双方才能互通。</p>
<p>实验拓扑图如下：<br><img src="https://rancho333.github.io/pictures/topo_d_nat.png"></p>
<p>本次实验通过配置一个NAT地址池，让R1、R4与R3通信时发生NAT转换。设备配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">R1：</span><br><span class="line">interface Ethernet0&#x2F;0</span><br><span class="line"> ip address 192.168.1.2 255.255.255.0</span><br><span class="line">ip route 0.0.0.0 0.0.0.0 192.168.1.1            #R1模拟私网主机，配置网关</span><br><span class="line"></span><br><span class="line">R2:</span><br><span class="line">interface Ethernet0&#x2F;0</span><br><span class="line"> ip address 192.168.1.1 255.255.255.0</span><br><span class="line"> ip nat inside                  # 配置NAT inside域</span><br><span class="line">interface Ethernet0&#x2F;1</span><br><span class="line"> ip address 202.100.10.1 255.255.255.0</span><br><span class="line"> ip nat outside                 # 配置NAT outside域</span><br><span class="line">interface Ethernet0&#x2F;2</span><br><span class="line"> ip address 192.168.2.1 255.255.255.0</span><br><span class="line"> ip nat inside                  # 配置NAT inside域</span><br><span class="line">ip nat pool rancho-test 202.100.10.3 202.100.10.10 prefix-length 24   # 设置NAT地址池</span><br><span class="line">ip nat inside source list 1 pool rancho-test                          # 设置地址池与ACL的映射  </span><br><span class="line">access-list 1 permit 192.168.2.2                                      # 设置ACL规则，标准acl只匹配source</span><br><span class="line">access-list 1 permit 192.168.1.2                                    </span><br><span class="line">access-list 1 deny any</span><br><span class="line"></span><br><span class="line">R3：</span><br><span class="line">interface Ethernet0&#x2F;1</span><br><span class="line"> ip address 202.100.10.2 255.255.255.0</span><br><span class="line">ip route 0.0.0.0 0.0.0.0 202.100.10.1</span><br><span class="line"></span><br><span class="line">R4:</span><br><span class="line">interface Ethernet0&#x2F;2</span><br><span class="line"> ip address 192.168.2.2 255.255.255.0</span><br><span class="line">ip route 0.0.0.0 0.0.0.0 192.168.2.1</span><br></pre></td></tr></table></figure>

<p>在R2左右两侧抓包，对应为NAT转换前后的包，对于R1 ping R3的抓包：<br><img src="https://rancho333.github.io/pictures/r1_d_nat.png"><br>配置的NAT地址池从202.100.10.3开始，第一个命中NAT规则的分配start ip。</p>
<p>对于R4 ping R3的抓包：<br><img src="https://rancho333.github.io/pictures/r4_d_nat.png"><br>后续命中NAT规则的依次分配，对于192.168.2.2分配外网IP：202.100.10.4</p>
<p>在R2上查看生成的NAT转换表项(在ping之前为空，只有当命中ACL规则，触发NAT转换才会生成，这是和静态NAT表项的区别)：<br><img src="https://rancho333.github.io/pictures/nat_tran.png"><br>转换表项和抓包的对比是吻合的。</p>
<p>查看下R2上关于NAT的统计数据以及使能的NAT的配置：<br><img src="https://rancho333.github.io/pictures/nat_stat.png"></p>
<h2 id="PAT实验"><a href="#PAT实验" class="headerlink" title="PAT实验"></a>PAT实验</h2><p>复用<code>动态NAt实验</code>的拓扑和基本配置，只需要将<code>R2</code>上的NAT配置做一些修改，使R1、R4访问R3时使用R2上右侧端口的IP。R2上的配置修改如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">- ip nat pool rancho-test 202.100.10.3 202.100.10.10 prefix-length 24   # 设置NAT地址池</span><br><span class="line">- ip nat inside source list 1 pool rancho-test                          # 设置地址池与ACL的映射</span><br><span class="line">+ ip nat inside source list 1 interface Ethernet0&#x2F;1 overload            # ACL 1的流量复用 0&#x2F;1端口的IP地址</span><br></pre></td></tr></table></figure>
<p>同样在R2左右两侧抓包，对应PAT转换前后的包，对于R1 telnet R3，发出去的包为：<br><img src="https://rancho333.github.io/pictures/r1_pat_to.png"><br>R3对R1的返回包为：<br><img src="https://rancho333.github.io/pictures/r1_pat_from.png"></p>
<p>对于R4 telnet R3, 发出去的包为:<br><img src="https://rancho333.github.io/pictures/r4_pat_to.png"><br>R3对R4的返回包为：<br><img src="https://rancho333.github.io/pictures/r4_pat_from.png"></p>
<p>查看R2上的NAT转换表，与抓包内容符合：<br><img src="https://rancho333.github.io/pictures/pat_tran.png"></p>
<p>这里可以发现PAT转换前后src port并没有发生改变(直接使用的就是源TCP包中的port)，在命令里面也没有看到配置port范围的命令，不知道这是不是思科的特殊实现, 如果NAT设备发现相同的端口再处理？<em>此处存疑，思科肯定会有处理的方式</em></p>
<p>对于ICMP报文的特殊处理，以R1 ping R3为例，ICMP request报文为：<br><img src="https://rancho333.github.io/pictures/r1_pat_ping_to.png"><br>ICMP reply报文为：<br><img src="https://rancho333.github.io/pictures/r1_pat_ping_from.png"><br>R2上的NAT转换表为：<br><img src="https://rancho333.github.io/pictures/pat_tran_ping.png"><br>这里这看到在PAT模式中，NAT设备通过ICMP报文中的identifier字段来标识一个ICMP的NAT转换。</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://datatracker.ietf.org/doc/html/rfc2663">rfc2663</a><br><a href="https://datatracker.ietf.org/doc/html/rfc3022">rfc3022</a><br><a href="https://datatracker.ietf.org/doc/html/rfc4787">rfc4787</a><br><a href="https://blog.csdn.net/armlinuxww/article/details/113541634">彻底理解Cisco NAT内部的一些事</a><br><a href="http://www.h3c.com/cn/d_201904/1175248_30005_0.htm#_Toc7355633">H3C NAT配置</a><br><a href="https://www.firewall.cx/cisco-technical-knowledgebase/cisco-routers/260-cisco-router-nat-overload.html">CONFIGURING NAT OVERLOAD ON A CISCO ROUTER</a><br><a href="https://github.com/Azure/SONiC/blob/master/doc/nat/nat_design_spec.md#221-snat-and-dnat">SONiC NAT design</a></p>
]]></content>
      <tags>
        <tag>NAT</tag>
      </tags>
  </entry>
  <entry>
    <title>SONiC自动化编译简述</title>
    <url>/2021/10/08/SONiC%E8%87%AA%E5%8A%A8%E5%8C%96%E7%BC%96%E8%AF%91%E7%AE%80%E8%BF%B0/</url>
    <content><![CDATA[<h1 id="关于SONiC自动化编译"><a href="#关于SONiC自动化编译" class="headerlink" title="关于SONiC自动化编译"></a>关于SONiC自动化编译</h1><ul>
<li><p>当gitlab仓库有push动作时触发自动编译，仓库地址为：<a href="http://cshgitlab.cn-csh.celestica.com/sonic-sdk/brixia_sonic.git">http://cshgitlab.cn-csh.celestica.com/sonic-sdk/brixia_sonic.git</a></p>
<span id="more"></span></li>
<li><p>编译环境部署在泰国服务器，设备ip为：10.196.48.47</p>
</li>
<li><p>考虑网络问题以及SONiC编译偶尔会抽疯，编译失败后再次执行，5次失败后退出编译</p>
</li>
<li><p>镜像版本号为“SONiC.202012-brixia-时间-版本”，如“SONiC.202012-brixia-20210930-r4”，其中时间为当天编译时间，r后面的数字依次递增，r5,r6……</p>
</li>
<li><p>编译好的版本，命名规则为”sonic-broadcom-时间-版本.bin”，会自动推送到文件服务器：<a href="http://10.204.112.155:8081/sonic/brixia/">http://10.204.112.155:8081/sonic/brixia/</a></p>
</li>
<li><p>jenkins环境部署在：10.204.112.155:8080, 后续稳定后考虑迁移到testbed的环境，当前上面只有一个账号(rancho/123456)，有兴趣的同学请自行参观使用</p>
</li>
<li><p>针对不需要gitlab+jenkins的场景，提供shell脚本实现自动化编译，在自己家目录下执行 bash ~/auto_build.sh即可</p>
</li>
</ul>
<h1 id="自动化编译一些小问题"><a href="#自动化编译一些小问题" class="headerlink" title="自动化编译一些小问题"></a>自动化编译一些小问题</h1><ul>
<li><p>自动化编译每次均为全量编译，时间较长，加上从泰国服务器拷贝image，时间较长，如果是特性或编译临时版本，并不建议使用，推荐增量编译或模块化编译。</p>
</li>
<li><p>自动化编译只会编译基础SONiC镜像，debug版本或加特性(如syncd-rpc)不会在自动化编译中(主要考虑编译时间、传输时间、存储空间以及使用率)</p>
</li>
<li><p>自动化编译单次只会编译一个target，对于无依赖关系target不能并行处理，并行处理大概率会报错，需要手动纠错</p>
</li>
<li><p>jenkins在远程主机上执行shell命令使用的是SSH，该shell是非交互式非登录式shell，需要注意shell配置文件的加载以及环境变量的配置</p>
</li>
<li><p>在host上清除已经编译过的环境需要root权限(fsroot文件夹)，使用脚本中的b.out可以完成该操作<br>  修改Makefile, 在target中加入sonic-slave-run, 使用 <code>make sonic-slave-run SONIC_RUN_CMDS=&quot;rm -rf fsroot&quot;</code>删除不能删除的部分</p>
</li>
</ul>
]]></content>
      <tags>
        <tag>SONiC</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title>vrf简述及仿真实验</title>
    <url>/2021/10/20/vrf%E7%AE%80%E8%BF%B0%E5%8F%8A%E4%BB%BF%E7%9C%9F%E5%AE%9E%E9%AA%8C/</url>
    <content><![CDATA[<!-- START doctoc generated TOC please keep comment here to allow auto update -->
<!-- DON'T EDIT THIS SECTION, INSTEAD RE-RUN doctoc TO UPDATE -->

<ul>
<li><a href="#%E4%BB%80%E4%B9%88%E6%98%AFvrf">什么是VRF</a><ul>
<li><a href="#vrf%E7%9A%84%E4%BD%9C%E7%94%A8">vrf的作用</a></li>
</ul>
</li>
<li><a href="#vrf%E4%BB%BF%E7%9C%9F%E5%AE%9E%E9%AA%8C">VRF仿真实验</a><ul>
<li><a href="#vrf%E8%A7%A3%E5%86%B3%E5%9C%B0%E5%9D%80%E9%87%8D%E5%8F%A0--ip%E9%9A%94%E7%A6%BB">VRF解决地址重叠 &amp;&amp; IP隔离</a></li>
<li><a href="#vrf%E8%B7%AF%E7%94%B1%E9%9A%94%E7%A6%BB%E4%BB%A5%E5%8F%8A%E8%B7%AF%E7%94%B1%E6%B3%84%E9%9C%B2">VRF路由隔离以及路由泄露</a><ul>
<li><a href="#vrf%E8%B7%AF%E7%94%B1%E6%B3%84%E9%9C%B2%E5%AE%9E%E9%AA%8C%E5%A4%B1%E8%B4%A5">vrf路由泄露实验失败</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99">参考资料</a></li>
</ul>
<!-- END doctoc generated TOC please keep comment here to allow auto update -->
<span id="more"></span>

<h1 id="什么是VRF"><a href="#什么是VRF" class="headerlink" title="什么是VRF"></a>什么是VRF</h1><p>VRF(virtual routing and forwarding)是一种允许在单台路由器上有多个路由表的技术。VRFs的典型使用是与MPLS VPNs结合。没有使用MPLS的VRFs称为VRF lite.</p>
<p>在Linux上，VRF设备通过与ip规则结合在Linux网络栈中提供创建虚拟路由和转发的能力。一个典型的应用场景就是多租户各自需要独立的路由表，少数场景下需要不同的默认路由。</p>
<p>程序通过socket与不同的VRF设备绑定感知VRF。数据包通过socket使用与VRF设备相关的路由表。VRF设备实现的一个重要特征就是它只影响L3而对L2工具（比如LLDP）没有影响(它们是全局的而不必运行在每一个VRF域中).这种设计允许使用更高优先级的ip rules(policy based routing, PBR)优先于VRF设备规则，根据需要引导特定流量。此外，VRF设备允许VRFs嵌套在namespace中。namespace提供物理层的接口隔离，vlan提供L2的隔离，vrf提供L3的隔离。VRF设备是使用关联的路由表创建的。</p>
<p>简而言之，VRF在逻辑上将一个路由器模拟成多台路由器，是一种网络虚拟化技术,VRF是路由器的虚拟化，VLAN是交换机的虚拟化，trunk是对网络连接的虚拟化。VDOM(virtual domain)是防火墙的虚拟化, VM是服务器的虚拟化。</p>
<p>注意：一个L3接口同一时间只能属于一个VRF域</p>
<h2 id="vrf的作用"><a href="#vrf的作用" class="headerlink" title="vrf的作用"></a>vrf的作用</h2><p>两点：<br>    1. 流量隔离：隔离不同的vpn用户,解决地址重叠问题<br>    2. 网络虚拟化</p>
<h1 id="VRF仿真实验"><a href="#VRF仿真实验" class="headerlink" title="VRF仿真实验"></a>VRF仿真实验</h1><p>针对vrf的路由隔离和解决地址重叠这两个特性，在GNS3上面做两个简单的仿真实验。</p>
<h2 id="VRF解决地址重叠-amp-amp-IP隔离"><a href="#VRF解决地址重叠-amp-amp-IP隔离" class="headerlink" title="VRF解决地址重叠 &amp;&amp; IP隔离"></a>VRF解决地址重叠 &amp;&amp; IP隔离</h2><p>实验拓扑如下：<br><img src="https://rancho333.github.io/pictures/vrf_overlap_topo.png"><br>其中，R1、R2、R4、R5模拟主机，R3上面创建两个<code>vrf</code>域, R1、R2属于<code>vrf-2</code>, R4、R5属于<code>vrf-1</code>。实验预期是R1可以ping通R2，R4可以ping通R5。<br>5台设备的配置如下：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">R1&#x2F;R3:</span><br><span class="line">interface Ethernet0&#x2F;1</span><br><span class="line"> no shutdown</span><br><span class="line"> ip address 192.168.1.2 255.255.255.0</span><br><span class="line">ip route 0.0.0.0 0.0.0.0 192.168.1.1                # 模拟主机，配置网关</span><br><span class="line"></span><br><span class="line">R2&#x2F;R4:</span><br><span class="line">interface Ethernet0&#x2F;3</span><br><span class="line"> no shutdown</span><br><span class="line"> ip address 202.100.10.2 255.255.255.0</span><br><span class="line">ip route 0.0.0.0 0.0.0.0 202.100.10.1</span><br><span class="line"></span><br><span class="line">R3:</span><br><span class="line">ip vrf vrf-1                                        # 创建vrf-1</span><br><span class="line">!   </span><br><span class="line">ip vrf vrf-2                                        # 创建vrf-2</span><br><span class="line">!</span><br><span class="line">interface Ethernet0&#x2F;0</span><br><span class="line"> no shutdown</span><br><span class="line"> ip vrf forwarding vrf-1                            # 接口加入vrf-1</span><br><span class="line"> ip address 192.168.1.1 255.255.255.0</span><br><span class="line">!</span><br><span class="line">interface Ethernet0&#x2F;1</span><br><span class="line"> no shutdown</span><br><span class="line"> ip vrf forwarding vrf-2                            # 接口加入vrf-2</span><br><span class="line"> ip address 192.168.1.1 255.255.255.0</span><br><span class="line">!</span><br><span class="line">interface Ethernet0&#x2F;2</span><br><span class="line"> no shutdown</span><br><span class="line"> ip vrf forwarding vrf-1                            # 接口加入vrf-1</span><br><span class="line"> ip address 202.100.10.1 255.255.255.0</span><br><span class="line">!</span><br><span class="line">interface Ethernet0&#x2F;3</span><br><span class="line"> no shutdown</span><br><span class="line"> ip vrf forwarding vrf-2                            # 接口加入vrf-2</span><br><span class="line"> ip address 202.100.10.1 255.255.255.0</span><br></pre></td></tr></table></figure>
<p>查看R3的路由表：<br><img src="https://rancho333.github.io/pictures/vrf_overlap_route.png"><br>路由表结果与预期相符，默认路由表中没有内容，vrf-1和vrf-2中分别是各自接口的直连路由。</p>
<p>同时在R2和R5上抓包，在R1和R3上ping 202.100.10.2，发现只有在相同的vrf域中才能收到icmp(即R1可以ping通R2，R4可以ping通R5)，实验结果符合预期。</p>
<h2 id="VRF路由隔离以及路由泄露"><a href="#VRF路由隔离以及路由泄露" class="headerlink" title="VRF路由隔离以及路由泄露"></a>VRF路由隔离以及路由泄露</h2><p>VRF可以隔离不同VPN用户之间的路由，即可以实现L3层级的隔离，同时通过vrf-leak可以实现不同vrf之间的互通。路由隔离与泄露使用相同的拓扑：<br><img src="https://rancho333.github.io/pictures/vrf_separation_topo.png"><br>配置参照<code>VRF解决地址重叠</code>的实验，根据拓扑修改对应端口，以及模拟主机的4台路由器上修改默认网关即可。</p>
<p>查看R3上的路由表，默认路由表依然为空，这里就不看了：<br><img src="https://rancho333.github.io/pictures/vrf_separation_route.png"><br>VRF分别包含各自网段的路由。</p>
<p>在R2上分别ping R1和R4，结果如下：<br><img src="https://rancho333.github.io/pictures/r2_ping_separation.png"><br>R2可以ping通同一路由域中的R1，不能ping通其它路由域中的R4，实验结果符合预期。</p>
<h3 id="vrf路由泄露实验失败-后面有机会再搞吧-大概率是配置错了"><a href="#vrf路由泄露实验失败-后面有机会再搞吧-大概率是配置错了" class="headerlink" title="vrf路由泄露实验失败, 后面有机会再搞吧(大概率是配置错了)"></a>vrf路由泄露实验失败, 后面有机会再搞吧(大概率是配置错了)</h3><p>vrf的路由泄露有三种方向，分别为：</p>
<ul>
<li>默认vrf——&gt;vrf</li>
<li>vrf——&gt;vrf</li>
<li>vrf——&gt;默认vrf<br>默认vrf即为全局路由表。</li>
</ul>
<p>vrf-leak可以通过static和dynamic两种方式实现，在此进行static实验。修改配置进行vrf-leak实验，在R3上添加如下配置：</p>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">&#96;&#96;&#96;</span><br><span class="line"></span><br><span class="line"># SONiC test case of VRF</span><br><span class="line"></span><br><span class="line">基本问题描述：test case场景下，单个VRF中存在12.8K(6.4K的IPv4和6.4K的IPv6)路由条目，删除VRF时，一定时间内需要删除大量路由。里面有两个问题：</span><br><span class="line">  1. zebra的fpm client不能将所有数据同步给fpm server</span><br><span class="line">  2. 删除VRF中默认路由时出错</span><br><span class="line"></span><br><span class="line">## 创建VRF时需要关注的几个对象</span><br><span class="line">![](https:&#x2F;&#x2F;rancho333.github.io&#x2F;pictures&#x2F;vrf_about_obiects.png)</span><br><span class="line"></span><br><span class="line">注意：</span><br><span class="line">  1. 一个VRF中包含一个或多个L3 接口，创建接口会增加该VRF的reference count</span><br><span class="line">  2. 一个L3 接口上包含一个或多个IP，创建IP会增加该接口的reference count</span><br><span class="line">  3. 一个IP对应一个邻居，增加neighbour会增加该IP的reference count</span><br><span class="line">  4. 有了neighbour之后，路由协议会创建路由条目(route entry)，增加route entry会增加对VRF的reference count</span><br><span class="line">  5. route entry中的一个重要参数是next hop(可能会有多个next hop)，增加next hop会增加对route entry的reference count</span><br><span class="line"></span><br><span class="line">当一个对象的reference count不为0时，是不能将其删除的，必须彻底的解决其依赖关系。</span><br><span class="line"></span><br><span class="line">## SONiC数据同步机制的缺陷，以删除VRF为例</span><br><span class="line">![](https:&#x2F;&#x2F;rancho333.github.io&#x2F;pictures&#x2F;vrf_del_vrf.png)</span><br><span class="line">vrfmgrd会陷入loop等待vrforch删除数据库中stateobjectvrf条目，如果vrforch执行失败，vrfmgrd会陷入死循环。</span><br><span class="line"></span><br><span class="line">## zebra到fpmsyncd(bgp)同步路由的过程以及之前版本的缺陷(以删除ip为例)</span><br><span class="line">![](https:&#x2F;&#x2F;rancho333.github.io&#x2F;pictures&#x2F;vrf_del_ip.png)</span><br><span class="line"></span><br><span class="line">基本流程：</span><br><span class="line">1. SONiC通过Linux shell删除L3的IP</span><br><span class="line">2. zebra通过netlink同步信息并通知给个路由进程</span><br><span class="line">3. 路由进程决策路由信息通知给zebra</span><br><span class="line">4. zebra决策路由信息，通过netlink同步给kernel，通过fpm同步给sonic端的fpmsyncd</span><br><span class="line">5. zebra端fpm client写机制有缺陷(write buffer较小，有写次数的限制)，导致数据丢失</span><br><span class="line">6. 修改方式，在步骤1中删除IP后添加时延，减少zebra单位时间内处理的路由信息，给frr添加如下patch，解决fpm client写缺陷</span><br></pre></td></tr></table></figure>
<p> zebra/zebra_fpm.c |    4 ++–<br> 1 file changed, 2 insertions(+), 2 deletions(-)</p>
<p>diff –git a/zebra/zebra_fpm.c b/zebra/zebra_fpm.c<br>index 7b0611bf9..4efa8c896 100644<br>— a/zebra/zebra_fpm.c<br>+++ b/zebra/zebra_fpm.c<br>@@ -62,7 +62,7 @@ DEFINE_MTYPE_STATIC(ZEBRA, FPM_MAC_INFO, “FPM_MAC_INFO”);</p>
<ul>
<li>The maximum number of times the FPM socket write callback can call</li>
<li>‘write’ before it yields.</li>
<li>/</li>
</ul>
<p>-#define ZFPM_MAX_WRITES_PER_RUN 10<br>+#define ZFPM_MAX_WRITES_PER_RUN 100</p>
<p> /*</p>
<ul>
<li>Interval over which we collect statistics.<br>@@ -929,7 +929,7 @@ enum {<br>FPM_GOTO_NEXT_Q = 1<br>};</li>
</ul>
<p>-#define FPM_QUEUE_PROCESS_LIMIT 10000<br>+#define FPM_QUEUE_PROCESS_LIMIT 50000</p>
<p>```<br>注意SONiC中frr的编译机制，sonic-frr目录下的Makefile会checkout到指定分支，所以直接修改的代码内容会被覆盖。</p>
<h2 id="关于删除VRF中默认路由出错"><a href="#关于删除VRF中默认路由出错" class="headerlink" title="关于删除VRF中默认路由出错"></a>关于删除VRF中默认路由出错</h2><p>alpm模式下，broadcom TH4芯片在创建VRF时会创建一条默认路由(只存在于ASIC中，上层协议不可见)<br>当VRF只存在默认路由时，删除VRF会自动删除默认路由，如果此时显示删除默认路由，可以成功；<br>当VRF中存在默认路由以及其它路由时，不能显示删除默路由</p>
<p>原有，SONiC上层逻辑SWSS中，当删除default VRF中的默认路由时，将其设置为blackhole路由，当删除VRF中的默认路由时，下发删除指令，由于VRF中还有其它路由信息，SDK报错</p>
<p>修改为：当SONiC下发删除VRF中默认路由指令时，在SAI中将其实际行为修改为：将该默认路由配置成黑洞路由<br>      如果修改SONiC中的删除指令为配置成黑洞路由，那么在该VRF中，依然存在一个route entry，那么该VRF就存在reference count，那么该VRF就无法删除</p>
<h1 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h1><p><a href="https://datatracker.ietf.org/doc/html/rfc2685">rfc2685</a><br><a href="https://datatracker.ietf.org/doc/html/rfc4364">rfc4364</a><br><a href="https://github.com/Azure/SONiC/blob/master/doc/vrf/sonic-vrf-hld.md">SONiC VRF support design spec draft</a><br><a href="https://www.cisco.com/c/en/us/td/docs/net_mgmt/prime/network/3-8/reference/guide/vrf.html">VPN and VRF of cisco</a><br><a href="https://www.cisco.com/c/en/us/td/docs/switches/lan/catalyst4500/12-2/15-02SG/configuration/guide/config/vrf.html#85589">Config vrf of cisco</a><br><a href="https://www.kernel.org/doc/html/latest/networking/vrf.html">Vrf of linux kernel</a></p>
]]></content>
      <tags>
        <tag>vrf</tag>
      </tags>
  </entry>
</search>
